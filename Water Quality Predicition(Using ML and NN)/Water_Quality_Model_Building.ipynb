{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dae0fe8f",
   "metadata": {},
   "source": [
    "## 1. Importing the packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "154847ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split,RandomizedSearchCV,GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "from sklearn import preprocessing\n",
    "\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09479b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "548f9410",
   "metadata": {},
   "source": [
    "# 2. Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "26d4b837",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv(\"Water_Quality_train_x.csv\")\n",
    "X_test = pd.read_csv(\"Water_Quality_test_x.csv\")\n",
    "y_train = pd.read_csv(\"Water_Quality_train_y.csv\")\n",
    "y_test = pd.read_csv(\"Water_Quality_test_y.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7682c3f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2048, 9), (711, 9), (2048, 1), (711, 1))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape,X_test.shape,y_train.shape,y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c161d29",
   "metadata": {},
   "source": [
    "## 3. Model the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "223d313c",
   "metadata": {},
   "outputs": [],
   "source": [
    "performance = pd.DataFrame({\"model\": [], \"Accuracy\": [], \"Precision\": [], \"Recall\": [], \"F1\": []})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "270f7436",
   "metadata": {},
   "source": [
    "# Type 2 Error cost Error for this model. Type 2 error (false negative) would occur if the model fails to detect the presence of harmful contaminants when the water is actually contaminated. This could lead to exposure to harmful contaminants and potentially adverse health effects for individuals who consume the water. hence for the Hyperparameter tuning we will using Recall as the scoring metric."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ceb388",
   "metadata": {},
   "source": [
    "### 3.1 Fit and test a Logistic Regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c5dd0b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg_model = LogisticRegression()#penalty='none'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "acad401c",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = log_reg_model.fit(X_train, np.ravel(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "604eef7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.39      0.46       124\n",
      "           1       0.71      0.47      0.57       137\n",
      "           2       0.80      0.71      0.75       231\n",
      "           3       0.37      0.83      0.51        90\n",
      "           4       0.79      0.78      0.78       129\n",
      "\n",
      "    accuracy                           0.64       711\n",
      "   macro avg       0.65      0.64      0.62       711\n",
      "weighted avg       0.69      0.64      0.64       711\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_preds = log_reg_model.predict(X_test)\n",
    "c_matrix = confusion_matrix(y_test, model_preds)\n",
    "print(classification_report(y_test, model_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f4b77d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Random search For the Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "80bbe986",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_measure = \"recall\"\n",
    "kfolds = 10\n",
    "\n",
    "param_grid = {\n",
    "    \"max_iter\" : [100, 500, 1000, 5000],\n",
    "    \"solver\" : ['liblinear', 'newton-cg', 'lbfgs'],\n",
    "    \"penalty\" : ['l1','l2','elasticnet'],\n",
    "    \"warm_start\" : [True, False],\n",
    "    \"C\" :  [0.01, 0.1, 1, 10, 100]}\n",
    "\n",
    "lm = LogisticRegression()\n",
    "rand_search = RandomizedSearchCV(estimator = lm, param_distributions=param_grid, cv=kfolds, n_iter=200,\n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1,  # n_jobs=-1 will utilize all available CPUs \n",
    "                           return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e05b4c05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 200 candidates, totalling 2000 fits\n"
     ]
    }
   ],
   "source": [
    "_ = rand_search.fit(X_train, np.ravel(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3d8d2ec2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... with parameters: {'warm_start': True, 'solver': 'liblinear', 'penalty': 'l2', 'max_iter': 1000, 'C': 10}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(f\"... with parameters: {rand_search.best_params_}\")\n",
    "\n",
    "bestmodel = rand_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "07544c90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.29      0.39       124\n",
      "           1       0.70      0.38      0.49       137\n",
      "           2       0.75      0.69      0.72       231\n",
      "           3       0.33      0.80      0.47        90\n",
      "           4       0.71      0.79      0.75       129\n",
      "\n",
      "    accuracy                           0.59       711\n",
      "   macro avg       0.62      0.59      0.56       711\n",
      "weighted avg       0.65      0.59      0.59       711\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_preds = bestmodel.predict(X_test)\n",
    "c_matrix = confusion_matrix(y_test, model_preds)\n",
    "print(classification_report(y_test, model_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6d94bf76",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Grid Search log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9275d6a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_measure = \"recall\"\n",
    "kfolds = 4\n",
    "\n",
    "param_grid = {\n",
    "    \"max_iter\" : range(900,1100,5),\n",
    "    \"solver\" : ['liblinear'],\n",
    "    \"penalty\" : ['l2'],\n",
    "    \"warm_start\" : [True],\n",
    "    \"C\" : np.arange(8,12,1)}\n",
    "\n",
    "lm = LogisticRegression()\n",
    "GridSearch_log = GridSearchCV(estimator = lm, param_grid=param_grid, cv=kfolds,\n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1,  # n_jobs=-1 will utilize all available CPUs \n",
    "                           return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "34f5135b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 160 candidates, totalling 640 fits\n",
      "... with parameters: {'C': 8, 'max_iter': 900, 'penalty': 'l2', 'solver': 'liblinear', 'warm_start': True}\n"
     ]
    }
   ],
   "source": [
    "_ = GridSearch_log.fit(X_train, np.ravel(y_train))\n",
    "\n",
    "print(f\"... with parameters: {GridSearch_log.best_params_}\")\n",
    "\n",
    "bestmodel = GridSearch_log.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ef841e09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.29      0.39       124\n",
      "           1       0.69      0.38      0.49       137\n",
      "           2       0.75      0.69      0.72       231\n",
      "           3       0.33      0.80      0.47        90\n",
      "           4       0.71      0.79      0.75       129\n",
      "\n",
      "    accuracy                           0.59       711\n",
      "   macro avg       0.62      0.59      0.56       711\n",
      "weighted avg       0.65      0.59      0.59       711\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_preds = bestmodel.predict(X_test)\n",
    "c_matrix = confusion_matrix(y_test, model_preds)\n",
    "print(classification_report(y_test, model_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "096b3a28",
   "metadata": {},
   "source": [
    "### 3.2 fitting a SVM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9bbdc72d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC  \n",
    "svc_linear = SVC(kernel='linear') \n",
    "# fitting x samples and y classes \n",
    "_ = svc_linear.fit(X_train, np.ravel(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1e821579",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.50      0.55       124\n",
      "           1       0.74      0.41      0.53       137\n",
      "           2       0.83      0.72      0.77       231\n",
      "           3       0.38      0.87      0.53        90\n",
      "           4       0.85      0.85      0.85       129\n",
      "\n",
      "    accuracy                           0.66       711\n",
      "   macro avg       0.68      0.67      0.65       711\n",
      "weighted avg       0.72      0.66      0.67       711\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_preds = svc_linear.predict(X_test)\n",
    "c_matrix = confusion_matrix(y_test, model_preds)\n",
    "print(classification_report(y_test, model_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "51aa6ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "### SVM classification model using rbf kernal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5f1d4811",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_rbf_model = SVC(kernel=\"rbf\", C=10, gamma='scale')\n",
    "_ = svm_rbf_model.fit(X_train, np.ravel(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "48365c92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.59      0.62       124\n",
      "           1       0.64      0.46      0.54       137\n",
      "           2       0.83      0.81      0.82       231\n",
      "           3       0.45      0.73      0.56        90\n",
      "           4       0.88      0.87      0.88       129\n",
      "\n",
      "    accuracy                           0.71       711\n",
      "   macro avg       0.69      0.69      0.68       711\n",
      "weighted avg       0.72      0.71      0.71       711\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_preds = svm_rbf_model.predict(X_test)\n",
    "c_matrix = confusion_matrix(y_test, model_preds)\n",
    "print(classification_report(y_test, model_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "22791f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "### SVM classification model using polynomial kernal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1060eab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_poly_model = SVC(kernel=\"poly\", degree=3, coef0=1, C=10)\n",
    "_ = svm_poly_model.fit(X_train, np.ravel(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0b7789bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.58      0.60       124\n",
      "           1       0.63      0.47      0.54       137\n",
      "           2       0.81      0.82      0.81       231\n",
      "           3       0.45      0.67      0.54        90\n",
      "           4       0.88      0.86      0.87       129\n",
      "\n",
      "    accuracy                           0.70       711\n",
      "   macro avg       0.68      0.68      0.67       711\n",
      "weighted avg       0.71      0.70      0.70       711\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_preds = svm_poly_model.predict(X_test)\n",
    "c_matrix = confusion_matrix(y_test, model_preds)\n",
    "print(classification_report(y_test, model_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dac55737",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'C': [0.1,1, 10, 100], 'gamma': ['scale'],'kernel': ['rbf', 'poly', 'sigmoid']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a49310e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 12 candidates, totalling 48 fits\n",
      "... with parameters: {'kernel': 'rbf', 'gamma': 'scale', 'C': 0.1}\n"
     ]
    }
   ],
   "source": [
    "score_measure = \"recall\"\n",
    "kfolds = 4\n",
    "\n",
    "sv = SVC()\n",
    "rand_search = RandomizedSearchCV(estimator = sv, param_distributions=param_grid, cv=kfolds, n_iter=48,\n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1,  # n_jobs=-1 will utilize all available CPUs \n",
    "                           return_train_score=True)\n",
    "\n",
    "_ = rand_search.fit(X_train, np.ravel(y_train))\n",
    "\n",
    "\n",
    "print(f\"... with parameters: {rand_search.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "18564fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = rand_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6965891b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(C=0.1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(C=0.1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(C=0.1)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.fit(X_train, np.ravel(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dd24d974",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.47      0.54       124\n",
      "           1       0.70      0.19      0.30       137\n",
      "           2       0.78      0.68      0.73       231\n",
      "           3       0.32      0.91      0.47        90\n",
      "           4       0.87      0.81      0.84       129\n",
      "\n",
      "    accuracy                           0.60       711\n",
      "   macro avg       0.66      0.61      0.58       711\n",
      "weighted avg       0.70      0.60      0.60       711\n",
      "\n"
     ]
    }
   ],
   "source": [
    "c_matrix = confusion_matrix(y_test, f.predict(X_test))\n",
    "print(classification_report(y_test,f.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9a47e3ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'C': [10,15,20,25] , 'gamma': ['scale'] ,'kernel': ['rbf']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "41b27fd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 4 candidates, totalling 16 fits\n",
      "... with parameters: {'C': 10, 'gamma': 'scale', 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "score_measure = \"recall\"\n",
    "kfolds = 4\n",
    "\n",
    "sv = SVC()\n",
    "rand_search = GridSearchCV(estimator = sv, param_grid=param_grid, cv=kfolds,\n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1,  # n_jobs=-1 will utilize all available CPUs \n",
    "                           return_train_score=True)\n",
    "\n",
    "_ = rand_search.fit(X_train, np.ravel(y_train))\n",
    "\n",
    "\n",
    "print(f\"... with parameters: {rand_search.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a3c4dc55",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = rand_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "451d6763",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(C=10)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(C=10)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(C=10)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.fit(X_train, np.ravel(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "86db3d9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.59      0.62       124\n",
      "           1       0.64      0.46      0.54       137\n",
      "           2       0.83      0.81      0.82       231\n",
      "           3       0.45      0.73      0.56        90\n",
      "           4       0.88      0.87      0.88       129\n",
      "\n",
      "    accuracy                           0.71       711\n",
      "   macro avg       0.69      0.69      0.68       711\n",
      "weighted avg       0.72      0.71      0.71       711\n",
      "\n"
     ]
    }
   ],
   "source": [
    "c_matrix = confusion_matrix(y_test, f.predict(X_test))\n",
    "print(classification_report(y_test,f.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0be9248f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "936b0975",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtree = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b99bef65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtree.fit(X_train, np.ravel(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "321b497e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.71      0.72       124\n",
      "           1       0.71      0.72      0.72       137\n",
      "           2       0.79      0.81      0.80       231\n",
      "           3       0.71      0.63      0.67        90\n",
      "           4       0.87      0.91      0.89       129\n",
      "\n",
      "    accuracy                           0.77       711\n",
      "   macro avg       0.76      0.76      0.76       711\n",
      "weighted avg       0.77      0.77      0.77       711\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, dtree.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a407d924",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 500 candidates, totalling 2000 fits\n",
      "... with parameters: {'min_samples_split': 25, 'min_samples_leaf': 28, 'min_impurity_decrease': 0.0071, 'max_leaf_nodes': 112, 'max_depth': 33, 'criterion': 'gini'}\n"
     ]
    }
   ],
   "source": [
    "score_measure = \"recall\"\n",
    "kfolds = 4 \n",
    "\n",
    "param_grid = {\n",
    "    'min_samples_split': np.arange(1,50),  \n",
    "    'min_samples_leaf': np.arange(1,50),\n",
    "    'min_impurity_decrease': np.arange(0.0001, 0.01, 0.0005),\n",
    "    'max_leaf_nodes': np.arange(5, 200), \n",
    "    'max_depth': np.arange(1,50), \n",
    "    'criterion': ['entropy', 'gini'],\n",
    "}\n",
    "\n",
    "dtree = DecisionTreeClassifier()\n",
    "rand_search = RandomizedSearchCV(estimator = dtree, param_distributions=param_grid, cv=kfolds, n_iter=500,\n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1,  # n_jobs=-1 will utilize all available CPUs \n",
    "                           return_train_score=True)\n",
    "\n",
    "_ = rand_search.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "print(f\"... with parameters: {rand_search.best_params_}\")\n",
    "\n",
    "bestRecallTree = rand_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d390d97e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.56      0.61       124\n",
      "           1       0.88      0.42      0.57       137\n",
      "           2       0.76      0.76      0.76       231\n",
      "           3       0.43      0.86      0.57        90\n",
      "           4       0.85      0.88      0.87       129\n",
      "\n",
      "    accuracy                           0.69       711\n",
      "   macro avg       0.72      0.70      0.68       711\n",
      "weighted avg       0.74      0.69      0.69       711\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_preds = bestRecallTree.predict(X_test)\n",
    "c_matrix = confusion_matrix(y_test, model_preds)\n",
    "print(classification_report(y_test, model_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "074be062",
   "metadata": {},
   "outputs": [],
   "source": [
    "### grid Search CV Dtree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3754263a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 8400 candidates, totalling 33600 fits\n",
      "... with parameters: {'criterion': 'gini', 'max_depth': 28, 'max_leaf_nodes': 94, 'min_impurity_decrease': 0.001, 'min_samples_leaf': 32, 'min_samples_split': 45}\n"
     ]
    }
   ],
   "source": [
    "score_measure = \"recall\"\n",
    "kfolds = 4\n",
    "\n",
    "param_grid = {\n",
    "    'min_samples_split': np.arange(45,50),  \n",
    "    'min_samples_leaf': np.arange(32,36),\n",
    "    'min_impurity_decrease': np.arange(0.001, 0.002, 0.0001),\n",
    "    'max_leaf_nodes': np.arange(94,100), \n",
    "    'max_depth': np.arange(28,35), \n",
    "    'criterion': ['gini'],\n",
    "}\n",
    "\n",
    "dtree = DecisionTreeClassifier()\n",
    "grid_search = GridSearchCV(estimator = dtree, param_grid=param_grid, cv=kfolds, \n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1,  # n_jobs=-1 will utilize all available CPUs \n",
    "                           return_train_score=True)\n",
    "\n",
    "_ = grid_search.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "print(f\"... with parameters: {grid_search.best_params_}\")\n",
    "\n",
    "bestRecallTree = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3f94ccf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.62      0.67       124\n",
      "           1       0.77      0.72      0.74       137\n",
      "           2       0.85      0.74      0.79       231\n",
      "           3       0.55      0.82      0.66        90\n",
      "           4       0.83      0.93      0.88       129\n",
      "\n",
      "    accuracy                           0.76       711\n",
      "   macro avg       0.75      0.76      0.75       711\n",
      "weighted avg       0.77      0.76      0.76       711\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_preds = bestRecallTree.predict(X_test)\n",
    "c_matrix = confusion_matrix(y_test, model_preds)\n",
    "print(classification_report(y_test, model_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d4043b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5f184655",
   "metadata": {},
   "source": [
    "## Netural Networks using sklearn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "88833167",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ac6cba9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 34.3 s\n",
      "Wall time: 4.31 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "ann = MLPClassifier(hidden_layer_sizes=(100,80,100), solver='sgd', max_iter=300)\n",
    "_ = ann.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0a0273ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 3.78 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_pred = ann.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5c01c43c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.53      0.58       124\n",
      "           1       0.68      0.44      0.53       137\n",
      "           2       0.80      0.74      0.77       231\n",
      "           3       0.44      0.83      0.58        90\n",
      "           4       0.83      0.88      0.86       129\n",
      "\n",
      "    accuracy                           0.68       711\n",
      "   macro avg       0.68      0.69      0.66       711\n",
      "weighted avg       0.71      0.68      0.68       711\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "513cda20",
   "metadata": {},
   "outputs": [],
   "source": [
    "### using accuracy as Scoring mertic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "66075ab0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "{'solver': 'sgd', 'max_iter': 5000, 'learning_rate_init': 0.2, 'learning_rate': 'adaptive', 'hidden_layer_sizes': (40, 40, 40), 'alpha': 0.5, 'activation': 'relu'}\n",
      "CPU times: total: 22.2 s\n",
      "Wall time: 2min 21s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "score_measure = \"accuracy\"\n",
    "kfolds = 5\n",
    "\n",
    "param_grid = {\n",
    "    'hidden_layer_sizes': [ (50,), (70,),(50,30), (40,20), (30,30,30),(40,40,40),(60,60,60),(60,40, 20), (70,50,40)],\n",
    "    'activation': ['logistic', 'tanh', 'relu'],\n",
    "    'solver': ['adam', 'sgd'],\n",
    "    'alpha': [0, .2, .5, .7, 1],\n",
    "    'learning_rate': ['constant', 'invscaling', 'adaptive'],\n",
    "    'learning_rate_init': [0.001, 0.01, 0.1, 0.2, 0.5],\n",
    "    'max_iter': [5000]\n",
    "}\n",
    "\n",
    "ann = MLPClassifier()\n",
    "grid_search = RandomizedSearchCV(estimator = ann, param_distributions=param_grid, cv=kfolds, n_iter=100,\n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1,  # n_jobs=-1 will utilize all available CPUs \n",
    "                           return_train_score=True)\n",
    "\n",
    "_ = grid_search.fit(X_train, y_train)\n",
    "\n",
    "bestRecallTree = grid_search.best_estimator_\n",
    "\n",
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2520a674",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8144552447969469"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "acad9978",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.65      0.66       124\n",
      "           1       0.63      0.54      0.58       137\n",
      "           2       0.86      0.82      0.84       231\n",
      "           3       0.48      0.66      0.55        90\n",
      "           4       0.89      0.87      0.88       129\n",
      "\n",
      "    accuracy                           0.72       711\n",
      "   macro avg       0.70      0.71      0.70       711\n",
      "weighted avg       0.74      0.72      0.73       711\n",
      "\n",
      "CPU times: total: 125 ms\n",
      "Wall time: 12.1 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_pred = bestRecallTree.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e90dbece",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ac625b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
    "{'solver': 'sgd', 'max_iter': 5000, 'learning_rate_init': 0.2, 'learning_rate': 'adaptive', 'hidden_layer_sizes': (40, 40, 40), 'alpha': 0.5, 'activation': 'relu'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "59532c10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 168 candidates, totalling 840 fits\n",
      "{'activation': 'relu', 'alpha': 0.1, 'hidden_layer_sizes': (45, 50, 45), 'learning_rate': 'adaptive', 'learning_rate_init': 0.15, 'max_iter': 5000, 'solver': 'sgd'}\n",
      "CPU times: total: 29.2 s\n",
      "Wall time: 5min 33s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "score_measure = \"accuracy\"\n",
    "kfolds = 5\n",
    "\n",
    "param_grid = {\n",
    "    'hidden_layer_sizes': [(50,30),(50,20),(40,20,10),(30,30,30),(40,40,40),(45,50,45),(60,60,60)],\n",
    "    'activation': ['relu'],\n",
    "    'solver': ['sgd'],\n",
    "    'alpha': [0.1,0.2,0.3,0.4],\n",
    "    'learning_rate': ['adaptive'],\n",
    "    'learning_rate_init': [0.005, 0.01, 0.15],\n",
    "    'max_iter': [5000,10000]\n",
    "}\n",
    "\n",
    "ann = MLPClassifier()\n",
    "grid_search = GridSearchCV(estimator = ann, param_grid=param_grid, cv=kfolds, \n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1,  # n_jobs=-1 will utilize all available CPUs \n",
    "                           return_train_score=True)\n",
    "\n",
    "_ = grid_search.fit(X_train, y_train)\n",
    "\n",
    "bestRecallTree = grid_search.best_estimator_\n",
    "\n",
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7abe349a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.63      0.63       124\n",
      "           1       0.59      0.60      0.60       137\n",
      "           2       0.83      0.82      0.83       231\n",
      "           3       0.42      0.43      0.43        90\n",
      "           4       0.87      0.87      0.87       129\n",
      "\n",
      "    accuracy                           0.70       711\n",
      "   macro avg       0.67      0.67      0.67       711\n",
      "weighted avg       0.71      0.70      0.70       711\n",
      "\n",
      "CPU times: total: 125 ms\n",
      "Wall time: 9.58 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_pred = bestRecallTree.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "672c5238",
   "metadata": {},
   "outputs": [],
   "source": [
    "### With Recall as the scoring mertic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a3afa6c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "{'solver': 'sgd', 'max_iter': 5000, 'learning_rate_init': 0.2, 'learning_rate': 'invscaling', 'hidden_layer_sizes': (30, 30, 30), 'alpha': 0.2, 'activation': 'relu'}\n",
      "CPU times: total: 1min 12s\n",
      "Wall time: 2min 26s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "score_measure = \"recall\"\n",
    "kfolds = 5\n",
    "\n",
    "param_grid = {\n",
    "    'hidden_layer_sizes': [ (50,), (70,),(50,30), (40,20), (30,30,30),(40,40,40),(60,60,60),(60,40, 20), (70,50,40)],\n",
    "    'activation': ['logistic', 'tanh', 'relu'],\n",
    "    'solver': ['adam', 'sgd'],\n",
    "    'alpha': [0, .2, .5, .7, 1],\n",
    "    'learning_rate': ['constant', 'invscaling', 'adaptive'],\n",
    "    'learning_rate_init': [0.001, 0.01, 0.1, 0.2, 0.5],\n",
    "    'max_iter': [5000]\n",
    "}\n",
    "\n",
    "ann = MLPClassifier()\n",
    "grid_search = RandomizedSearchCV(estimator = ann, param_distributions=param_grid, cv=kfolds, n_iter=100,\n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1,  # n_jobs=-1 will utilize all available CPUs \n",
    "                           return_train_score=True)\n",
    "\n",
    "_ = grid_search.fit(X_train, y_train)\n",
    "\n",
    "bestRecallTree = grid_search.best_estimator_\n",
    "\n",
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c8031c32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.49      0.55       124\n",
      "           1       0.69      0.42      0.52       137\n",
      "           2       0.82      0.72      0.76       231\n",
      "           3       0.41      0.86      0.56        90\n",
      "           4       0.81      0.88      0.84       129\n",
      "\n",
      "    accuracy                           0.67       711\n",
      "   macro avg       0.67      0.67      0.65       711\n",
      "weighted avg       0.71      0.67      0.67       711\n",
      "\n",
      "CPU times: total: 0 ns\n",
      "Wall time: 10 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_pred = bestRecallTree.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "78db7955",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 180 candidates, totalling 900 fits\n",
      "{'activation': 'tanh', 'alpha': 0.5, 'hidden_layer_sizes': (30, 30, 30), 'learning_rate': 'adaptive', 'learning_rate_init': 0.005, 'max_iter': 5000, 'solver': 'adam'}\n",
      "CPU times: total: 15.3 s\n",
      "Wall time: 1min 19s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "score_measure = \"recall\"\n",
    "kfolds = 5\n",
    "\n",
    "param_grid = {\n",
    "    'hidden_layer_sizes': [(30,30,30),(40, 20),(40,20,5),(40,50,2),(50,80,55)],\n",
    "    'activation': ['tanh', 'relu'],\n",
    "    'solver': ['adam'],\n",
    "    'alpha': [.5, .7, 1],\n",
    "    'learning_rate': ['adaptive', 'invscaling'],\n",
    "    'learning_rate_init': [0.005, 0.01, 0.15],\n",
    "    'max_iter': [5000]\n",
    "}\n",
    "\n",
    "ann = MLPClassifier()\n",
    "grid_search = GridSearchCV(estimator = ann, param_grid=param_grid, cv=kfolds, \n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1,  # n_jobs=-1 will utilize all available CPUs \n",
    "                           return_train_score=True)\n",
    "\n",
    "_ = grid_search.fit(X_train, y_train)\n",
    "\n",
    "bestRecallTree = grid_search.best_estimator_\n",
    "\n",
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "97804481",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.60      0.63       124\n",
      "           1       0.60      0.45      0.51       137\n",
      "           2       0.81      0.82      0.81       231\n",
      "           3       0.46      0.69      0.55        90\n",
      "           4       0.88      0.85      0.87       129\n",
      "\n",
      "    accuracy                           0.70       711\n",
      "   macro avg       0.68      0.68      0.68       711\n",
      "weighted avg       0.71      0.70      0.70       711\n",
      "\n",
      "CPU times: total: 125 ms\n",
      "Wall time: 20.3 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_pred = bestRecallTree.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f3a8aef",
   "metadata": {},
   "source": [
    "# NN Using Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad15bbe",
   "metadata": {},
   "source": [
    "## Deep Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5620a408",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "np.random.seed(1)\n",
    "tf.random.set_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "91fbb547",
   "metadata": {},
   "outputs": [],
   "source": [
    "## DEFAULT "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "feb7d5f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 46.9 ms\n",
      "Wall time: 56 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# create model stucture\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Input(9))\n",
    "model.add(keras.layers.Dense(40, activation='relu'))\n",
    "model.add(keras.layers.Dense(30, activation='relu'))\n",
    "model.add(keras.layers.Dense(30, activation='relu'))\n",
    "model.add(keras.layers.Dense(5, activation='softmax')) # final layer, 10 categories\n",
    "\n",
    "\n",
    "# compile\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# if you want to overide the defaults for the optimizer....\n",
    "#adam = keras.optimizers.Adam(learning_rate=0.01)\n",
    "#model.compile(loss='sparse_categorical_crossentropy', optimizer=adam, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c49b4ccb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "21/21 [==============================] - 1s 15ms/step - loss: 1.5233 - accuracy: 0.3647 - val_loss: 1.4086 - val_accuracy: 0.4852\n",
      "Epoch 2/50\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.3449 - accuracy: 0.5259 - val_loss: 1.2870 - val_accuracy: 0.4866\n",
      "Epoch 3/50\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.2024 - accuracy: 0.5513 - val_loss: 1.2140 - val_accuracy: 0.4698\n",
      "Epoch 4/50\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.1016 - accuracy: 0.5640 - val_loss: 1.1469 - val_accuracy: 0.4937\n",
      "Epoch 5/50\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.0339 - accuracy: 0.5874 - val_loss: 1.0971 - val_accuracy: 0.5401\n",
      "Epoch 6/50\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 0.9722 - accuracy: 0.6152 - val_loss: 1.0373 - val_accuracy: 0.5752\n",
      "Epoch 7/50\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 0.9191 - accuracy: 0.6475 - val_loss: 0.9969 - val_accuracy: 0.5963\n",
      "Epoch 8/50\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 0.8716 - accuracy: 0.6748 - val_loss: 0.9792 - val_accuracy: 0.6062\n",
      "Epoch 9/50\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 0.8306 - accuracy: 0.6875 - val_loss: 0.9470 - val_accuracy: 0.6343\n",
      "Epoch 10/50\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 0.7954 - accuracy: 0.7056 - val_loss: 0.9358 - val_accuracy: 0.6540\n",
      "Epoch 11/50\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 0.7676 - accuracy: 0.7065 - val_loss: 0.9215 - val_accuracy: 0.6624\n",
      "Epoch 12/50\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 0.7450 - accuracy: 0.7207 - val_loss: 0.9038 - val_accuracy: 0.6723\n",
      "Epoch 13/50\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 0.7252 - accuracy: 0.7202 - val_loss: 0.8900 - val_accuracy: 0.6821\n",
      "Epoch 14/50\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 0.7100 - accuracy: 0.7344 - val_loss: 0.8896 - val_accuracy: 0.6821\n",
      "Epoch 15/50\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 0.6957 - accuracy: 0.7349 - val_loss: 0.8846 - val_accuracy: 0.6892\n",
      "Epoch 16/50\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 0.6811 - accuracy: 0.7461 - val_loss: 0.8755 - val_accuracy: 0.6850\n",
      "Epoch 17/50\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 0.6672 - accuracy: 0.7471 - val_loss: 0.8848 - val_accuracy: 0.6864\n",
      "Epoch 18/50\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 0.6603 - accuracy: 0.7461 - val_loss: 0.9196 - val_accuracy: 0.6596\n",
      "Epoch 19/50\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 0.6490 - accuracy: 0.7515 - val_loss: 0.8830 - val_accuracy: 0.6920\n",
      "Epoch 20/50\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 0.6366 - accuracy: 0.7627 - val_loss: 0.8695 - val_accuracy: 0.6948\n",
      "Epoch 21/50\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 0.6270 - accuracy: 0.7583 - val_loss: 0.8597 - val_accuracy: 0.6976\n",
      "Epoch 22/50\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 0.6194 - accuracy: 0.7686 - val_loss: 0.8783 - val_accuracy: 0.6948\n",
      "Epoch 23/50\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 0.6165 - accuracy: 0.7676 - val_loss: 0.8859 - val_accuracy: 0.6920\n",
      "Epoch 24/50\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 0.6073 - accuracy: 0.7700 - val_loss: 0.8903 - val_accuracy: 0.6821\n",
      "Epoch 25/50\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 0.6008 - accuracy: 0.7739 - val_loss: 0.8708 - val_accuracy: 0.6934\n",
      "Epoch 26/50\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 0.5935 - accuracy: 0.7734 - val_loss: 0.9021 - val_accuracy: 0.6864\n",
      "Epoch 27/50\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 0.5908 - accuracy: 0.7793 - val_loss: 0.8787 - val_accuracy: 0.6962\n",
      "Epoch 28/50\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 0.5829 - accuracy: 0.7832 - val_loss: 0.8846 - val_accuracy: 0.6976\n",
      "Epoch 29/50\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 0.5758 - accuracy: 0.7871 - val_loss: 0.8864 - val_accuracy: 0.6934\n",
      "Epoch 30/50\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 0.5722 - accuracy: 0.7876 - val_loss: 0.8878 - val_accuracy: 0.6920\n",
      "Epoch 31/50\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 0.5684 - accuracy: 0.7856 - val_loss: 0.8903 - val_accuracy: 0.6976\n",
      "Epoch 32/50\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 0.5655 - accuracy: 0.7881 - val_loss: 0.8981 - val_accuracy: 0.6920\n",
      "Epoch 33/50\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 0.5594 - accuracy: 0.7842 - val_loss: 0.8812 - val_accuracy: 0.6906\n",
      "Epoch 34/50\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 0.5530 - accuracy: 0.7988 - val_loss: 0.8716 - val_accuracy: 0.6976\n",
      "Epoch 35/50\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 0.5514 - accuracy: 0.7949 - val_loss: 0.8782 - val_accuracy: 0.7004\n",
      "Epoch 36/50\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 0.5482 - accuracy: 0.7959 - val_loss: 0.8972 - val_accuracy: 0.6990\n",
      "Epoch 37/50\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 0.5427 - accuracy: 0.7979 - val_loss: 0.8869 - val_accuracy: 0.6934\n",
      "Epoch 38/50\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 0.5394 - accuracy: 0.7998 - val_loss: 0.8988 - val_accuracy: 0.7018\n",
      "Epoch 39/50\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 0.5373 - accuracy: 0.7998 - val_loss: 0.9099 - val_accuracy: 0.6976\n",
      "Epoch 40/50\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 0.5331 - accuracy: 0.8057 - val_loss: 0.9000 - val_accuracy: 0.6906\n",
      "Epoch 41/50\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 0.5301 - accuracy: 0.8037 - val_loss: 0.8973 - val_accuracy: 0.6906\n",
      "Epoch 42/50\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 0.5327 - accuracy: 0.8027 - val_loss: 0.8900 - val_accuracy: 0.6920\n",
      "Epoch 43/50\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 0.5247 - accuracy: 0.8062 - val_loss: 0.8893 - val_accuracy: 0.6976\n",
      "Epoch 44/50\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 0.5193 - accuracy: 0.8076 - val_loss: 0.9012 - val_accuracy: 0.6962\n",
      "Epoch 45/50\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 0.5210 - accuracy: 0.8062 - val_loss: 0.8918 - val_accuracy: 0.7089\n",
      "Epoch 46/50\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 0.5172 - accuracy: 0.8081 - val_loss: 0.9188 - val_accuracy: 0.6920\n",
      "Epoch 47/50\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 0.5120 - accuracy: 0.8115 - val_loss: 0.9293 - val_accuracy: 0.6920\n",
      "Epoch 48/50\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 0.5116 - accuracy: 0.8081 - val_loss: 0.9039 - val_accuracy: 0.6976\n",
      "Epoch 49/50\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 0.5062 - accuracy: 0.8135 - val_loss: 0.8991 - val_accuracy: 0.6962\n",
      "Epoch 50/50\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 0.5043 - accuracy: 0.8096 - val_loss: 0.9035 - val_accuracy: 0.6962\n",
      "CPU times: total: 49.8 s\n",
      "Wall time: 5.14 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# fit the model\n",
    "history = model.fit(X_train, y_train, \n",
    "                    validation_data=(X_test, y_test), \n",
    "                    epochs=50, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "790ea749",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9034883379936218, 0.6962025165557861]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate the model\n",
    "\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "scores\n",
    "# In results, first is loss, second is accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d50c95f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.90\n",
      "accuracy: 69.62%\n"
     ]
    }
   ],
   "source": [
    "# let's format this into a better output...\n",
    "\n",
    "print(\"%s: %.2f\" % (model.metrics_names[0], scores[0]))\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c37804a2",
   "metadata": {},
   "source": [
    "### KERAS WITH SKLEARN HYPERPARAMETER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d3a5cb4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RANDOM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "003f1518",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "def build_clf(meta, hidden_layer_sizes, dropout):\n",
    "    n_features_in_ = meta[\"n_features_in_\"]\n",
    "    n_classes_ = meta[\"n_classes_\"]\n",
    "    target_encoder_ = meta[\"target_encoder_\"]\n",
    "    \n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(keras.layers.Input(shape=n_features_in_)),\n",
    "    #for hidden_layer_size in hidden_layer_sizes:\n",
    "    for hidden_layer_size in hidden_layer_sizes:\n",
    "        model.add(keras.layers.Dense(hidden_layer_size, \n",
    "            kernel_initializer= tf.keras.initializers.GlorotUniform(), \n",
    "            bias_initializer=keras.initializers.RandomNormal(mean=0.0, stddev=0.05, seed=None), \n",
    "            activation=\"relu\"))\n",
    "        model.add(keras.layers.Dropout(dropout))\n",
    "    model.add(tf.keras.layers.Dense(5, activation='softmax'))\n",
    "    \n",
    "    #though you could return a compiled model, it's not necessary, and would result in the loss of these\n",
    "    # parameters in the tune process - as they would be 'hard coded'\n",
    "    # model.compile(loss = 'sparse_categorical_crossentropy', metrics = ['accuracy']) \n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "34122b70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 15.6 ms\n",
      "Wall time: 29.1 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'model': <function __main__.build_clf(meta, hidden_layer_sizes, dropout)>,\n",
       " 'build_fn': None,\n",
       " 'warm_start': False,\n",
       " 'random_state': None,\n",
       " 'optimizer': keras.optimizers.optimizer_v2.adam.Adam,\n",
       " 'loss': None,\n",
       " 'metrics': None,\n",
       " 'batch_size': None,\n",
       " 'validation_batch_size': None,\n",
       " 'verbose': 1,\n",
       " 'callbacks': None,\n",
       " 'validation_split': 0.0,\n",
       " 'shuffle': True,\n",
       " 'run_eagerly': False,\n",
       " 'epochs': 1,\n",
       " 'hidden_layer_sizes': 9,\n",
       " 'dropout': 0.5,\n",
       " 'optimizer__learning_rate': 0.0001,\n",
       " 'class_weight': None}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# If you don't have the following installed, from command line '!pip install scikeras'\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "\n",
    "keras_clf = KerasClassifier(\n",
    "    model=build_clf,\n",
    "    hidden_layer_sizes=9,\n",
    "    dropout=0.5,\n",
    "    optimizer=keras.optimizers.Adam,\n",
    "    optimizer__learning_rate=0.0001\n",
    ")\n",
    "keras_clf.get_params()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "3c1b8ef1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'model': <function __main__.build_clf(meta, hidden_layer_sizes, dropout)>,\n",
       " 'build_fn': None,\n",
       " 'warm_start': False,\n",
       " 'random_state': None,\n",
       " 'optimizer': keras.optimizers.optimizer_v2.adam.Adam,\n",
       " 'loss': None,\n",
       " 'metrics': None,\n",
       " 'batch_size': None,\n",
       " 'validation_batch_size': None,\n",
       " 'verbose': 1,\n",
       " 'callbacks': None,\n",
       " 'validation_split': 0.0,\n",
       " 'shuffle': True,\n",
       " 'run_eagerly': False,\n",
       " 'epochs': 1,\n",
       " 'hidden_layer_sizes': 9,\n",
       " 'dropout': 0.5,\n",
       " 'optimizer__learning_rate': 0.0001,\n",
       " 'class_weight': None}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "params = {\n",
    "    \n",
    "    # the following are model parameters, and therefore must be defined as parameters in the KarasClassifier, and then in the build_clf function\n",
    "    'model__hidden_layer_sizes': [(40,),(50, ), (56,), (60, 90)], # this will require KarasClassifier and build_clf to have hidden_layer_sizes parameter set\n",
    "    'model__dropout': [0, 0.1], # this will require KarasClassifier and build_clf to have hidden_layer_sizes parameter set\n",
    "    \n",
    "    # the following are 'fit' parameters, the scikeras wrapper provides these parameters. These are passed to the 'model.fit' method for each fit of the model\n",
    "    'batch_size':[20, 60, 100],\n",
    "    'epochs':[10],\n",
    "    'optimizer':['adam','sgd'],\n",
    "    'loss':['sparse_categorical_crossentropy'],\n",
    "    \n",
    "    # this is added to the optimizer \n",
    "    'optimizer__learning_rate': [0.0001, 0.001, 0.01]\n",
    "\n",
    "}\n",
    "keras_clf.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "c67de490",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 1.6022\n",
      "Epoch 2/10\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 1.5908\n",
      "Epoch 3/10\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 1.5859\n",
      "Epoch 4/10\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 1.5831\n",
      "Epoch 5/10\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 1.5703\n",
      "Epoch 6/10\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 1.5673\n",
      "Epoch 7/10\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 1.5574\n",
      "Epoch 8/10\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 1.5473\n",
      "Epoch 9/10\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 1.5467\n",
      "Epoch 10/10\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 1.5409\n",
      "12/12 [==============================] - 0s 819us/step\n",
      "Epoch 1/10\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 1.6536\n",
      "Epoch 2/10\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 1.6502\n",
      "Epoch 3/10\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 1.6465\n",
      "Epoch 4/10\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 1.6406\n",
      "Epoch 5/10\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 1.6366\n",
      "Epoch 6/10\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 1.6299\n",
      "Epoch 7/10\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 1.6257\n",
      "Epoch 8/10\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 1.6154\n",
      "Epoch 9/10\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 1.6151\n",
      "Epoch 10/10\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 1.6112\n",
      "12/12 [==============================] - 0s 774us/step\n",
      "Epoch 1/10\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 1.6189\n",
      "Epoch 2/10\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 1.6146\n",
      "Epoch 3/10\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 1.6123\n",
      "Epoch 4/10\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 1.6053\n",
      "Epoch 5/10\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 1.6042\n",
      "Epoch 6/10\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 1.5927\n",
      "Epoch 7/10\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 1.5931\n",
      "Epoch 8/10\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 1.5892\n",
      "Epoch 9/10\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 1.5788\n",
      "Epoch 10/10\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 1.5742\n",
      "12/12 [==============================] - 0s 898us/step\n",
      "Epoch 1/10\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 1.4573\n",
      "Epoch 2/10\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 1.2612\n",
      "Epoch 3/10\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 1.1447\n",
      "Epoch 4/10\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 1.0780\n",
      "Epoch 5/10\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 1.0032\n",
      "Epoch 6/10\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.9363\n",
      "Epoch 7/10\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.9135\n",
      "Epoch 8/10\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.8808\n",
      "Epoch 9/10\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.8500\n",
      "Epoch 10/10\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.8256\n",
      "12/12 [==============================] - 0s 708us/step\n",
      "Epoch 1/10\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 1.4929\n",
      "Epoch 2/10\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 1.3031\n",
      "Epoch 3/10\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 1.1719\n",
      "Epoch 4/10\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 1.0821\n",
      "Epoch 5/10\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 1.0095\n",
      "Epoch 6/10\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.9585\n",
      "Epoch 7/10\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.9161\n",
      "Epoch 8/10\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.8951\n",
      "Epoch 9/10\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.8499\n",
      "Epoch 10/10\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.8351\n",
      "12/12 [==============================] - 0s 752us/step\n",
      "Epoch 1/10\n",
      "23/23 [==============================] - 1s 1ms/step - loss: 1.5228\n",
      "Epoch 2/10\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 1.3102\n",
      "Epoch 3/10\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 1.1847\n",
      "Epoch 4/10\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 1.1088\n",
      "Epoch 5/10\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 1.0423\n",
      "Epoch 6/10\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 1.0023\n",
      "Epoch 7/10\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.9585\n",
      "Epoch 8/10\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.9293\n",
      "Epoch 9/10\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.8955\n",
      "Epoch 10/10\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.8714\n",
      "12/12 [==============================] - 0s 882us/step\n",
      "Epoch 1/10\n",
      "23/23 [==============================] - 0s 987us/step - loss: 1.7971\n",
      "Epoch 2/10\n",
      "23/23 [==============================] - 0s 872us/step - loss: 1.7729\n",
      "Epoch 3/10\n",
      "23/23 [==============================] - 0s 876us/step - loss: 1.7484\n",
      "Epoch 4/10\n",
      "23/23 [==============================] - 0s 911us/step - loss: 1.7313\n",
      "Epoch 5/10\n",
      "23/23 [==============================] - 0s 883us/step - loss: 1.7116\n",
      "Epoch 6/10\n",
      "23/23 [==============================] - 0s 871us/step - loss: 1.6909\n",
      "Epoch 7/10\n",
      "23/23 [==============================] - 0s 886us/step - loss: 1.6737\n",
      "Epoch 8/10\n",
      "23/23 [==============================] - 0s 882us/step - loss: 1.6570\n",
      "Epoch 9/10\n",
      "23/23 [==============================] - 0s 856us/step - loss: 1.6396\n",
      "Epoch 10/10\n",
      "23/23 [==============================] - 0s 863us/step - loss: 1.6209\n",
      "12/12 [==============================] - 0s 639us/step\n",
      "Epoch 1/10\n",
      "23/23 [==============================] - 0s 978us/step - loss: 1.6836\n",
      "Epoch 2/10\n",
      "23/23 [==============================] - 0s 856us/step - loss: 1.6556\n",
      "Epoch 3/10\n",
      "23/23 [==============================] - 0s 842us/step - loss: 1.6354\n",
      "Epoch 4/10\n",
      "23/23 [==============================] - 0s 847us/step - loss: 1.6223\n",
      "Epoch 5/10\n",
      "23/23 [==============================] - 0s 905us/step - loss: 1.5919\n",
      "Epoch 6/10\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 1.5727\n",
      "Epoch 7/10\n",
      "23/23 [==============================] - 0s 843us/step - loss: 1.5622\n",
      "Epoch 8/10\n",
      "23/23 [==============================] - 0s 870us/step - loss: 1.5402\n",
      "Epoch 9/10\n",
      "23/23 [==============================] - 0s 829us/step - loss: 1.5227\n",
      "Epoch 10/10\n",
      "23/23 [==============================] - 0s 876us/step - loss: 1.5028\n",
      "12/12 [==============================] - 0s 795us/step\n",
      "Epoch 1/10\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 1.7134\n",
      "Epoch 2/10\n",
      "23/23 [==============================] - 0s 861us/step - loss: 1.6874\n",
      "Epoch 3/10\n",
      "23/23 [==============================] - 0s 875us/step - loss: 1.6633\n",
      "Epoch 4/10\n",
      "23/23 [==============================] - 0s 860us/step - loss: 1.6471\n",
      "Epoch 5/10\n",
      "23/23 [==============================] - 0s 884us/step - loss: 1.6357\n",
      "Epoch 6/10\n",
      "23/23 [==============================] - 0s 832us/step - loss: 1.6116\n",
      "Epoch 7/10\n",
      "23/23 [==============================] - 0s 880us/step - loss: 1.6029\n",
      "Epoch 8/10\n",
      "23/23 [==============================] - 0s 833us/step - loss: 1.5920\n",
      "Epoch 9/10\n",
      "23/23 [==============================] - 0s 862us/step - loss: 1.5749\n",
      "Epoch 10/10\n",
      "23/23 [==============================] - 0s 824us/step - loss: 1.5593\n",
      "12/12 [==============================] - 0s 640us/step\n",
      "Epoch 1/10\n",
      "23/23 [==============================] - 0s 780us/step - loss: 1.6304\n",
      "Epoch 2/10\n",
      "23/23 [==============================] - 0s 731us/step - loss: 1.6119\n",
      "Epoch 3/10\n",
      "23/23 [==============================] - 0s 728us/step - loss: 1.5942\n",
      "Epoch 4/10\n",
      "23/23 [==============================] - 0s 697us/step - loss: 1.5775\n",
      "Epoch 5/10\n",
      "23/23 [==============================] - 0s 761us/step - loss: 1.5612\n",
      "Epoch 6/10\n",
      "23/23 [==============================] - 0s 711us/step - loss: 1.5458\n",
      "Epoch 7/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 725us/step - loss: 1.5310\n",
      "Epoch 8/10\n",
      "23/23 [==============================] - 0s 776us/step - loss: 1.5165\n",
      "Epoch 9/10\n",
      "23/23 [==============================] - 0s 722us/step - loss: 1.5030\n",
      "Epoch 10/10\n",
      "23/23 [==============================] - 0s 745us/step - loss: 1.4897\n",
      "12/12 [==============================] - 0s 672us/step\n",
      "Epoch 1/10\n",
      "23/23 [==============================] - 0s 847us/step - loss: 1.6813\n",
      "Epoch 2/10\n",
      "23/23 [==============================] - 0s 707us/step - loss: 1.6612\n",
      "Epoch 3/10\n",
      "23/23 [==============================] - 0s 726us/step - loss: 1.6421\n",
      "Epoch 4/10\n",
      "23/23 [==============================] - 0s 711us/step - loss: 1.6240\n",
      "Epoch 5/10\n",
      "23/23 [==============================] - 0s 741us/step - loss: 1.6063\n",
      "Epoch 6/10\n",
      "23/23 [==============================] - 0s 721us/step - loss: 1.5895\n",
      "Epoch 7/10\n",
      "23/23 [==============================] - 0s 754us/step - loss: 1.5736\n",
      "Epoch 8/10\n",
      "23/23 [==============================] - 0s 738us/step - loss: 1.5583\n",
      "Epoch 9/10\n",
      "23/23 [==============================] - 0s 767us/step - loss: 1.5435\n",
      "Epoch 10/10\n",
      "23/23 [==============================] - 0s 749us/step - loss: 1.5296\n",
      "12/12 [==============================] - 0s 742us/step\n",
      "Epoch 1/10\n",
      "23/23 [==============================] - 0s 880us/step - loss: 1.7908\n",
      "Epoch 2/10\n",
      "23/23 [==============================] - 0s 746us/step - loss: 1.7703\n",
      "Epoch 3/10\n",
      "23/23 [==============================] - 0s 724us/step - loss: 1.7508\n",
      "Epoch 4/10\n",
      "23/23 [==============================] - 0s 728us/step - loss: 1.7318\n",
      "Epoch 5/10\n",
      "23/23 [==============================] - 0s 689us/step - loss: 1.7132\n",
      "Epoch 6/10\n",
      "23/23 [==============================] - 0s 750us/step - loss: 1.6961\n",
      "Epoch 7/10\n",
      "23/23 [==============================] - 0s 762us/step - loss: 1.6786\n",
      "Epoch 8/10\n",
      "23/23 [==============================] - 0s 746us/step - loss: 1.6623\n",
      "Epoch 9/10\n",
      "23/23 [==============================] - 0s 742us/step - loss: 1.6461\n",
      "Epoch 10/10\n",
      "23/23 [==============================] - 0s 722us/step - loss: 1.6306\n",
      "12/12 [==============================] - 0s 723us/step\n",
      "Epoch 1/10\n",
      "23/23 [==============================] - 0s 957us/step - loss: 1.6914\n",
      "Epoch 2/10\n",
      "23/23 [==============================] - 0s 732us/step - loss: 1.6180\n",
      "Epoch 3/10\n",
      "23/23 [==============================] - 0s 716us/step - loss: 1.5607\n",
      "Epoch 4/10\n",
      "23/23 [==============================] - 0s 719us/step - loss: 1.5151\n",
      "Epoch 5/10\n",
      "23/23 [==============================] - 0s 683us/step - loss: 1.4775\n",
      "Epoch 6/10\n",
      "23/23 [==============================] - 0s 705us/step - loss: 1.4456\n",
      "Epoch 7/10\n",
      "23/23 [==============================] - 0s 689us/step - loss: 1.4185\n",
      "Epoch 8/10\n",
      "23/23 [==============================] - 0s 712us/step - loss: 1.3947\n",
      "Epoch 9/10\n",
      "23/23 [==============================] - 0s 725us/step - loss: 1.3733\n",
      "Epoch 10/10\n",
      "23/23 [==============================] - 0s 679us/step - loss: 1.3542\n",
      "12/12 [==============================] - 0s 700us/step\n",
      "Epoch 1/10\n",
      "23/23 [==============================] - 0s 931us/step - loss: 1.8449\n",
      "Epoch 2/10\n",
      "23/23 [==============================] - 0s 881us/step - loss: 1.7529\n",
      "Epoch 3/10\n",
      "23/23 [==============================] - 0s 671us/step - loss: 1.6765\n",
      "Epoch 4/10\n",
      "23/23 [==============================] - 0s 741us/step - loss: 1.6125\n",
      "Epoch 5/10\n",
      "23/23 [==============================] - 0s 696us/step - loss: 1.5581\n",
      "Epoch 6/10\n",
      "23/23 [==============================] - 0s 821us/step - loss: 1.5119\n",
      "Epoch 7/10\n",
      "23/23 [==============================] - 0s 681us/step - loss: 1.4736\n",
      "Epoch 8/10\n",
      "23/23 [==============================] - 0s 678us/step - loss: 1.4424\n",
      "Epoch 9/10\n",
      "23/23 [==============================] - 0s 750us/step - loss: 1.4158\n",
      "Epoch 10/10\n",
      "23/23 [==============================] - 0s 738us/step - loss: 1.3925\n",
      "12/12 [==============================] - 0s 578us/step\n",
      "Epoch 1/10\n",
      "23/23 [==============================] - 0s 729us/step - loss: 1.7621\n",
      "Epoch 2/10\n",
      "23/23 [==============================] - 0s 948us/step - loss: 1.6734\n",
      "Epoch 3/10\n",
      "23/23 [==============================] - 0s 718us/step - loss: 1.6026\n",
      "Epoch 4/10\n",
      "23/23 [==============================] - 0s 671us/step - loss: 1.5449\n",
      "Epoch 5/10\n",
      "23/23 [==============================] - 0s 685us/step - loss: 1.4976\n",
      "Epoch 6/10\n",
      "23/23 [==============================] - 0s 711us/step - loss: 1.4582\n",
      "Epoch 7/10\n",
      "23/23 [==============================] - 0s 735us/step - loss: 1.4253\n",
      "Epoch 8/10\n",
      "23/23 [==============================] - 0s 727us/step - loss: 1.3976\n",
      "Epoch 9/10\n",
      "23/23 [==============================] - 0s 690us/step - loss: 1.3735\n",
      "Epoch 10/10\n",
      "23/23 [==============================] - 0s 689us/step - loss: 1.3527\n",
      "12/12 [==============================] - 0s 660us/step\n",
      "Epoch 1/10\n",
      "69/69 [==============================] - 0s 732us/step - loss: 1.4934\n",
      "Epoch 2/10\n",
      "69/69 [==============================] - 0s 647us/step - loss: 1.3654\n",
      "Epoch 3/10\n",
      "69/69 [==============================] - 0s 634us/step - loss: 1.2987\n",
      "Epoch 4/10\n",
      "69/69 [==============================] - 0s 639us/step - loss: 1.2560\n",
      "Epoch 5/10\n",
      "69/69 [==============================] - 0s 647us/step - loss: 1.2231\n",
      "Epoch 6/10\n",
      "69/69 [==============================] - 0s 648us/step - loss: 1.1949\n",
      "Epoch 7/10\n",
      "69/69 [==============================] - 0s 631us/step - loss: 1.1704\n",
      "Epoch 8/10\n",
      "69/69 [==============================] - 0s 633us/step - loss: 1.1475\n",
      "Epoch 9/10\n",
      "69/69 [==============================] - 0s 649us/step - loss: 1.1268\n",
      "Epoch 10/10\n",
      "69/69 [==============================] - 0s 674us/step - loss: 1.1072\n",
      "35/35 [==============================] - 0s 566us/step\n",
      "Epoch 1/10\n",
      "69/69 [==============================] - 0s 683us/step - loss: 1.6440\n",
      "Epoch 2/10\n",
      "69/69 [==============================] - 0s 615us/step - loss: 1.4734\n",
      "Epoch 3/10\n",
      "69/69 [==============================] - 0s 667us/step - loss: 1.3742\n",
      "Epoch 4/10\n",
      "69/69 [==============================] - 0s 666us/step - loss: 1.3146\n",
      "Epoch 5/10\n",
      "69/69 [==============================] - 0s 668us/step - loss: 1.2714\n",
      "Epoch 6/10\n",
      "69/69 [==============================] - 0s 667us/step - loss: 1.2371\n",
      "Epoch 7/10\n",
      "69/69 [==============================] - 0s 652us/step - loss: 1.2085\n",
      "Epoch 8/10\n",
      "69/69 [==============================] - 0s 666us/step - loss: 1.1840\n",
      "Epoch 9/10\n",
      "69/69 [==============================] - 0s 670us/step - loss: 1.1618\n",
      "Epoch 10/10\n",
      "69/69 [==============================] - 0s 657us/step - loss: 1.1426\n",
      "35/35 [==============================] - 0s 570us/step\n",
      "Epoch 1/10\n",
      "69/69 [==============================] - 0s 676us/step - loss: 1.5327\n",
      "Epoch 2/10\n",
      "69/69 [==============================] - 0s 635us/step - loss: 1.4131\n",
      "Epoch 3/10\n",
      "69/69 [==============================] - 0s 655us/step - loss: 1.3377\n",
      "Epoch 4/10\n",
      "69/69 [==============================] - 0s 673us/step - loss: 1.2852\n",
      "Epoch 5/10\n",
      "69/69 [==============================] - 0s 659us/step - loss: 1.2450\n",
      "Epoch 6/10\n",
      "69/69 [==============================] - 0s 663us/step - loss: 1.2127\n",
      "Epoch 7/10\n",
      "69/69 [==============================] - 0s 661us/step - loss: 1.1853\n",
      "Epoch 8/10\n",
      "69/69 [==============================] - 0s 666us/step - loss: 1.1609\n",
      "Epoch 9/10\n",
      "69/69 [==============================] - 0s 685us/step - loss: 1.1395\n",
      "Epoch 10/10\n",
      "69/69 [==============================] - 0s 677us/step - loss: 1.1202\n",
      "35/35 [==============================] - 0s 580us/step\n",
      "Epoch 1/10\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 1.5778\n",
      "Epoch 2/10\n",
      "69/69 [==============================] - 0s 932us/step - loss: 1.5126\n",
      "Epoch 3/10\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 1.4615\n",
      "Epoch 4/10\n",
      "69/69 [==============================] - 0s 933us/step - loss: 1.4047\n",
      "Epoch 5/10\n",
      "69/69 [==============================] - 0s 936us/step - loss: 1.3527\n",
      "Epoch 6/10\n",
      "69/69 [==============================] - 0s 930us/step - loss: 1.3147\n",
      "Epoch 7/10\n",
      "69/69 [==============================] - 0s 920us/step - loss: 1.2772\n",
      "Epoch 8/10\n",
      "69/69 [==============================] - 0s 930us/step - loss: 1.2450\n",
      "Epoch 9/10\n",
      "69/69 [==============================] - 0s 941us/step - loss: 1.2076\n",
      "Epoch 10/10\n",
      "69/69 [==============================] - 0s 920us/step - loss: 1.1825\n",
      "35/35 [==============================] - 0s 841us/step\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69/69 [==============================] - 0s 978us/step - loss: 1.5150\n",
      "Epoch 2/10\n",
      "69/69 [==============================] - 0s 946us/step - loss: 1.4513\n",
      "Epoch 3/10\n",
      "69/69 [==============================] - 0s 947us/step - loss: 1.4133\n",
      "Epoch 4/10\n",
      "69/69 [==============================] - 0s 989us/step - loss: 1.3630\n",
      "Epoch 5/10\n",
      "69/69 [==============================] - 0s 950us/step - loss: 1.3227\n",
      "Epoch 6/10\n",
      "69/69 [==============================] - 0s 949us/step - loss: 1.2911\n",
      "Epoch 7/10\n",
      "69/69 [==============================] - 0s 961us/step - loss: 1.2609\n",
      "Epoch 8/10\n",
      "69/69 [==============================] - 0s 946us/step - loss: 1.2331\n",
      "Epoch 9/10\n",
      "69/69 [==============================] - 0s 969us/step - loss: 1.2097\n",
      "Epoch 10/10\n",
      "69/69 [==============================] - 0s 948us/step - loss: 1.1900\n",
      "35/35 [==============================] - 0s 632us/step\n",
      "Epoch 1/10\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 1.7191\n",
      "Epoch 2/10\n",
      "69/69 [==============================] - 0s 979us/step - loss: 1.6090\n",
      "Epoch 3/10\n",
      "69/69 [==============================] - 0s 984us/step - loss: 1.5247\n",
      "Epoch 4/10\n",
      "69/69 [==============================] - 0s 978us/step - loss: 1.4544\n",
      "Epoch 5/10\n",
      "69/69 [==============================] - 0s 942us/step - loss: 1.3946\n",
      "Epoch 6/10\n",
      "69/69 [==============================] - 0s 928us/step - loss: 1.3473\n",
      "Epoch 7/10\n",
      "69/69 [==============================] - 0s 968us/step - loss: 1.3013\n",
      "Epoch 8/10\n",
      "69/69 [==============================] - 0s 962us/step - loss: 1.2714\n",
      "Epoch 9/10\n",
      "69/69 [==============================] - 0s 947us/step - loss: 1.2312\n",
      "Epoch 10/10\n",
      "69/69 [==============================] - 0s 946us/step - loss: 1.2094\n",
      "35/35 [==============================] - 0s 621us/step\n",
      "Epoch 1/10\n",
      "69/69 [==============================] - 0s 697us/step - loss: 1.5111\n",
      "Epoch 2/10\n",
      "69/69 [==============================] - 0s 672us/step - loss: 1.5109\n",
      "Epoch 3/10\n",
      "69/69 [==============================] - 0s 702us/step - loss: 1.5147\n",
      "Epoch 4/10\n",
      "69/69 [==============================] - 0s 694us/step - loss: 1.5042\n",
      "Epoch 5/10\n",
      "69/69 [==============================] - 0s 682us/step - loss: 1.5067\n",
      "Epoch 6/10\n",
      "69/69 [==============================] - 0s 676us/step - loss: 1.5007\n",
      "Epoch 7/10\n",
      "69/69 [==============================] - 0s 670us/step - loss: 1.5045\n",
      "Epoch 8/10\n",
      "69/69 [==============================] - 0s 680us/step - loss: 1.5006\n",
      "Epoch 9/10\n",
      "69/69 [==============================] - 0s 700us/step - loss: 1.4985\n",
      "Epoch 10/10\n",
      "69/69 [==============================] - 0s 670us/step - loss: 1.5026\n",
      "35/35 [==============================] - 0s 546us/step\n",
      "Epoch 1/10\n",
      "69/69 [==============================] - 0s 676us/step - loss: 1.8105\n",
      "Epoch 2/10\n",
      "69/69 [==============================] - 0s 688us/step - loss: 1.8108\n",
      "Epoch 3/10\n",
      "69/69 [==============================] - 0s 721us/step - loss: 1.8112\n",
      "Epoch 4/10\n",
      "69/69 [==============================] - 0s 701us/step - loss: 1.8017\n",
      "Epoch 5/10\n",
      "69/69 [==============================] - 0s 696us/step - loss: 1.7924\n",
      "Epoch 6/10\n",
      "69/69 [==============================] - 0s 720us/step - loss: 1.7963\n",
      "Epoch 7/10\n",
      "69/69 [==============================] - 0s 731us/step - loss: 1.7867\n",
      "Epoch 8/10\n",
      "69/69 [==============================] - 0s 709us/step - loss: 1.7863\n",
      "Epoch 9/10\n",
      "69/69 [==============================] - 0s 702us/step - loss: 1.7777\n",
      "Epoch 10/10\n",
      "69/69 [==============================] - 0s 704us/step - loss: 1.7782\n",
      "35/35 [==============================] - 0s 599us/step\n",
      "Epoch 1/10\n",
      "69/69 [==============================] - 0s 688us/step - loss: 1.7397\n",
      "Epoch 2/10\n",
      "69/69 [==============================] - 0s 698us/step - loss: 1.7327\n",
      "Epoch 3/10\n",
      "69/69 [==============================] - 0s 697us/step - loss: 1.7311\n",
      "Epoch 4/10\n",
      "69/69 [==============================] - 0s 746us/step - loss: 1.7326\n",
      "Epoch 5/10\n",
      "69/69 [==============================] - 0s 706us/step - loss: 1.7299\n",
      "Epoch 6/10\n",
      "69/69 [==============================] - 0s 711us/step - loss: 1.7248\n",
      "Epoch 7/10\n",
      "69/69 [==============================] - 0s 716us/step - loss: 1.7181\n",
      "Epoch 8/10\n",
      "69/69 [==============================] - 0s 718us/step - loss: 1.7114\n",
      "Epoch 9/10\n",
      "69/69 [==============================] - 0s 712us/step - loss: 1.7123\n",
      "Epoch 10/10\n",
      "69/69 [==============================] - 0s 707us/step - loss: 1.7094\n",
      "35/35 [==============================] - 0s 612us/step\n",
      "Epoch 1/10\n",
      "14/14 [==============================] - 0s 995us/step - loss: 1.9061\n",
      "Epoch 2/10\n",
      "14/14 [==============================] - 0s 852us/step - loss: 1.8944\n",
      "Epoch 3/10\n",
      "14/14 [==============================] - 0s 792us/step - loss: 1.8829\n",
      "Epoch 4/10\n",
      "14/14 [==============================] - 0s 750us/step - loss: 1.8716\n",
      "Epoch 5/10\n",
      "14/14 [==============================] - 0s 772us/step - loss: 1.8606\n",
      "Epoch 6/10\n",
      "14/14 [==============================] - 0s 708us/step - loss: 1.8497\n",
      "Epoch 7/10\n",
      "14/14 [==============================] - 0s 789us/step - loss: 1.8392\n",
      "Epoch 8/10\n",
      "14/14 [==============================] - 0s 815us/step - loss: 1.8288\n",
      "Epoch 9/10\n",
      "14/14 [==============================] - 0s 752us/step - loss: 1.8186\n",
      "Epoch 10/10\n",
      "14/14 [==============================] - 0s 757us/step - loss: 1.8087\n",
      "7/7 [==============================] - 0s 883us/step\n",
      "Epoch 1/10\n",
      "14/14 [==============================] - 0s 880us/step - loss: 1.6370\n",
      "Epoch 2/10\n",
      "14/14 [==============================] - 0s 798us/step - loss: 1.6321\n",
      "Epoch 3/10\n",
      "14/14 [==============================] - 0s 771us/step - loss: 1.6272\n",
      "Epoch 4/10\n",
      "14/14 [==============================] - 0s 803us/step - loss: 1.6225\n",
      "Epoch 5/10\n",
      "14/14 [==============================] - 0s 775us/step - loss: 1.6178\n",
      "Epoch 6/10\n",
      "14/14 [==============================] - 0s 809us/step - loss: 1.6131\n",
      "Epoch 7/10\n",
      "14/14 [==============================] - 0s 829us/step - loss: 1.6085\n",
      "Epoch 8/10\n",
      "14/14 [==============================] - 0s 786us/step - loss: 1.6040\n",
      "Epoch 9/10\n",
      "14/14 [==============================] - 0s 768us/step - loss: 1.5996\n",
      "Epoch 10/10\n",
      "14/14 [==============================] - 0s 747us/step - loss: 1.5952\n",
      "7/7 [==============================] - 0s 929us/step\n",
      "Epoch 1/10\n",
      "14/14 [==============================] - 0s 941us/step - loss: 1.7488\n",
      "Epoch 2/10\n",
      "14/14 [==============================] - 0s 889us/step - loss: 1.7420\n",
      "Epoch 3/10\n",
      "14/14 [==============================] - 0s 819us/step - loss: 1.7355\n",
      "Epoch 4/10\n",
      "14/14 [==============================] - 0s 864us/step - loss: 1.7290\n",
      "Epoch 5/10\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 1.7227\n",
      "Epoch 6/10\n",
      "14/14 [==============================] - 0s 925us/step - loss: 1.7164\n",
      "Epoch 7/10\n",
      "14/14 [==============================] - 0s 879us/step - loss: 1.7103\n",
      "Epoch 8/10\n",
      "14/14 [==============================] - 0s 800us/step - loss: 1.7042\n",
      "Epoch 9/10\n",
      "14/14 [==============================] - 0s 822us/step - loss: 1.6983\n",
      "Epoch 10/10\n",
      "14/14 [==============================] - 0s 762us/step - loss: 1.6925\n",
      "7/7 [==============================] - 0s 926us/step\n",
      "Epoch 1/10\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 1.6639\n",
      "Epoch 2/10\n",
      "14/14 [==============================] - 0s 750us/step - loss: 1.6477\n",
      "Epoch 3/10\n",
      "14/14 [==============================] - 0s 843us/step - loss: 1.6320\n",
      "Epoch 4/10\n",
      "14/14 [==============================] - 0s 880us/step - loss: 1.6172\n",
      "Epoch 5/10\n",
      "14/14 [==============================] - 0s 792us/step - loss: 1.6025\n",
      "Epoch 6/10\n",
      "14/14 [==============================] - 0s 843us/step - loss: 1.5886\n",
      "Epoch 7/10\n",
      "14/14 [==============================] - 0s 846us/step - loss: 1.5750\n",
      "Epoch 8/10\n",
      "14/14 [==============================] - 0s 850us/step - loss: 1.5618\n",
      "Epoch 9/10\n",
      "14/14 [==============================] - 0s 851us/step - loss: 1.5492\n",
      "Epoch 10/10\n",
      "14/14 [==============================] - 0s 858us/step - loss: 1.5368\n",
      "7/7 [==============================] - 0s 797us/step\n",
      "Epoch 1/10\n",
      "14/14 [==============================] - 0s 995us/step - loss: 1.6994\n",
      "Epoch 2/10\n",
      "14/14 [==============================] - 0s 845us/step - loss: 1.6851\n",
      "Epoch 3/10\n",
      "14/14 [==============================] - 0s 869us/step - loss: 1.6714\n",
      "Epoch 4/10\n",
      "14/14 [==============================] - 0s 777us/step - loss: 1.6580\n",
      "Epoch 5/10\n",
      "14/14 [==============================] - 0s 777us/step - loss: 1.6447\n",
      "Epoch 6/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 816us/step - loss: 1.6317\n",
      "Epoch 7/10\n",
      "14/14 [==============================] - 0s 871us/step - loss: 1.6192\n",
      "Epoch 8/10\n",
      "14/14 [==============================] - 0s 898us/step - loss: 1.6068\n",
      "Epoch 9/10\n",
      "14/14 [==============================] - 0s 842us/step - loss: 1.5948\n",
      "Epoch 10/10\n",
      "14/14 [==============================] - 0s 784us/step - loss: 1.5833\n",
      "7/7 [==============================] - 0s 802us/step\n",
      "Epoch 1/10\n",
      "14/14 [==============================] - 0s 922us/step - loss: 1.7714\n",
      "Epoch 2/10\n",
      "14/14 [==============================] - 0s 889us/step - loss: 1.7537\n",
      "Epoch 3/10\n",
      "14/14 [==============================] - 0s 875us/step - loss: 1.7365\n",
      "Epoch 4/10\n",
      "14/14 [==============================] - 0s 806us/step - loss: 1.7197\n",
      "Epoch 5/10\n",
      "14/14 [==============================] - 0s 831us/step - loss: 1.7034\n",
      "Epoch 6/10\n",
      "14/14 [==============================] - 0s 864us/step - loss: 1.6878\n",
      "Epoch 7/10\n",
      "14/14 [==============================] - 0s 845us/step - loss: 1.6721\n",
      "Epoch 8/10\n",
      "14/14 [==============================] - 0s 885us/step - loss: 1.6573\n",
      "Epoch 9/10\n",
      "14/14 [==============================] - 0s 748us/step - loss: 1.6426\n",
      "Epoch 10/10\n",
      "14/14 [==============================] - 0s 797us/step - loss: 1.6287\n",
      "7/7 [==============================] - 0s 744us/step\n",
      "Epoch 1/10\n",
      "69/69 [==============================] - 0s 721us/step - loss: 1.1097\n",
      "Epoch 2/10\n",
      "69/69 [==============================] - 0s 686us/step - loss: 0.8500\n",
      "Epoch 3/10\n",
      "69/69 [==============================] - 0s 698us/step - loss: 0.7707\n",
      "Epoch 4/10\n",
      "69/69 [==============================] - 0s 708us/step - loss: 0.7303\n",
      "Epoch 5/10\n",
      "69/69 [==============================] - 0s 706us/step - loss: 0.6897\n",
      "Epoch 6/10\n",
      "69/69 [==============================] - 0s 707us/step - loss: 0.6679\n",
      "Epoch 7/10\n",
      "69/69 [==============================] - 0s 707us/step - loss: 0.6664\n",
      "Epoch 8/10\n",
      "69/69 [==============================] - 0s 705us/step - loss: 0.6572\n",
      "Epoch 9/10\n",
      "69/69 [==============================] - 0s 710us/step - loss: 0.6174\n",
      "Epoch 10/10\n",
      "69/69 [==============================] - 0s 712us/step - loss: 0.6168\n",
      "35/35 [==============================] - 0s 604us/step\n",
      "Epoch 1/10\n",
      "69/69 [==============================] - 0s 712us/step - loss: 1.1440\n",
      "Epoch 2/10\n",
      "69/69 [==============================] - 0s 708us/step - loss: 0.8811\n",
      "Epoch 3/10\n",
      "69/69 [==============================] - 0s 708us/step - loss: 0.8000\n",
      "Epoch 4/10\n",
      "69/69 [==============================] - 0s 705us/step - loss: 0.7643\n",
      "Epoch 5/10\n",
      "69/69 [==============================] - 0s 720us/step - loss: 0.7371\n",
      "Epoch 6/10\n",
      "69/69 [==============================] - 0s 689us/step - loss: 0.7027\n",
      "Epoch 7/10\n",
      "69/69 [==============================] - 0s 696us/step - loss: 0.6695\n",
      "Epoch 8/10\n",
      "69/69 [==============================] - 0s 711us/step - loss: 0.6731\n",
      "Epoch 9/10\n",
      "69/69 [==============================] - 0s 702us/step - loss: 0.6480\n",
      "Epoch 10/10\n",
      "69/69 [==============================] - 0s 723us/step - loss: 0.6544\n",
      "35/35 [==============================] - 0s 580us/step\n",
      "Epoch 1/10\n",
      "69/69 [==============================] - 0s 747us/step - loss: 1.1763\n",
      "Epoch 2/10\n",
      "69/69 [==============================] - 0s 701us/step - loss: 0.9100\n",
      "Epoch 3/10\n",
      "69/69 [==============================] - 0s 687us/step - loss: 0.8283\n",
      "Epoch 4/10\n",
      "69/69 [==============================] - 0s 690us/step - loss: 0.7486\n",
      "Epoch 5/10\n",
      "69/69 [==============================] - 0s 702us/step - loss: 0.7267\n",
      "Epoch 6/10\n",
      "69/69 [==============================] - 0s 679us/step - loss: 0.6970\n",
      "Epoch 7/10\n",
      "69/69 [==============================] - 0s 691us/step - loss: 0.6905\n",
      "Epoch 8/10\n",
      "69/69 [==============================] - 0s 699us/step - loss: 0.6528\n",
      "Epoch 9/10\n",
      "69/69 [==============================] - 0s 702us/step - loss: 0.6518\n",
      "Epoch 10/10\n",
      "69/69 [==============================] - 0s 692us/step - loss: 0.6550\n",
      "35/35 [==============================] - 0s 598us/step\n",
      "Epoch 1/10\n",
      "69/69 [==============================] - 0s 731us/step - loss: 1.7180\n",
      "Epoch 2/10\n",
      "69/69 [==============================] - 0s 673us/step - loss: 1.6983\n",
      "Epoch 3/10\n",
      "69/69 [==============================] - 0s 655us/step - loss: 1.6792\n",
      "Epoch 4/10\n",
      "69/69 [==============================] - 0s 660us/step - loss: 1.6612\n",
      "Epoch 5/10\n",
      "69/69 [==============================] - 0s 665us/step - loss: 1.6441\n",
      "Epoch 6/10\n",
      "69/69 [==============================] - 0s 664us/step - loss: 1.6275\n",
      "Epoch 7/10\n",
      "69/69 [==============================] - 0s 655us/step - loss: 1.6115\n",
      "Epoch 8/10\n",
      "69/69 [==============================] - 0s 647us/step - loss: 1.5964\n",
      "Epoch 9/10\n",
      "69/69 [==============================] - 0s 672us/step - loss: 1.5819\n",
      "Epoch 10/10\n",
      "69/69 [==============================] - 0s 655us/step - loss: 1.5679\n",
      "35/35 [==============================] - 0s 842us/step\n",
      "Epoch 1/10\n",
      "69/69 [==============================] - 0s 660us/step - loss: 1.6395\n",
      "Epoch 2/10\n",
      "69/69 [==============================] - 0s 651us/step - loss: 1.6190\n",
      "Epoch 3/10\n",
      "69/69 [==============================] - 0s 676us/step - loss: 1.5996\n",
      "Epoch 4/10\n",
      "69/69 [==============================] - 0s 724us/step - loss: 1.5816\n",
      "Epoch 5/10\n",
      "69/69 [==============================] - 0s 668us/step - loss: 1.5645\n",
      "Epoch 6/10\n",
      "69/69 [==============================] - 0s 670us/step - loss: 1.5482\n",
      "Epoch 7/10\n",
      "69/69 [==============================] - 0s 662us/step - loss: 1.5327\n",
      "Epoch 8/10\n",
      "69/69 [==============================] - 0s 653us/step - loss: 1.5181\n",
      "Epoch 9/10\n",
      "69/69 [==============================] - 0s 661us/step - loss: 1.5044\n",
      "Epoch 10/10\n",
      "69/69 [==============================] - 0s 672us/step - loss: 1.4913\n",
      "35/35 [==============================] - 0s 575us/step\n",
      "Epoch 1/10\n",
      "69/69 [==============================] - 0s 683us/step - loss: 1.6674\n",
      "Epoch 2/10\n",
      "69/69 [==============================] - 0s 661us/step - loss: 1.6476\n",
      "Epoch 3/10\n",
      "69/69 [==============================] - 0s 672us/step - loss: 1.6293\n",
      "Epoch 4/10\n",
      "69/69 [==============================] - 0s 682us/step - loss: 1.6119\n",
      "Epoch 5/10\n",
      "69/69 [==============================] - 0s 669us/step - loss: 1.5956\n",
      "Epoch 6/10\n",
      "69/69 [==============================] - 0s 706us/step - loss: 1.5804\n",
      "Epoch 7/10\n",
      "69/69 [==============================] - 0s 685us/step - loss: 1.5658\n",
      "Epoch 8/10\n",
      "69/69 [==============================] - 0s 662us/step - loss: 1.5523\n",
      "Epoch 9/10\n",
      "69/69 [==============================] - 0s 676us/step - loss: 1.5394\n",
      "Epoch 10/10\n",
      "69/69 [==============================] - 0s 677us/step - loss: 1.5272\n",
      "35/35 [==============================] - 0s 612us/step\n",
      "Epoch 1/10\n",
      "23/23 [==============================] - 0s 938us/step - loss: 1.3198\n",
      "Epoch 2/10\n",
      "23/23 [==============================] - 0s 826us/step - loss: 1.0735\n",
      "Epoch 3/10\n",
      "23/23 [==============================] - 0s 828us/step - loss: 0.9508\n",
      "Epoch 4/10\n",
      "23/23 [==============================] - 0s 806us/step - loss: 0.8870\n",
      "Epoch 5/10\n",
      "23/23 [==============================] - 0s 805us/step - loss: 0.8332\n",
      "Epoch 6/10\n",
      "23/23 [==============================] - 0s 822us/step - loss: 0.8186\n",
      "Epoch 7/10\n",
      "23/23 [==============================] - 0s 797us/step - loss: 0.7815\n",
      "Epoch 8/10\n",
      "23/23 [==============================] - 0s 869us/step - loss: 0.7706\n",
      "Epoch 9/10\n",
      "23/23 [==============================] - 0s 810us/step - loss: 0.7452\n",
      "Epoch 10/10\n",
      "23/23 [==============================] - 0s 818us/step - loss: 0.7235\n",
      "12/12 [==============================] - 0s 735us/step\n",
      "Epoch 1/10\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 1.3006\n",
      "Epoch 2/10\n",
      "23/23 [==============================] - 0s 828us/step - loss: 1.0584\n",
      "Epoch 3/10\n",
      "23/23 [==============================] - 0s 808us/step - loss: 0.9480\n",
      "Epoch 4/10\n",
      "23/23 [==============================] - 0s 800us/step - loss: 0.8936\n",
      "Epoch 5/10\n",
      "23/23 [==============================] - 0s 789us/step - loss: 0.8427\n",
      "Epoch 6/10\n",
      "23/23 [==============================] - 0s 822us/step - loss: 0.8092\n",
      "Epoch 7/10\n",
      "23/23 [==============================] - 0s 798us/step - loss: 0.7815\n",
      "Epoch 8/10\n",
      "23/23 [==============================] - 0s 800us/step - loss: 0.7509\n",
      "Epoch 9/10\n",
      "23/23 [==============================] - 0s 791us/step - loss: 0.7469\n",
      "Epoch 10/10\n",
      "23/23 [==============================] - 0s 822us/step - loss: 0.7397\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 685us/step\n",
      "Epoch 1/10\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 1.3326\n",
      "Epoch 2/10\n",
      "23/23 [==============================] - 0s 818us/step - loss: 1.0665\n",
      "Epoch 3/10\n",
      "23/23 [==============================] - 0s 920us/step - loss: 0.9659\n",
      "Epoch 4/10\n",
      "23/23 [==============================] - 0s 936us/step - loss: 0.8879\n",
      "Epoch 5/10\n",
      "23/23 [==============================] - 0s 790us/step - loss: 0.8396\n",
      "Epoch 6/10\n",
      "23/23 [==============================] - 0s 800us/step - loss: 0.7988\n",
      "Epoch 7/10\n",
      "23/23 [==============================] - 0s 846us/step - loss: 0.7971\n",
      "Epoch 8/10\n",
      "23/23 [==============================] - 0s 836us/step - loss: 0.7652\n",
      "Epoch 9/10\n",
      "23/23 [==============================] - 0s 796us/step - loss: 0.7506\n",
      "Epoch 10/10\n",
      "23/23 [==============================] - 0s 783us/step - loss: 0.7385\n",
      "12/12 [==============================] - 0s 752us/step\n",
      "Epoch 1/10\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 1.3584\n",
      "Epoch 2/10\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 1.0791\n",
      "Epoch 3/10\n",
      "14/14 [==============================] - 0s 998us/step - loss: 0.9727\n",
      "Epoch 4/10\n",
      "14/14 [==============================] - 0s 984us/step - loss: 0.9020\n",
      "Epoch 5/10\n",
      "14/14 [==============================] - 0s 917us/step - loss: 0.8576\n",
      "Epoch 6/10\n",
      "14/14 [==============================] - 0s 888us/step - loss: 0.8166\n",
      "Epoch 7/10\n",
      "14/14 [==============================] - 0s 967us/step - loss: 0.7845\n",
      "Epoch 8/10\n",
      "14/14 [==============================] - 0s 932us/step - loss: 0.7650\n",
      "Epoch 9/10\n",
      "14/14 [==============================] - 0s 959us/step - loss: 0.7578\n",
      "Epoch 10/10\n",
      "14/14 [==============================] - 0s 988us/step - loss: 0.7529\n",
      "7/7 [==============================] - 0s 835us/step\n",
      "Epoch 1/10\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 1.4452\n",
      "Epoch 2/10\n",
      "14/14 [==============================] - 0s 935us/step - loss: 1.1421\n",
      "Epoch 3/10\n",
      "14/14 [==============================] - 0s 936us/step - loss: 1.0038\n",
      "Epoch 4/10\n",
      "14/14 [==============================] - 0s 946us/step - loss: 0.9275\n",
      "Epoch 5/10\n",
      "14/14 [==============================] - 0s 937us/step - loss: 0.8703\n",
      "Epoch 6/10\n",
      "14/14 [==============================] - 0s 992us/step - loss: 0.8346\n",
      "Epoch 7/10\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.7933\n",
      "Epoch 8/10\n",
      "14/14 [==============================] - 0s 973us/step - loss: 0.7893\n",
      "Epoch 9/10\n",
      "14/14 [==============================] - 0s 934us/step - loss: 0.7605\n",
      "Epoch 10/10\n",
      "14/14 [==============================] - 0s 968us/step - loss: 0.7549\n",
      "7/7 [==============================] - 0s 945us/step\n",
      "Epoch 1/10\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 1.3645\n",
      "Epoch 2/10\n",
      "14/14 [==============================] - 0s 922us/step - loss: 1.0996\n",
      "Epoch 3/10\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 1.0013\n",
      "Epoch 4/10\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.9201\n",
      "Epoch 5/10\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.8669\n",
      "Epoch 6/10\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.8248\n",
      "Epoch 7/10\n",
      "14/14 [==============================] - 0s 985us/step - loss: 0.8172\n",
      "Epoch 8/10\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.7987\n",
      "Epoch 9/10\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.7627\n",
      "Epoch 10/10\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.7516\n",
      "7/7 [==============================] - 0s 860us/step\n",
      "Epoch 1/10\n",
      "23/23 [==============================] - 0s 979us/step - loss: 1.6816\n",
      "Epoch 2/10\n",
      "23/23 [==============================] - 0s 863us/step - loss: 1.6807\n",
      "Epoch 3/10\n",
      "23/23 [==============================] - 0s 865us/step - loss: 1.6797\n",
      "Epoch 4/10\n",
      "23/23 [==============================] - 0s 888us/step - loss: 1.6788\n",
      "Epoch 5/10\n",
      "23/23 [==============================] - 0s 884us/step - loss: 1.6778\n",
      "Epoch 6/10\n",
      "23/23 [==============================] - 0s 889us/step - loss: 1.6769\n",
      "Epoch 7/10\n",
      "23/23 [==============================] - 0s 926us/step - loss: 1.6760\n",
      "Epoch 8/10\n",
      "23/23 [==============================] - 0s 912us/step - loss: 1.6750\n",
      "Epoch 9/10\n",
      "23/23 [==============================] - 0s 931us/step - loss: 1.6741\n",
      "Epoch 10/10\n",
      "23/23 [==============================] - 0s 888us/step - loss: 1.6732\n",
      "12/12 [==============================] - 0s 763us/step\n",
      "Epoch 1/10\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 1.6679\n",
      "Epoch 2/10\n",
      "23/23 [==============================] - 0s 837us/step - loss: 1.6670\n",
      "Epoch 3/10\n",
      "23/23 [==============================] - 0s 881us/step - loss: 1.6661\n",
      "Epoch 4/10\n",
      "23/23 [==============================] - 0s 876us/step - loss: 1.6652\n",
      "Epoch 5/10\n",
      "23/23 [==============================] - 0s 882us/step - loss: 1.6643\n",
      "Epoch 6/10\n",
      "23/23 [==============================] - 0s 980us/step - loss: 1.6635\n",
      "Epoch 7/10\n",
      "23/23 [==============================] - 0s 981us/step - loss: 1.6626\n",
      "Epoch 8/10\n",
      "23/23 [==============================] - 0s 980us/step - loss: 1.6617\n",
      "Epoch 9/10\n",
      "23/23 [==============================] - 0s 1000us/step - loss: 1.6609\n",
      "Epoch 10/10\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 1.6600\n",
      "12/12 [==============================] - 0s 1ms/step\n",
      "Epoch 1/10\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 1.6318\n",
      "Epoch 2/10\n",
      "23/23 [==============================] - 0s 895us/step - loss: 1.6311\n",
      "Epoch 3/10\n",
      "23/23 [==============================] - 0s 962us/step - loss: 1.6305\n",
      "Epoch 4/10\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 1.6298\n",
      "Epoch 5/10\n",
      "23/23 [==============================] - 0s 881us/step - loss: 1.6292\n",
      "Epoch 6/10\n",
      "23/23 [==============================] - 0s 892us/step - loss: 1.6286\n",
      "Epoch 7/10\n",
      "23/23 [==============================] - 0s 984us/step - loss: 1.6279\n",
      "Epoch 8/10\n",
      "23/23 [==============================] - 0s 906us/step - loss: 1.6273\n",
      "Epoch 9/10\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 1.6267\n",
      "Epoch 10/10\n",
      "23/23 [==============================] - 0s 985us/step - loss: 1.6260\n",
      "12/12 [==============================] - 0s 1ms/step\n",
      "Epoch 1/10\n",
      "69/69 [==============================] - 0s 703us/step - loss: 1.7131\n",
      "Epoch 2/10\n",
      "69/69 [==============================] - 0s 723us/step - loss: 1.5421\n",
      "Epoch 3/10\n",
      "69/69 [==============================] - 0s 783us/step - loss: 1.4361\n",
      "Epoch 4/10\n",
      "69/69 [==============================] - 0s 841us/step - loss: 1.3681\n",
      "Epoch 5/10\n",
      "69/69 [==============================] - 0s 851us/step - loss: 1.3216\n",
      "Epoch 6/10\n",
      "69/69 [==============================] - 0s 853us/step - loss: 1.2716\n",
      "Epoch 7/10\n",
      "69/69 [==============================] - 0s 931us/step - loss: 1.2340\n",
      "Epoch 8/10\n",
      "69/69 [==============================] - 0s 906us/step - loss: 1.2190\n",
      "Epoch 9/10\n",
      "69/69 [==============================] - 0s 849us/step - loss: 1.1861\n",
      "Epoch 10/10\n",
      "69/69 [==============================] - 0s 885us/step - loss: 1.1677\n",
      "35/35 [==============================] - 0s 756us/step\n",
      "Epoch 1/10\n",
      "69/69 [==============================] - 0s 705us/step - loss: 1.5448\n",
      "Epoch 2/10\n",
      "69/69 [==============================] - 0s 672us/step - loss: 1.4113\n",
      "Epoch 3/10\n",
      "69/69 [==============================] - 0s 712us/step - loss: 1.3311\n",
      "Epoch 4/10\n",
      "69/69 [==============================] - 0s 907us/step - loss: 1.2902\n",
      "Epoch 5/10\n",
      "69/69 [==============================] - 0s 899us/step - loss: 1.2503\n",
      "Epoch 6/10\n",
      "69/69 [==============================] - 0s 888us/step - loss: 1.2187\n",
      "Epoch 7/10\n",
      "69/69 [==============================] - 0s 912us/step - loss: 1.1928\n",
      "Epoch 8/10\n",
      "69/69 [==============================] - 0s 911us/step - loss: 1.1671\n",
      "Epoch 9/10\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 1.1487\n",
      "Epoch 10/10\n",
      "69/69 [==============================] - 0s 937us/step - loss: 1.1276\n",
      "35/35 [==============================] - 0s 780us/step\n",
      "Epoch 1/10\n",
      "69/69 [==============================] - 0s 721us/step - loss: 1.7496\n",
      "Epoch 2/10\n",
      "69/69 [==============================] - 0s 689us/step - loss: 1.5261\n",
      "Epoch 3/10\n",
      "69/69 [==============================] - 0s 770us/step - loss: 1.4279\n",
      "Epoch 4/10\n",
      "69/69 [==============================] - 0s 851us/step - loss: 1.3644\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69/69 [==============================] - 0s 909us/step - loss: 1.3144\n",
      "Epoch 6/10\n",
      "69/69 [==============================] - 0s 858us/step - loss: 1.2881\n",
      "Epoch 7/10\n",
      "69/69 [==============================] - 0s 872us/step - loss: 1.2449\n",
      "Epoch 8/10\n",
      "69/69 [==============================] - 0s 903us/step - loss: 1.2306\n",
      "Epoch 9/10\n",
      "69/69 [==============================] - 0s 913us/step - loss: 1.2157\n",
      "Epoch 10/10\n",
      "69/69 [==============================] - 0s 922us/step - loss: 1.1825\n",
      "35/35 [==============================] - 0s 819us/step\n",
      "Epoch 1/10\n",
      "23/23 [==============================] - 0s 905us/step - loss: 1.5712\n",
      "Epoch 2/10\n",
      "23/23 [==============================] - 0s 720us/step - loss: 1.5644\n",
      "Epoch 3/10\n",
      "23/23 [==============================] - 0s 701us/step - loss: 1.5576\n",
      "Epoch 4/10\n",
      "23/23 [==============================] - 0s 685us/step - loss: 1.5510\n",
      "Epoch 5/10\n",
      "23/23 [==============================] - 0s 693us/step - loss: 1.5446\n",
      "Epoch 6/10\n",
      "23/23 [==============================] - 0s 679us/step - loss: 1.5382\n",
      "Epoch 7/10\n",
      "23/23 [==============================] - 0s 678us/step - loss: 1.5320\n",
      "Epoch 8/10\n",
      "23/23 [==============================] - 0s 689us/step - loss: 1.5260\n",
      "Epoch 9/10\n",
      "23/23 [==============================] - 0s 699us/step - loss: 1.5200\n",
      "Epoch 10/10\n",
      "23/23 [==============================] - 0s 704us/step - loss: 1.5142\n",
      "12/12 [==============================] - 0s 820us/step\n",
      "Epoch 1/10\n",
      "23/23 [==============================] - 0s 737us/step - loss: 1.7143\n",
      "Epoch 2/10\n",
      "23/23 [==============================] - 0s 710us/step - loss: 1.7056\n",
      "Epoch 3/10\n",
      "23/23 [==============================] - 0s 686us/step - loss: 1.6970\n",
      "Epoch 4/10\n",
      "23/23 [==============================] - 0s 723us/step - loss: 1.6887\n",
      "Epoch 5/10\n",
      "23/23 [==============================] - 0s 743us/step - loss: 1.6806\n",
      "Epoch 6/10\n",
      "23/23 [==============================] - 0s 768us/step - loss: 1.6726\n",
      "Epoch 7/10\n",
      "23/23 [==============================] - 0s 739us/step - loss: 1.6649\n",
      "Epoch 8/10\n",
      "23/23 [==============================] - 0s 793us/step - loss: 1.6573\n",
      "Epoch 9/10\n",
      "23/23 [==============================] - 0s 804us/step - loss: 1.6499\n",
      "Epoch 10/10\n",
      "23/23 [==============================] - 0s 903us/step - loss: 1.6427\n",
      "12/12 [==============================] - 0s 1ms/step\n",
      "Epoch 1/10\n",
      "23/23 [==============================] - 0s 787us/step - loss: 1.6280\n",
      "Epoch 2/10\n",
      "23/23 [==============================] - 0s 731us/step - loss: 1.6202\n",
      "Epoch 3/10\n",
      "23/23 [==============================] - 0s 799us/step - loss: 1.6126\n",
      "Epoch 4/10\n",
      "23/23 [==============================] - 0s 811us/step - loss: 1.6052\n",
      "Epoch 5/10\n",
      "23/23 [==============================] - 0s 849us/step - loss: 1.5980\n",
      "Epoch 6/10\n",
      "23/23 [==============================] - 0s 832us/step - loss: 1.5910\n",
      "Epoch 7/10\n",
      "23/23 [==============================] - 0s 821us/step - loss: 1.5842\n",
      "Epoch 8/10\n",
      "23/23 [==============================] - 0s 788us/step - loss: 1.5775\n",
      "Epoch 9/10\n",
      "23/23 [==============================] - 0s 853us/step - loss: 1.5710\n",
      "Epoch 10/10\n",
      "23/23 [==============================] - 0s 996us/step - loss: 1.5647\n",
      "12/12 [==============================] - 0s 986us/step\n",
      "Epoch 1/10\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 1.6468\n",
      "Epoch 2/10\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 1.6248\n",
      "Epoch 3/10\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 1.5984\n",
      "Epoch 4/10\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 1.5867\n",
      "Epoch 5/10\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 1.5571\n",
      "Epoch 6/10\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 1.5393\n",
      "Epoch 7/10\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 1.5242\n",
      "Epoch 8/10\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 1.5081\n",
      "Epoch 9/10\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 1.4862\n",
      "Epoch 10/10\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 1.4716\n",
      "7/7 [==============================] - 0s 1ms/step\n",
      "Epoch 1/10\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 1.6971\n",
      "Epoch 2/10\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 1.6664\n",
      "Epoch 3/10\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 1.6340\n",
      "Epoch 4/10\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 1.6097\n",
      "Epoch 5/10\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 1.5809\n",
      "Epoch 6/10\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 1.5620\n",
      "Epoch 7/10\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 1.5359\n",
      "Epoch 8/10\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 1.5085\n",
      "Epoch 9/10\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 1.4968\n",
      "Epoch 10/10\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 1.4780\n",
      "7/7 [==============================] - 0s 1ms/step\n",
      "Epoch 1/10\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 1.5810\n",
      "Epoch 2/10\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 1.5533\n",
      "Epoch 3/10\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 1.5385\n",
      "Epoch 4/10\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 1.5202\n",
      "Epoch 5/10\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 1.4959\n",
      "Epoch 6/10\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 1.4805\n",
      "Epoch 7/10\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 1.4722\n",
      "Epoch 8/10\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 1.4544\n",
      "Epoch 9/10\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 1.4385\n",
      "Epoch 10/10\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 1.4272\n",
      "7/7 [==============================] - 0s 1ms/step\n",
      "Epoch 1/10\n",
      "69/69 [==============================] - 0s 873us/step - loss: 1.5091\n",
      "Epoch 2/10\n",
      "69/69 [==============================] - 0s 755us/step - loss: 1.2992\n",
      "Epoch 3/10\n",
      "69/69 [==============================] - 0s 789us/step - loss: 1.1833\n",
      "Epoch 4/10\n",
      "69/69 [==============================] - 0s 876us/step - loss: 1.1100\n",
      "Epoch 5/10\n",
      "69/69 [==============================] - 0s 935us/step - loss: 1.0578\n",
      "Epoch 6/10\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 1.0198\n",
      "Epoch 7/10\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.9761\n",
      "Epoch 8/10\n",
      "69/69 [==============================] - 0s 973us/step - loss: 0.9467\n",
      "Epoch 9/10\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.9277\n",
      "Epoch 10/10\n",
      "69/69 [==============================] - 0s 981us/step - loss: 0.9096\n",
      "35/35 [==============================] - 0s 775us/step\n",
      "Epoch 1/10\n",
      "69/69 [==============================] - 0s 820us/step - loss: 1.5563\n",
      "Epoch 2/10\n",
      "69/69 [==============================] - 0s 742us/step - loss: 1.3087\n",
      "Epoch 3/10\n",
      "69/69 [==============================] - 0s 787us/step - loss: 1.2069\n",
      "Epoch 4/10\n",
      "69/69 [==============================] - 0s 946us/step - loss: 1.1209\n",
      "Epoch 5/10\n",
      "69/69 [==============================] - 0s 956us/step - loss: 1.0744\n",
      "Epoch 6/10\n",
      "69/69 [==============================] - 0s 996us/step - loss: 1.0396\n",
      "Epoch 7/10\n",
      "69/69 [==============================] - 0s 993us/step - loss: 0.9998\n",
      "Epoch 8/10\n",
      "69/69 [==============================] - 0s 992us/step - loss: 0.9813\n",
      "Epoch 9/10\n",
      "69/69 [==============================] - 0s 983us/step - loss: 0.9507\n",
      "Epoch 10/10\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.9241\n",
      "35/35 [==============================] - 0s 699us/step\n",
      "Epoch 1/10\n",
      "69/69 [==============================] - 1s 796us/step - loss: 1.5386\n",
      "Epoch 2/10\n",
      "69/69 [==============================] - 0s 746us/step - loss: 1.3227\n",
      "Epoch 3/10\n",
      "69/69 [==============================] - 0s 732us/step - loss: 1.2063\n",
      "Epoch 4/10\n",
      "69/69 [==============================] - 0s 771us/step - loss: 1.1347\n",
      "Epoch 5/10\n",
      "69/69 [==============================] - 0s 773us/step - loss: 1.0774\n",
      "Epoch 6/10\n",
      "69/69 [==============================] - 0s 824us/step - loss: 1.0464\n",
      "Epoch 7/10\n",
      "69/69 [==============================] - 0s 933us/step - loss: 1.0126\n",
      "Epoch 8/10\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.9844\n",
      "Epoch 9/10\n",
      "69/69 [==============================] - 0s 932us/step - loss: 0.9467\n",
      "Epoch 10/10\n",
      "69/69 [==============================] - 0s 984us/step - loss: 0.9300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 0s 798us/step\n",
      "Epoch 1/10\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 1.7383\n",
      "Epoch 2/10\n",
      "23/23 [==============================] - 0s 725us/step - loss: 1.6498\n",
      "Epoch 3/10\n",
      "23/23 [==============================] - 0s 757us/step - loss: 1.5776\n",
      "Epoch 4/10\n",
      "23/23 [==============================] - 0s 734us/step - loss: 1.5195\n",
      "Epoch 5/10\n",
      "23/23 [==============================] - 0s 774us/step - loss: 1.4719\n",
      "Epoch 6/10\n",
      "23/23 [==============================] - 0s 733us/step - loss: 1.4322\n",
      "Epoch 7/10\n",
      "23/23 [==============================] - 0s 781us/step - loss: 1.3989\n",
      "Epoch 8/10\n",
      "23/23 [==============================] - 0s 789us/step - loss: 1.3704\n",
      "Epoch 9/10\n",
      "23/23 [==============================] - 0s 798us/step - loss: 1.3453\n",
      "Epoch 10/10\n",
      "23/23 [==============================] - 0s 893us/step - loss: 1.3233\n",
      "12/12 [==============================] - 0s 1ms/step\n",
      "Epoch 1/10\n",
      "23/23 [==============================] - 0s 783us/step - loss: 1.6186\n",
      "Epoch 2/10\n",
      "23/23 [==============================] - 0s 725us/step - loss: 1.5556\n",
      "Epoch 3/10\n",
      "23/23 [==============================] - 0s 731us/step - loss: 1.5028\n",
      "Epoch 4/10\n",
      "23/23 [==============================] - 0s 701us/step - loss: 1.4586\n",
      "Epoch 5/10\n",
      "23/23 [==============================] - 0s 777us/step - loss: 1.4215\n",
      "Epoch 6/10\n",
      "23/23 [==============================] - 0s 736us/step - loss: 1.3898\n",
      "Epoch 7/10\n",
      "23/23 [==============================] - 0s 814us/step - loss: 1.3627\n",
      "Epoch 8/10\n",
      "23/23 [==============================] - 0s 868us/step - loss: 1.3396\n",
      "Epoch 9/10\n",
      "23/23 [==============================] - 0s 809us/step - loss: 1.3195\n",
      "Epoch 10/10\n",
      "23/23 [==============================] - 0s 837us/step - loss: 1.3019\n",
      "12/12 [==============================] - 0s 898us/step\n",
      "Epoch 1/10\n",
      "23/23 [==============================] - 0s 932us/step - loss: 1.6311\n",
      "Epoch 2/10\n",
      "23/23 [==============================] - 0s 773us/step - loss: 1.5679\n",
      "Epoch 3/10\n",
      "23/23 [==============================] - 0s 722us/step - loss: 1.5162\n",
      "Epoch 4/10\n",
      "23/23 [==============================] - 0s 764us/step - loss: 1.4731\n",
      "Epoch 5/10\n",
      "23/23 [==============================] - 0s 769us/step - loss: 1.4380\n",
      "Epoch 6/10\n",
      "23/23 [==============================] - 0s 740us/step - loss: 1.4093\n",
      "Epoch 7/10\n",
      "23/23 [==============================] - 0s 760us/step - loss: 1.3851\n",
      "Epoch 8/10\n",
      "23/23 [==============================] - 0s 828us/step - loss: 1.3639\n",
      "Epoch 9/10\n",
      "23/23 [==============================] - 0s 887us/step - loss: 1.3450\n",
      "Epoch 10/10\n",
      "23/23 [==============================] - 0s 876us/step - loss: 1.3281\n",
      "12/12 [==============================] - 0s 939us/step\n",
      "Epoch 1/10\n",
      "69/69 [==============================] - 0s 858us/step - loss: 1.6501\n",
      "Epoch 2/10\n",
      "69/69 [==============================] - 0s 892us/step - loss: 1.6473\n",
      "Epoch 3/10\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 1.6416\n",
      "Epoch 4/10\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 1.6423\n",
      "Epoch 5/10\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 1.6485\n",
      "Epoch 6/10\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 1.6337\n",
      "Epoch 7/10\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 1.6394\n",
      "Epoch 8/10\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 1.6323\n",
      "Epoch 9/10\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 1.6355\n",
      "Epoch 10/10\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 1.6291\n",
      "35/35 [==============================] - 0s 833us/step\n",
      "Epoch 1/10\n",
      "69/69 [==============================] - 0s 858us/step - loss: 1.6064\n",
      "Epoch 2/10\n",
      "69/69 [==============================] - 0s 847us/step - loss: 1.6046\n",
      "Epoch 3/10\n",
      "69/69 [==============================] - 0s 999us/step - loss: 1.5943\n",
      "Epoch 4/10\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 1.6007\n",
      "Epoch 5/10\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 1.5919\n",
      "Epoch 6/10\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 1.5975\n",
      "Epoch 7/10\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 1.5942\n",
      "Epoch 8/10\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 1.5866\n",
      "Epoch 9/10\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 1.5825\n",
      "Epoch 10/10\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 1.5809\n",
      "35/35 [==============================] - 0s 861us/step\n",
      "Epoch 1/10\n",
      "69/69 [==============================] - 0s 848us/step - loss: 1.6320\n",
      "Epoch 2/10\n",
      "69/69 [==============================] - 0s 811us/step - loss: 1.6228\n",
      "Epoch 3/10\n",
      "69/69 [==============================] - 0s 877us/step - loss: 1.6208\n",
      "Epoch 4/10\n",
      "69/69 [==============================] - 0s 934us/step - loss: 1.6225\n",
      "Epoch 5/10\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 1.6253\n",
      "Epoch 6/10\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 1.6188\n",
      "Epoch 7/10\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 1.6168\n",
      "Epoch 8/10\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 1.6183\n",
      "Epoch 9/10\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 1.6135\n",
      "Epoch 10/10\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 1.6160\n",
      "35/35 [==============================] - 0s 809us/step\n",
      "Epoch 1/10\n",
      "69/69 [==============================] - 0s 853us/step - loss: 1.3576\n",
      "Epoch 2/10\n",
      "69/69 [==============================] - 0s 824us/step - loss: 1.0998\n",
      "Epoch 3/10\n",
      "69/69 [==============================] - 0s 831us/step - loss: 0.9610\n",
      "Epoch 4/10\n",
      "69/69 [==============================] - 0s 875us/step - loss: 0.8809\n",
      "Epoch 5/10\n",
      "69/69 [==============================] - 0s 932us/step - loss: 0.8194\n",
      "Epoch 6/10\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.7763\n",
      "Epoch 7/10\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.7474\n",
      "Epoch 8/10\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.7142\n",
      "Epoch 9/10\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.6897\n",
      "Epoch 10/10\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.6785\n",
      "35/35 [==============================] - 0s 765us/step\n",
      "Epoch 1/10\n",
      "69/69 [==============================] - 0s 837us/step - loss: 1.3645\n",
      "Epoch 2/10\n",
      "69/69 [==============================] - 0s 839us/step - loss: 1.0992\n",
      "Epoch 3/10\n",
      "69/69 [==============================] - 0s 845us/step - loss: 0.9691\n",
      "Epoch 4/10\n",
      "69/69 [==============================] - 0s 859us/step - loss: 0.8834\n",
      "Epoch 5/10\n",
      "69/69 [==============================] - 0s 891us/step - loss: 0.8293\n",
      "Epoch 6/10\n",
      "69/69 [==============================] - 0s 993us/step - loss: 0.7853\n",
      "Epoch 7/10\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.7480\n",
      "Epoch 8/10\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.7229\n",
      "Epoch 9/10\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.6997\n",
      "Epoch 10/10\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.6841\n",
      "35/35 [==============================] - 0s 735us/step\n",
      "Epoch 1/10\n",
      "69/69 [==============================] - 0s 839us/step - loss: 1.3513\n",
      "Epoch 2/10\n",
      "69/69 [==============================] - 0s 846us/step - loss: 1.1056\n",
      "Epoch 3/10\n",
      "69/69 [==============================] - 0s 900us/step - loss: 0.9827\n",
      "Epoch 4/10\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.8969\n",
      "Epoch 5/10\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.8428\n",
      "Epoch 6/10\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.7963\n",
      "Epoch 7/10\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.7614\n",
      "Epoch 8/10\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.7295\n",
      "Epoch 9/10\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.7011\n",
      "Epoch 10/10\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.6851\n",
      "35/35 [==============================] - 0s 765us/step\n",
      "Epoch 1/10\n",
      "23/23 [==============================] - 0s 799us/step - loss: 1.7114\n",
      "Epoch 2/10\n",
      "23/23 [==============================] - 0s 728us/step - loss: 1.6373\n",
      "Epoch 3/10\n",
      "23/23 [==============================] - 0s 749us/step - loss: 1.5700\n",
      "Epoch 4/10\n",
      "23/23 [==============================] - 0s 794us/step - loss: 1.5218\n",
      "Epoch 5/10\n",
      "23/23 [==============================] - 0s 792us/step - loss: 1.4814\n",
      "Epoch 6/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 825us/step - loss: 1.4586\n",
      "Epoch 7/10\n",
      "23/23 [==============================] - 0s 738us/step - loss: 1.4246\n",
      "Epoch 8/10\n",
      "23/23 [==============================] - 0s 837us/step - loss: 1.3983\n",
      "Epoch 9/10\n",
      "23/23 [==============================] - 0s 944us/step - loss: 1.3789\n",
      "Epoch 10/10\n",
      "23/23 [==============================] - 0s 925us/step - loss: 1.3667\n",
      "12/12 [==============================] - 0s 783us/step\n",
      "Epoch 1/10\n",
      "23/23 [==============================] - 0s 768us/step - loss: 1.6668\n",
      "Epoch 2/10\n",
      "23/23 [==============================] - 0s 750us/step - loss: 1.5938\n",
      "Epoch 3/10\n",
      "23/23 [==============================] - 0s 730us/step - loss: 1.5398\n",
      "Epoch 4/10\n",
      "23/23 [==============================] - 0s 750us/step - loss: 1.4878\n",
      "Epoch 5/10\n",
      "23/23 [==============================] - 0s 750us/step - loss: 1.4592\n",
      "Epoch 6/10\n",
      "23/23 [==============================] - 0s 750us/step - loss: 1.4270\n",
      "Epoch 7/10\n",
      "23/23 [==============================] - 0s 795us/step - loss: 1.3974\n",
      "Epoch 8/10\n",
      "23/23 [==============================] - 0s 822us/step - loss: 1.3728\n",
      "Epoch 9/10\n",
      "23/23 [==============================] - 0s 909us/step - loss: 1.3555\n",
      "Epoch 10/10\n",
      "23/23 [==============================] - 0s 978us/step - loss: 1.3358\n",
      "12/12 [==============================] - 0s 865us/step\n",
      "Epoch 1/10\n",
      "23/23 [==============================] - 0s 773us/step - loss: 1.7699\n",
      "Epoch 2/10\n",
      "23/23 [==============================] - 0s 729us/step - loss: 1.6857\n",
      "Epoch 3/10\n",
      "23/23 [==============================] - 0s 750us/step - loss: 1.6311\n",
      "Epoch 4/10\n",
      "23/23 [==============================] - 0s 768us/step - loss: 1.5823\n",
      "Epoch 5/10\n",
      "23/23 [==============================] - 0s 773us/step - loss: 1.5434\n",
      "Epoch 6/10\n",
      "23/23 [==============================] - 0s 811us/step - loss: 1.4997\n",
      "Epoch 7/10\n",
      "23/23 [==============================] - 0s 786us/step - loss: 1.4700\n",
      "Epoch 8/10\n",
      "23/23 [==============================] - 0s 860us/step - loss: 1.4411\n",
      "Epoch 9/10\n",
      "23/23 [==============================] - 0s 865us/step - loss: 1.4183\n",
      "Epoch 10/10\n",
      "23/23 [==============================] - 0s 933us/step - loss: 1.3956\n",
      "12/12 [==============================] - 0s 797us/step\n",
      "Epoch 1/10\n",
      "23/23 [==============================] - 0s 798us/step - loss: 1.7079\n",
      "Epoch 2/10\n",
      "23/23 [==============================] - 0s 753us/step - loss: 1.6158\n",
      "Epoch 3/10\n",
      "23/23 [==============================] - 0s 781us/step - loss: 1.5475\n",
      "Epoch 4/10\n",
      "23/23 [==============================] - 0s 773us/step - loss: 1.4918\n",
      "Epoch 5/10\n",
      "23/23 [==============================] - 0s 773us/step - loss: 1.4498\n",
      "Epoch 6/10\n",
      "23/23 [==============================] - 0s 794us/step - loss: 1.4089\n",
      "Epoch 7/10\n",
      "23/23 [==============================] - 0s 785us/step - loss: 1.3706\n",
      "Epoch 8/10\n",
      "23/23 [==============================] - 0s 841us/step - loss: 1.3488\n",
      "Epoch 9/10\n",
      "23/23 [==============================] - 0s 932us/step - loss: 1.3285\n",
      "Epoch 10/10\n",
      "23/23 [==============================] - 0s 889us/step - loss: 1.3121\n",
      "12/12 [==============================] - 0s 818us/step\n",
      "Epoch 1/10\n",
      "23/23 [==============================] - 0s 866us/step - loss: 1.7656\n",
      "Epoch 2/10\n",
      "23/23 [==============================] - 0s 734us/step - loss: 1.6572\n",
      "Epoch 3/10\n",
      "23/23 [==============================] - 0s 743us/step - loss: 1.5836\n",
      "Epoch 4/10\n",
      "23/23 [==============================] - 0s 750us/step - loss: 1.5212\n",
      "Epoch 5/10\n",
      "23/23 [==============================] - 0s 775us/step - loss: 1.4734\n",
      "Epoch 6/10\n",
      "23/23 [==============================] - 0s 777us/step - loss: 1.4333\n",
      "Epoch 7/10\n",
      "23/23 [==============================] - 0s 796us/step - loss: 1.4003\n",
      "Epoch 8/10\n",
      "23/23 [==============================] - 0s 886us/step - loss: 1.3708\n",
      "Epoch 9/10\n",
      "23/23 [==============================] - 0s 932us/step - loss: 1.3574\n",
      "Epoch 10/10\n",
      "23/23 [==============================] - 0s 958us/step - loss: 1.3319\n",
      "12/12 [==============================] - 0s 738us/step\n",
      "Epoch 1/10\n",
      "23/23 [==============================] - 0s 849us/step - loss: 1.8101\n",
      "Epoch 2/10\n",
      "23/23 [==============================] - 0s 763us/step - loss: 1.7083\n",
      "Epoch 3/10\n",
      "23/23 [==============================] - 0s 777us/step - loss: 1.6256\n",
      "Epoch 4/10\n",
      "23/23 [==============================] - 0s 800us/step - loss: 1.5633\n",
      "Epoch 5/10\n",
      "23/23 [==============================] - 0s 779us/step - loss: 1.5041\n",
      "Epoch 6/10\n",
      "23/23 [==============================] - 0s 795us/step - loss: 1.4683\n",
      "Epoch 7/10\n",
      "23/23 [==============================] - 0s 795us/step - loss: 1.4402\n",
      "Epoch 8/10\n",
      "23/23 [==============================] - 0s 768us/step - loss: 1.4082\n",
      "Epoch 9/10\n",
      "23/23 [==============================] - 0s 796us/step - loss: 1.3897\n",
      "Epoch 10/10\n",
      "23/23 [==============================] - 0s 761us/step - loss: 1.3612\n",
      "12/12 [==============================] - 0s 779us/step\n",
      "Epoch 1/10\n",
      "14/14 [==============================] - 0s 1000us/step - loss: 1.6153\n",
      "Epoch 2/10\n",
      "14/14 [==============================] - 0s 909us/step - loss: 1.5801\n",
      "Epoch 3/10\n",
      "14/14 [==============================] - 0s 945us/step - loss: 1.5497\n",
      "Epoch 4/10\n",
      "14/14 [==============================] - 0s 915us/step - loss: 1.5226\n",
      "Epoch 5/10\n",
      "14/14 [==============================] - 0s 885us/step - loss: 1.4979\n",
      "Epoch 6/10\n",
      "14/14 [==============================] - 0s 884us/step - loss: 1.4748\n",
      "Epoch 7/10\n",
      "14/14 [==============================] - 0s 923us/step - loss: 1.4534\n",
      "Epoch 8/10\n",
      "14/14 [==============================] - 0s 913us/step - loss: 1.4332\n",
      "Epoch 9/10\n",
      "14/14 [==============================] - 0s 923us/step - loss: 1.4140\n",
      "Epoch 10/10\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 1.3957\n",
      "7/7 [==============================] - 0s 1ms/step\n",
      "Epoch 1/10\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 1.6343\n",
      "Epoch 2/10\n",
      "14/14 [==============================] - 0s 934us/step - loss: 1.5972\n",
      "Epoch 3/10\n",
      "14/14 [==============================] - 0s 885us/step - loss: 1.5654\n",
      "Epoch 4/10\n",
      "14/14 [==============================] - 0s 890us/step - loss: 1.5377\n",
      "Epoch 5/10\n",
      "14/14 [==============================] - 0s 868us/step - loss: 1.5133\n",
      "Epoch 6/10\n",
      "14/14 [==============================] - 0s 914us/step - loss: 1.4909\n",
      "Epoch 7/10\n",
      "14/14 [==============================] - 0s 922us/step - loss: 1.4707\n",
      "Epoch 8/10\n",
      "14/14 [==============================] - 0s 936us/step - loss: 1.4521\n",
      "Epoch 9/10\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 1.4349\n",
      "Epoch 10/10\n",
      "14/14 [==============================] - 0s 924us/step - loss: 1.4188\n",
      "7/7 [==============================] - 0s 1ms/step\n",
      "Epoch 1/10\n",
      "14/14 [==============================] - 0s 1000us/step - loss: 1.6405\n",
      "Epoch 2/10\n",
      "14/14 [==============================] - 0s 995us/step - loss: 1.6041\n",
      "Epoch 3/10\n",
      "14/14 [==============================] - 0s 948us/step - loss: 1.5717\n",
      "Epoch 4/10\n",
      "14/14 [==============================] - 0s 975us/step - loss: 1.5427\n",
      "Epoch 5/10\n",
      "14/14 [==============================] - 0s 943us/step - loss: 1.5164\n",
      "Epoch 6/10\n",
      "14/14 [==============================] - 0s 921us/step - loss: 1.4922\n",
      "Epoch 7/10\n",
      "14/14 [==============================] - 0s 973us/step - loss: 1.4697\n",
      "Epoch 8/10\n",
      "14/14 [==============================] - 0s 998us/step - loss: 1.4488\n",
      "Epoch 9/10\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 1.4291\n",
      "Epoch 10/10\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 1.4104\n",
      "7/7 [==============================] - 0s 1ms/step\n",
      "Epoch 1/10\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 1.6494\n",
      "Epoch 2/10\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 1.6008\n",
      "Epoch 3/10\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 1.5589\n",
      "Epoch 4/10\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 1.5281\n",
      "Epoch 5/10\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 1.4933\n",
      "Epoch 6/10\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 1.4678\n",
      "Epoch 7/10\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 1.4420\n",
      "Epoch 8/10\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 1.4199\n",
      "Epoch 9/10\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 1.4040\n",
      "Epoch 10/10\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 1.3845\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 909us/step\n",
      "Epoch 1/10\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 1.5751\n",
      "Epoch 2/10\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 1.5536\n",
      "Epoch 3/10\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 1.5187\n",
      "Epoch 4/10\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 1.5028\n",
      "Epoch 5/10\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 1.4717\n",
      "Epoch 6/10\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 1.4501\n",
      "Epoch 7/10\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 1.4340\n",
      "Epoch 8/10\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 1.4090\n",
      "Epoch 9/10\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 1.3865\n",
      "Epoch 10/10\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 1.3643\n",
      "12/12 [==============================] - 0s 880us/step\n",
      "Epoch 1/10\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 1.6394\n",
      "Epoch 2/10\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 1.6118\n",
      "Epoch 3/10\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 1.5711\n",
      "Epoch 4/10\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 1.5428\n",
      "Epoch 5/10\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 1.5073\n",
      "Epoch 6/10\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 1.4818\n",
      "Epoch 7/10\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 1.4519\n",
      "Epoch 8/10\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 1.4300\n",
      "Epoch 9/10\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 1.4111\n",
      "Epoch 10/10\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 1.3850\n",
      "12/12 [==============================] - 0s 909us/step\n",
      "Epoch 1/10\n",
      "14/14 [==============================] - 0s 979us/step - loss: 1.7242\n",
      "Epoch 2/10\n",
      "14/14 [==============================] - 0s 884us/step - loss: 1.7172\n",
      "Epoch 3/10\n",
      "14/14 [==============================] - 0s 884us/step - loss: 1.7212\n",
      "Epoch 4/10\n",
      "14/14 [==============================] - 0s 814us/step - loss: 1.7255\n",
      "Epoch 5/10\n",
      "14/14 [==============================] - 0s 888us/step - loss: 1.7185\n",
      "Epoch 6/10\n",
      "14/14 [==============================] - 0s 892us/step - loss: 1.7237\n",
      "Epoch 7/10\n",
      "14/14 [==============================] - 0s 846us/step - loss: 1.7097\n",
      "Epoch 8/10\n",
      "14/14 [==============================] - 0s 883us/step - loss: 1.7199\n",
      "Epoch 9/10\n",
      "14/14 [==============================] - 0s 885us/step - loss: 1.7106\n",
      "Epoch 10/10\n",
      "14/14 [==============================] - 0s 985us/step - loss: 1.7229\n",
      "7/7 [==============================] - 0s 1ms/step\n",
      "Epoch 1/10\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 1.7130\n",
      "Epoch 2/10\n",
      "14/14 [==============================] - 0s 885us/step - loss: 1.7037\n",
      "Epoch 3/10\n",
      "14/14 [==============================] - 0s 898us/step - loss: 1.7056\n",
      "Epoch 4/10\n",
      "14/14 [==============================] - 0s 913us/step - loss: 1.7031\n",
      "Epoch 5/10\n",
      "14/14 [==============================] - 0s 884us/step - loss: 1.7077\n",
      "Epoch 6/10\n",
      "14/14 [==============================] - 0s 829us/step - loss: 1.7129\n",
      "Epoch 7/10\n",
      "14/14 [==============================] - 0s 884us/step - loss: 1.7113\n",
      "Epoch 8/10\n",
      "14/14 [==============================] - 0s 885us/step - loss: 1.7052\n",
      "Epoch 9/10\n",
      "14/14 [==============================] - 0s 926us/step - loss: 1.7005\n",
      "Epoch 10/10\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 1.7073\n",
      "7/7 [==============================] - 0s 1ms/step\n",
      "Epoch 1/10\n",
      "14/14 [==============================] - 0s 923us/step - loss: 1.7006\n",
      "Epoch 2/10\n",
      "14/14 [==============================] - 0s 849us/step - loss: 1.7014\n",
      "Epoch 3/10\n",
      "14/14 [==============================] - 0s 831us/step - loss: 1.7008\n",
      "Epoch 4/10\n",
      "14/14 [==============================] - 0s 879us/step - loss: 1.6936\n",
      "Epoch 5/10\n",
      "14/14 [==============================] - 0s 808us/step - loss: 1.6991\n",
      "Epoch 6/10\n",
      "14/14 [==============================] - 0s 922us/step - loss: 1.6968\n",
      "Epoch 7/10\n",
      "14/14 [==============================] - 0s 833us/step - loss: 1.7014\n",
      "Epoch 8/10\n",
      "14/14 [==============================] - 0s 884us/step - loss: 1.6879\n",
      "Epoch 9/10\n",
      "14/14 [==============================] - 0s 885us/step - loss: 1.6937\n",
      "Epoch 10/10\n",
      "14/14 [==============================] - 0s 888us/step - loss: 1.6991\n",
      "7/7 [==============================] - 0s 1000us/step\n",
      "Epoch 1/10\n",
      "69/69 [==============================] - 0s 971us/step - loss: 1.1004\n",
      "Epoch 2/10\n",
      "69/69 [==============================] - 0s 927us/step - loss: 0.8779\n",
      "Epoch 3/10\n",
      "69/69 [==============================] - 0s 952us/step - loss: 0.7714\n",
      "Epoch 4/10\n",
      "69/69 [==============================] - 0s 974us/step - loss: 0.7445\n",
      "Epoch 5/10\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.7320\n",
      "Epoch 6/10\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.7061\n",
      "Epoch 7/10\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.7215\n",
      "Epoch 8/10\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.6808\n",
      "Epoch 9/10\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.6522\n",
      "Epoch 10/10\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.6496\n",
      "35/35 [==============================] - 0s 735us/step\n",
      "Epoch 1/10\n",
      "69/69 [==============================] - 0s 957us/step - loss: 1.1699\n",
      "Epoch 2/10\n",
      "69/69 [==============================] - 0s 909us/step - loss: 0.9292\n",
      "Epoch 3/10\n",
      "69/69 [==============================] - 0s 948us/step - loss: 0.8228\n",
      "Epoch 4/10\n",
      "69/69 [==============================] - 0s 948us/step - loss: 0.8262\n",
      "Epoch 5/10\n",
      "69/69 [==============================] - 0s 978us/step - loss: 0.7579\n",
      "Epoch 6/10\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.7102\n",
      "Epoch 7/10\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.7076\n",
      "Epoch 8/10\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.6954\n",
      "Epoch 9/10\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.6456\n",
      "Epoch 10/10\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.6448\n",
      "35/35 [==============================] - 0s 735us/step\n",
      "Epoch 1/10\n",
      "69/69 [==============================] - 0s 947us/step - loss: 1.1375\n",
      "Epoch 2/10\n",
      "69/69 [==============================] - 0s 939us/step - loss: 0.9013\n",
      "Epoch 3/10\n",
      "69/69 [==============================] - 0s 951us/step - loss: 0.8385\n",
      "Epoch 4/10\n",
      "69/69 [==============================] - 0s 960us/step - loss: 0.7764\n",
      "Epoch 5/10\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.7575\n",
      "Epoch 6/10\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.7001\n",
      "Epoch 7/10\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.6758\n",
      "Epoch 8/10\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.6381\n",
      "Epoch 9/10\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.6364\n",
      "Epoch 10/10\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.6319\n",
      "35/35 [==============================] - 0s 765us/step\n",
      "Epoch 1/10\n",
      "69/69 [==============================] - 0s 633us/step - loss: 1.6817\n",
      "Epoch 2/10\n",
      "69/69 [==============================] - 0s 666us/step - loss: 1.6672\n",
      "Epoch 3/10\n",
      "69/69 [==============================] - 0s 678us/step - loss: 1.6476\n",
      "Epoch 4/10\n",
      "69/69 [==============================] - 0s 713us/step - loss: 1.6241\n",
      "Epoch 5/10\n",
      "69/69 [==============================] - 0s 767us/step - loss: 1.6050\n",
      "Epoch 6/10\n",
      "69/69 [==============================] - 0s 837us/step - loss: 1.5951\n",
      "Epoch 7/10\n",
      "69/69 [==============================] - 0s 838us/step - loss: 1.5787\n",
      "Epoch 8/10\n",
      "69/69 [==============================] - 0s 868us/step - loss: 1.5694\n",
      "Epoch 9/10\n",
      "69/69 [==============================] - 0s 867us/step - loss: 1.5553\n",
      "Epoch 10/10\n",
      "69/69 [==============================] - 0s 875us/step - loss: 1.5483\n",
      "35/35 [==============================] - 0s 706us/step\n",
      "Epoch 1/10\n",
      "69/69 [==============================] - 0s 660us/step - loss: 1.7919\n",
      "Epoch 2/10\n",
      "69/69 [==============================] - 0s 684us/step - loss: 1.7578\n",
      "Epoch 3/10\n",
      "69/69 [==============================] - 0s 699us/step - loss: 1.7258\n",
      "Epoch 4/10\n",
      "69/69 [==============================] - 0s 706us/step - loss: 1.6925\n",
      "Epoch 5/10\n",
      "69/69 [==============================] - 0s 824us/step - loss: 1.6718\n",
      "Epoch 6/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69/69 [==============================] - 0s 857us/step - loss: 1.6386\n",
      "Epoch 7/10\n",
      "69/69 [==============================] - 0s 858us/step - loss: 1.6263\n",
      "Epoch 8/10\n",
      "69/69 [==============================] - 0s 913us/step - loss: 1.6076\n",
      "Epoch 9/10\n",
      "69/69 [==============================] - 0s 855us/step - loss: 1.5707\n",
      "Epoch 10/10\n",
      "69/69 [==============================] - 0s 867us/step - loss: 1.5598\n",
      "35/35 [==============================] - 0s 644us/step\n",
      "Epoch 1/10\n",
      "69/69 [==============================] - 0s 737us/step - loss: 1.5576\n",
      "Epoch 2/10\n",
      "69/69 [==============================] - 0s 663us/step - loss: 1.5395\n",
      "Epoch 3/10\n",
      "69/69 [==============================] - 0s 669us/step - loss: 1.5278\n",
      "Epoch 4/10\n",
      "69/69 [==============================] - 0s 788us/step - loss: 1.5144\n",
      "Epoch 5/10\n",
      "69/69 [==============================] - 0s 798us/step - loss: 1.5028\n",
      "Epoch 6/10\n",
      "69/69 [==============================] - 0s 838us/step - loss: 1.4996\n",
      "Epoch 7/10\n",
      "69/69 [==============================] - 0s 868us/step - loss: 1.4835\n",
      "Epoch 8/10\n",
      "69/69 [==============================] - 0s 865us/step - loss: 1.4743\n",
      "Epoch 9/10\n",
      "69/69 [==============================] - 0s 856us/step - loss: 1.4644\n",
      "Epoch 10/10\n",
      "69/69 [==============================] - 0s 860us/step - loss: 1.4514\n",
      "35/35 [==============================] - 0s 693us/step\n",
      "Epoch 1/10\n",
      "69/69 [==============================] - 0s 692us/step - loss: 1.5736\n",
      "Epoch 2/10\n",
      "69/69 [==============================] - 0s 654us/step - loss: 1.4333\n",
      "Epoch 3/10\n",
      "69/69 [==============================] - 0s 694us/step - loss: 1.3502\n",
      "Epoch 4/10\n",
      "69/69 [==============================] - 0s 765us/step - loss: 1.2855\n",
      "Epoch 5/10\n",
      "69/69 [==============================] - 0s 824us/step - loss: 1.2408\n",
      "Epoch 6/10\n",
      "69/69 [==============================] - 0s 816us/step - loss: 1.2102\n",
      "Epoch 7/10\n",
      "69/69 [==============================] - 0s 868us/step - loss: 1.1834\n",
      "Epoch 8/10\n",
      "69/69 [==============================] - 0s 869us/step - loss: 1.1543\n",
      "Epoch 9/10\n",
      "69/69 [==============================] - 0s 866us/step - loss: 1.1328\n",
      "Epoch 10/10\n",
      "69/69 [==============================] - 0s 854us/step - loss: 1.1201\n",
      "35/35 [==============================] - 0s 693us/step\n",
      "Epoch 1/10\n",
      "69/69 [==============================] - 0s 667us/step - loss: 1.5370\n",
      "Epoch 2/10\n",
      "69/69 [==============================] - 0s 670us/step - loss: 1.4367\n",
      "Epoch 3/10\n",
      "69/69 [==============================] - 0s 678us/step - loss: 1.3710\n",
      "Epoch 4/10\n",
      "69/69 [==============================] - 0s 788us/step - loss: 1.3184\n",
      "Epoch 5/10\n",
      "69/69 [==============================] - 0s 860us/step - loss: 1.2881\n",
      "Epoch 6/10\n",
      "69/69 [==============================] - 0s 886us/step - loss: 1.2525\n",
      "Epoch 7/10\n",
      "69/69 [==============================] - 0s 917us/step - loss: 1.2321\n",
      "Epoch 8/10\n",
      "69/69 [==============================] - 0s 969us/step - loss: 1.2061\n",
      "Epoch 9/10\n",
      "69/69 [==============================] - 0s 885us/step - loss: 1.1824\n",
      "Epoch 10/10\n",
      "69/69 [==============================] - 0s 844us/step - loss: 1.1631\n",
      "35/35 [==============================] - 0s 685us/step\n",
      "Epoch 1/10\n",
      "69/69 [==============================] - 0s 673us/step - loss: 1.6142\n",
      "Epoch 2/10\n",
      "69/69 [==============================] - 0s 663us/step - loss: 1.4524\n",
      "Epoch 3/10\n",
      "69/69 [==============================] - 0s 690us/step - loss: 1.3672\n",
      "Epoch 4/10\n",
      "69/69 [==============================] - 0s 775us/step - loss: 1.3173\n",
      "Epoch 5/10\n",
      "69/69 [==============================] - 0s 829us/step - loss: 1.2684\n",
      "Epoch 6/10\n",
      "69/69 [==============================] - 0s 873us/step - loss: 1.2414\n",
      "Epoch 7/10\n",
      "69/69 [==============================] - 0s 869us/step - loss: 1.2042\n",
      "Epoch 8/10\n",
      "69/69 [==============================] - 0s 870us/step - loss: 1.1814\n",
      "Epoch 9/10\n",
      "69/69 [==============================] - 0s 859us/step - loss: 1.1601\n",
      "Epoch 10/10\n",
      "69/69 [==============================] - 0s 852us/step - loss: 1.1452\n",
      "35/35 [==============================] - 0s 730us/step\n",
      "Epoch 1/10\n",
      "14/14 [==============================] - 0s 761us/step - loss: 1.6723\n",
      "Epoch 2/10\n",
      "14/14 [==============================] - 0s 755us/step - loss: 1.6664\n",
      "Epoch 3/10\n",
      "14/14 [==============================] - 0s 729us/step - loss: 1.6607\n",
      "Epoch 4/10\n",
      "14/14 [==============================] - 0s 691us/step - loss: 1.6550\n",
      "Epoch 5/10\n",
      "14/14 [==============================] - 0s 701us/step - loss: 1.6494\n",
      "Epoch 6/10\n",
      "14/14 [==============================] - 0s 806us/step - loss: 1.6439\n",
      "Epoch 7/10\n",
      "14/14 [==============================] - 0s 731us/step - loss: 1.6385\n",
      "Epoch 8/10\n",
      "14/14 [==============================] - 0s 731us/step - loss: 1.6332\n",
      "Epoch 9/10\n",
      "14/14 [==============================] - 0s 740us/step - loss: 1.6280\n",
      "Epoch 10/10\n",
      "14/14 [==============================] - 0s 807us/step - loss: 1.6229\n",
      "7/7 [==============================] - 0s 1ms/step\n",
      "Epoch 1/10\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 1.8100\n",
      "Epoch 2/10\n",
      "14/14 [==============================] - 0s 709us/step - loss: 1.8032\n",
      "Epoch 3/10\n",
      "14/14 [==============================] - 0s 768us/step - loss: 1.7963\n",
      "Epoch 4/10\n",
      "14/14 [==============================] - 0s 692us/step - loss: 1.7897\n",
      "Epoch 5/10\n",
      "14/14 [==============================] - 0s 729us/step - loss: 1.7831\n",
      "Epoch 6/10\n",
      "14/14 [==============================] - 0s 855us/step - loss: 1.7767\n",
      "Epoch 7/10\n",
      "14/14 [==============================] - 0s 773us/step - loss: 1.7704\n",
      "Epoch 8/10\n",
      "14/14 [==============================] - 0s 798us/step - loss: 1.7642\n",
      "Epoch 9/10\n",
      "14/14 [==============================] - 0s 807us/step - loss: 1.7580\n",
      "Epoch 10/10\n",
      "14/14 [==============================] - 0s 784us/step - loss: 1.7519\n",
      "7/7 [==============================] - 0s 1ms/step\n",
      "Epoch 1/10\n",
      "14/14 [==============================] - 0s 769us/step - loss: 1.6014\n",
      "Epoch 2/10\n",
      "14/14 [==============================] - 0s 728us/step - loss: 1.5972\n",
      "Epoch 3/10\n",
      "14/14 [==============================] - 0s 731us/step - loss: 1.5931\n",
      "Epoch 4/10\n",
      "14/14 [==============================] - 0s 731us/step - loss: 1.5891\n",
      "Epoch 5/10\n",
      "14/14 [==============================] - 0s 731us/step - loss: 1.5852\n",
      "Epoch 6/10\n",
      "14/14 [==============================] - 0s 806us/step - loss: 1.5813\n",
      "Epoch 7/10\n",
      "14/14 [==============================] - 0s 731us/step - loss: 1.5774\n",
      "Epoch 8/10\n",
      "14/14 [==============================] - 0s 772us/step - loss: 1.5737\n",
      "Epoch 9/10\n",
      "14/14 [==============================] - 0s 833us/step - loss: 1.5700\n",
      "Epoch 10/10\n",
      "14/14 [==============================] - 0s 732us/step - loss: 1.5663\n",
      "7/7 [==============================] - 0s 1ms/step\n",
      "Epoch 1/10\n",
      "14/14 [==============================] - 0s 962us/step - loss: 1.6444\n",
      "Epoch 2/10\n",
      "14/14 [==============================] - 0s 721us/step - loss: 1.6439\n",
      "Epoch 3/10\n",
      "14/14 [==============================] - 0s 731us/step - loss: 1.6435\n",
      "Epoch 4/10\n",
      "14/14 [==============================] - 0s 729us/step - loss: 1.6431\n",
      "Epoch 5/10\n",
      "14/14 [==============================] - 0s 731us/step - loss: 1.6427\n",
      "Epoch 6/10\n",
      "14/14 [==============================] - 0s 730us/step - loss: 1.6423\n",
      "Epoch 7/10\n",
      "14/14 [==============================] - 0s 773us/step - loss: 1.6418\n",
      "Epoch 8/10\n",
      "14/14 [==============================] - 0s 731us/step - loss: 1.6414\n",
      "Epoch 9/10\n",
      "14/14 [==============================] - 0s 806us/step - loss: 1.6410\n",
      "Epoch 10/10\n",
      "14/14 [==============================] - 0s 800us/step - loss: 1.6406\n",
      "7/7 [==============================] - 0s 1000us/step\n",
      "Epoch 1/10\n",
      "14/14 [==============================] - 0s 805us/step - loss: 1.6307\n",
      "Epoch 2/10\n",
      "14/14 [==============================] - 0s 731us/step - loss: 1.6302\n",
      "Epoch 3/10\n",
      "14/14 [==============================] - 0s 769us/step - loss: 1.6297\n",
      "Epoch 4/10\n",
      "14/14 [==============================] - 0s 773us/step - loss: 1.6292\n",
      "Epoch 5/10\n",
      "14/14 [==============================] - 0s 730us/step - loss: 1.6287\n",
      "Epoch 6/10\n",
      "14/14 [==============================] - 0s 729us/step - loss: 1.6282\n",
      "Epoch 7/10\n",
      "14/14 [==============================] - 0s 807us/step - loss: 1.6277\n",
      "Epoch 8/10\n",
      "14/14 [==============================] - 0s 731us/step - loss: 1.6272\n",
      "Epoch 9/10\n",
      "14/14 [==============================] - 0s 806us/step - loss: 1.6267\n",
      "Epoch 10/10\n",
      "14/14 [==============================] - 0s 730us/step - loss: 1.6262\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 833us/step\n",
      "Epoch 1/10\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 1.6972\n",
      "Epoch 2/10\n",
      "14/14 [==============================] - 0s 711us/step - loss: 1.6967\n",
      "Epoch 3/10\n",
      "14/14 [==============================] - 0s 808us/step - loss: 1.6961\n",
      "Epoch 4/10\n",
      "14/14 [==============================] - 0s 705us/step - loss: 1.6956\n",
      "Epoch 5/10\n",
      "14/14 [==============================] - 0s 770us/step - loss: 1.6951\n",
      "Epoch 6/10\n",
      "14/14 [==============================] - 0s 730us/step - loss: 1.6946\n",
      "Epoch 7/10\n",
      "14/14 [==============================] - 0s 730us/step - loss: 1.6941\n",
      "Epoch 8/10\n",
      "14/14 [==============================] - 0s 729us/step - loss: 1.6935\n",
      "Epoch 9/10\n",
      "14/14 [==============================] - 0s 770us/step - loss: 1.6930\n",
      "Epoch 10/10\n",
      "14/14 [==============================] - 0s 781us/step - loss: 1.6925\n",
      "7/7 [==============================] - 0s 1ms/step\n",
      "Epoch 1/10\n",
      "69/69 [==============================] - 0s 699us/step - loss: 1.6777\n",
      "Epoch 2/10\n",
      "69/69 [==============================] - 0s 667us/step - loss: 1.6560\n",
      "Epoch 3/10\n",
      "69/69 [==============================] - 0s 692us/step - loss: 1.6458\n",
      "Epoch 4/10\n",
      "69/69 [==============================] - 0s 807us/step - loss: 1.6280\n",
      "Epoch 5/10\n",
      "69/69 [==============================] - 0s 832us/step - loss: 1.6151\n",
      "Epoch 6/10\n",
      "69/69 [==============================] - 0s 892us/step - loss: 1.5960\n",
      "Epoch 7/10\n",
      "69/69 [==============================] - 0s 866us/step - loss: 1.5824\n",
      "Epoch 8/10\n",
      "69/69 [==============================] - 0s 894us/step - loss: 1.5669\n",
      "Epoch 9/10\n",
      "69/69 [==============================] - 0s 860us/step - loss: 1.5478\n",
      "Epoch 10/10\n",
      "69/69 [==============================] - 0s 888us/step - loss: 1.5350\n",
      "35/35 [==============================] - 0s 692us/step\n",
      "Epoch 1/10\n",
      "69/69 [==============================] - 0s 722us/step - loss: 1.6582\n",
      "Epoch 2/10\n",
      "69/69 [==============================] - 0s 695us/step - loss: 1.6298\n",
      "Epoch 3/10\n",
      "69/69 [==============================] - 0s 699us/step - loss: 1.5975\n",
      "Epoch 4/10\n",
      "69/69 [==============================] - 0s 802us/step - loss: 1.5808\n",
      "Epoch 5/10\n",
      "69/69 [==============================] - 0s 839us/step - loss: 1.5644\n",
      "Epoch 6/10\n",
      "69/69 [==============================] - 0s 860us/step - loss: 1.5516\n",
      "Epoch 7/10\n",
      "69/69 [==============================] - 0s 927us/step - loss: 1.5275\n",
      "Epoch 8/10\n",
      "69/69 [==============================] - 0s 890us/step - loss: 1.5139\n",
      "Epoch 9/10\n",
      "69/69 [==============================] - 0s 899us/step - loss: 1.5083\n",
      "Epoch 10/10\n",
      "69/69 [==============================] - 0s 881us/step - loss: 1.4962\n",
      "35/35 [==============================] - 0s 706us/step\n",
      "Epoch 1/10\n",
      "69/69 [==============================] - 0s 689us/step - loss: 1.7082\n",
      "Epoch 2/10\n",
      "69/69 [==============================] - 0s 698us/step - loss: 1.6819\n",
      "Epoch 3/10\n",
      "69/69 [==============================] - 0s 692us/step - loss: 1.6606\n",
      "Epoch 4/10\n",
      "69/69 [==============================] - 0s 757us/step - loss: 1.6351\n",
      "Epoch 5/10\n",
      "69/69 [==============================] - 0s 883us/step - loss: 1.6054\n",
      "Epoch 6/10\n",
      "69/69 [==============================] - 0s 846us/step - loss: 1.5966\n",
      "Epoch 7/10\n",
      "69/69 [==============================] - 0s 891us/step - loss: 1.5800\n",
      "Epoch 8/10\n",
      "69/69 [==============================] - 0s 872us/step - loss: 1.5636\n",
      "Epoch 9/10\n",
      "69/69 [==============================] - 0s 890us/step - loss: 1.5466\n",
      "Epoch 10/10\n",
      "69/69 [==============================] - 0s 945us/step - loss: 1.5278\n",
      "35/35 [==============================] - 0s 726us/step\n",
      "Epoch 1/10\n",
      "69/69 [==============================] - 0s 699us/step - loss: 1.6264\n",
      "Epoch 2/10\n",
      "69/69 [==============================] - 0s 638us/step - loss: 1.4228\n",
      "Epoch 3/10\n",
      "69/69 [==============================] - 0s 640us/step - loss: 1.3230\n",
      "Epoch 4/10\n",
      "69/69 [==============================] - 0s 728us/step - loss: 1.2635\n",
      "Epoch 5/10\n",
      "69/69 [==============================] - 0s 767us/step - loss: 1.2214\n",
      "Epoch 6/10\n",
      "69/69 [==============================] - 0s 816us/step - loss: 1.1876\n",
      "Epoch 7/10\n",
      "69/69 [==============================] - 0s 801us/step - loss: 1.1605\n",
      "Epoch 8/10\n",
      "69/69 [==============================] - 0s 832us/step - loss: 1.1352\n",
      "Epoch 9/10\n",
      "69/69 [==============================] - 0s 816us/step - loss: 1.1135\n",
      "Epoch 10/10\n",
      "69/69 [==============================] - 0s 839us/step - loss: 1.0939\n",
      "35/35 [==============================] - 0s 691us/step\n",
      "Epoch 1/10\n",
      "69/69 [==============================] - 0s 712us/step - loss: 1.5719\n",
      "Epoch 2/10\n",
      "69/69 [==============================] - 0s 670us/step - loss: 1.4206\n",
      "Epoch 3/10\n",
      "69/69 [==============================] - 0s 734us/step - loss: 1.3348\n",
      "Epoch 4/10\n",
      "69/69 [==============================] - 0s 803us/step - loss: 1.2792\n",
      "Epoch 5/10\n",
      "69/69 [==============================] - 0s 823us/step - loss: 1.2384\n",
      "Epoch 6/10\n",
      "69/69 [==============================] - 0s 824us/step - loss: 1.2043\n",
      "Epoch 7/10\n",
      "69/69 [==============================] - 0s 896us/step - loss: 1.1756\n",
      "Epoch 8/10\n",
      "69/69 [==============================] - 0s 964us/step - loss: 1.1510\n",
      "Epoch 9/10\n",
      "69/69 [==============================] - 0s 844us/step - loss: 1.1288\n",
      "Epoch 10/10\n",
      "69/69 [==============================] - 0s 844us/step - loss: 1.1093\n",
      "35/35 [==============================] - 0s 647us/step\n",
      "Epoch 1/10\n",
      "69/69 [==============================] - 0s 668us/step - loss: 1.7025\n",
      "Epoch 2/10\n",
      "69/69 [==============================] - 0s 645us/step - loss: 1.5111\n",
      "Epoch 3/10\n",
      "69/69 [==============================] - 0s 659us/step - loss: 1.3993\n",
      "Epoch 4/10\n",
      "69/69 [==============================] - 0s 736us/step - loss: 1.3264\n",
      "Epoch 5/10\n",
      "69/69 [==============================] - 0s 788us/step - loss: 1.2747\n",
      "Epoch 6/10\n",
      "69/69 [==============================] - 0s 840us/step - loss: 1.2359\n",
      "Epoch 7/10\n",
      "69/69 [==============================] - 0s 837us/step - loss: 1.2052\n",
      "Epoch 8/10\n",
      "69/69 [==============================] - 0s 853us/step - loss: 1.1784\n",
      "Epoch 9/10\n",
      "69/69 [==============================] - 0s 840us/step - loss: 1.1555\n",
      "Epoch 10/10\n",
      "69/69 [==============================] - 0s 828us/step - loss: 1.1356\n",
      "35/35 [==============================] - 0s 690us/step\n",
      "Epoch 1/10\n",
      "23/23 [==============================] - 0s 955us/step - loss: 1.6200\n",
      "Epoch 2/10\n",
      "23/23 [==============================] - 0s 955us/step - loss: 1.5795\n",
      "Epoch 3/10\n",
      "23/23 [==============================] - 0s 928us/step - loss: 1.5428\n",
      "Epoch 4/10\n",
      "23/23 [==============================] - 0s 929us/step - loss: 1.5097\n",
      "Epoch 5/10\n",
      "23/23 [==============================] - 0s 947us/step - loss: 1.4783\n",
      "Epoch 6/10\n",
      "23/23 [==============================] - 0s 929us/step - loss: 1.4493\n",
      "Epoch 7/10\n",
      "23/23 [==============================] - 0s 946us/step - loss: 1.4219\n",
      "Epoch 8/10\n",
      "23/23 [==============================] - 0s 995us/step - loss: 1.3953\n",
      "Epoch 9/10\n",
      "23/23 [==============================] - 0s 956us/step - loss: 1.3706\n",
      "Epoch 10/10\n",
      "23/23 [==============================] - 0s 950us/step - loss: 1.3466\n",
      "12/12 [==============================] - 0s 818us/step\n",
      "Epoch 1/10\n",
      "23/23 [==============================] - 0s 954us/step - loss: 1.6472\n",
      "Epoch 2/10\n",
      "23/23 [==============================] - 0s 932us/step - loss: 1.6063\n",
      "Epoch 3/10\n",
      "23/23 [==============================] - 0s 932us/step - loss: 1.5699\n",
      "Epoch 4/10\n",
      "23/23 [==============================] - 0s 949us/step - loss: 1.5374\n",
      "Epoch 5/10\n",
      "23/23 [==============================] - 0s 911us/step - loss: 1.5062\n",
      "Epoch 6/10\n",
      "23/23 [==============================] - 0s 932us/step - loss: 1.4776\n",
      "Epoch 7/10\n",
      "23/23 [==============================] - 0s 956us/step - loss: 1.4507\n",
      "Epoch 8/10\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 1.4251\n",
      "Epoch 9/10\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 1.4006\n",
      "Epoch 10/10\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 1.3778\n",
      "12/12 [==============================] - 0s 818us/step\n",
      "Epoch 1/10\n",
      "23/23 [==============================] - 0s 1000us/step - loss: 1.5745\n",
      "Epoch 2/10\n",
      "23/23 [==============================] - 0s 932us/step - loss: 1.5346\n",
      "Epoch 3/10\n",
      "23/23 [==============================] - 0s 931us/step - loss: 1.4999\n",
      "Epoch 4/10\n",
      "23/23 [==============================] - 0s 947us/step - loss: 1.4691\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 910us/step - loss: 1.4406\n",
      "Epoch 6/10\n",
      "23/23 [==============================] - 0s 943us/step - loss: 1.4155\n",
      "Epoch 7/10\n",
      "23/23 [==============================] - 0s 933us/step - loss: 1.3910\n",
      "Epoch 8/10\n",
      "23/23 [==============================] - 0s 932us/step - loss: 1.3688\n",
      "Epoch 9/10\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 1.3475\n",
      "Epoch 10/10\n",
      "23/23 [==============================] - 0s 962us/step - loss: 1.3276\n",
      "12/12 [==============================] - 0s 909us/step\n",
      "Epoch 1/10\n",
      "23/23 [==============================] - 0s 800us/step - loss: 1.5929\n",
      "Epoch 2/10\n",
      "23/23 [==============================] - 0s 780us/step - loss: 1.4591\n",
      "Epoch 3/10\n",
      "23/23 [==============================] - 0s 774us/step - loss: 1.3678\n",
      "Epoch 4/10\n",
      "23/23 [==============================] - 0s 773us/step - loss: 1.3088\n",
      "Epoch 5/10\n",
      "23/23 [==============================] - 0s 749us/step - loss: 1.2509\n",
      "Epoch 6/10\n",
      "23/23 [==============================] - 0s 750us/step - loss: 1.2166\n",
      "Epoch 7/10\n",
      "23/23 [==============================] - 0s 779us/step - loss: 1.1729\n",
      "Epoch 8/10\n",
      "23/23 [==============================] - 0s 795us/step - loss: 1.1393\n",
      "Epoch 9/10\n",
      "23/23 [==============================] - 0s 796us/step - loss: 1.1090\n",
      "Epoch 10/10\n",
      "23/23 [==============================] - 0s 843us/step - loss: 1.0842\n",
      "12/12 [==============================] - 0s 818us/step\n",
      "Epoch 1/10\n",
      "23/23 [==============================] - 0s 817us/step - loss: 1.5518\n",
      "Epoch 2/10\n",
      "23/23 [==============================] - 0s 773us/step - loss: 1.4176\n",
      "Epoch 3/10\n",
      "23/23 [==============================] - 0s 818us/step - loss: 1.3294\n",
      "Epoch 4/10\n",
      "23/23 [==============================] - 0s 774us/step - loss: 1.2678\n",
      "Epoch 5/10\n",
      "23/23 [==============================] - 0s 816us/step - loss: 1.2134\n",
      "Epoch 6/10\n",
      "23/23 [==============================] - 0s 772us/step - loss: 1.1828\n",
      "Epoch 7/10\n",
      "23/23 [==============================] - 0s 796us/step - loss: 1.1423\n",
      "Epoch 8/10\n",
      "23/23 [==============================] - 0s 796us/step - loss: 1.1081\n",
      "Epoch 9/10\n",
      "23/23 [==============================] - 0s 820us/step - loss: 1.0938\n",
      "Epoch 10/10\n",
      "23/23 [==============================] - 0s 820us/step - loss: 1.0655\n",
      "12/12 [==============================] - 0s 868us/step\n",
      "Epoch 1/10\n",
      "23/23 [==============================] - 0s 814us/step - loss: 1.5815\n",
      "Epoch 2/10\n",
      "23/23 [==============================] - 0s 798us/step - loss: 1.4392\n",
      "Epoch 3/10\n",
      "23/23 [==============================] - 0s 766us/step - loss: 1.3414\n",
      "Epoch 4/10\n",
      "23/23 [==============================] - 0s 766us/step - loss: 1.2880\n",
      "Epoch 5/10\n",
      "23/23 [==============================] - 0s 795us/step - loss: 1.2323\n",
      "Epoch 6/10\n",
      "23/23 [==============================] - 0s 773us/step - loss: 1.2057\n",
      "Epoch 7/10\n",
      "23/23 [==============================] - 0s 796us/step - loss: 1.1715\n",
      "Epoch 8/10\n",
      "23/23 [==============================] - 0s 841us/step - loss: 1.1427\n",
      "Epoch 9/10\n",
      "23/23 [==============================] - 0s 818us/step - loss: 1.1242\n",
      "Epoch 10/10\n",
      "23/23 [==============================] - 0s 887us/step - loss: 1.0988\n",
      "12/12 [==============================] - 0s 773us/step\n",
      "Epoch 1/10\n",
      "14/14 [==============================] - 0s 1000us/step - loss: 1.3690\n",
      "Epoch 2/10\n",
      "14/14 [==============================] - 0s 808us/step - loss: 1.1039\n",
      "Epoch 3/10\n",
      "14/14 [==============================] - 0s 808us/step - loss: 0.9765\n",
      "Epoch 4/10\n",
      "14/14 [==============================] - 0s 808us/step - loss: 0.8880\n",
      "Epoch 5/10\n",
      "14/14 [==============================] - 0s 771us/step - loss: 0.8283\n",
      "Epoch 6/10\n",
      "14/14 [==============================] - 0s 806us/step - loss: 0.7891\n",
      "Epoch 7/10\n",
      "14/14 [==============================] - 0s 772us/step - loss: 0.7583\n",
      "Epoch 8/10\n",
      "14/14 [==============================] - 0s 885us/step - loss: 0.7355\n",
      "Epoch 9/10\n",
      "14/14 [==============================] - 0s 741us/step - loss: 0.7189\n",
      "Epoch 10/10\n",
      "14/14 [==============================] - 0s 808us/step - loss: 0.7014\n",
      "7/7 [==============================] - 0s 798us/step\n",
      "Epoch 1/10\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 1.3371\n",
      "Epoch 2/10\n",
      "14/14 [==============================] - 0s 786us/step - loss: 1.0998\n",
      "Epoch 3/10\n",
      "14/14 [==============================] - 0s 808us/step - loss: 0.9811\n",
      "Epoch 4/10\n",
      "14/14 [==============================] - 0s 811us/step - loss: 0.9009\n",
      "Epoch 5/10\n",
      "14/14 [==============================] - 0s 808us/step - loss: 0.8356\n",
      "Epoch 6/10\n",
      "14/14 [==============================] - 0s 847us/step - loss: 0.7925\n",
      "Epoch 7/10\n",
      "14/14 [==============================] - 0s 769us/step - loss: 0.7505\n",
      "Epoch 8/10\n",
      "14/14 [==============================] - 0s 877us/step - loss: 0.7325\n",
      "Epoch 9/10\n",
      "14/14 [==============================] - 0s 920us/step - loss: 0.7083\n",
      "Epoch 10/10\n",
      "14/14 [==============================] - 0s 789us/step - loss: 0.6918\n",
      "7/7 [==============================] - 0s 1ms/step\n",
      "Epoch 1/10\n",
      "14/14 [==============================] - 0s 965us/step - loss: 1.3055\n",
      "Epoch 2/10\n",
      "14/14 [==============================] - 0s 808us/step - loss: 1.0714\n",
      "Epoch 3/10\n",
      "14/14 [==============================] - 0s 769us/step - loss: 0.9731\n",
      "Epoch 4/10\n",
      "14/14 [==============================] - 0s 805us/step - loss: 0.8948\n",
      "Epoch 5/10\n",
      "14/14 [==============================] - 0s 784us/step - loss: 0.8399\n",
      "Epoch 6/10\n",
      "14/14 [==============================] - 0s 808us/step - loss: 0.8077\n",
      "Epoch 7/10\n",
      "14/14 [==============================] - 0s 837us/step - loss: 0.7771\n",
      "Epoch 8/10\n",
      "14/14 [==============================] - 0s 889us/step - loss: 0.7431\n",
      "Epoch 9/10\n",
      "14/14 [==============================] - 0s 878us/step - loss: 0.7168\n",
      "Epoch 10/10\n",
      "14/14 [==============================] - 0s 820us/step - loss: 0.7147\n",
      "7/7 [==============================] - 0s 1ms/step\n",
      "Epoch 1/10\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 1.5867\n",
      "Epoch 2/10\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 1.5899\n",
      "Epoch 3/10\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 1.5877\n",
      "Epoch 4/10\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 1.5861\n",
      "Epoch 5/10\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 1.5859\n",
      "Epoch 6/10\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 1.5838\n",
      "Epoch 7/10\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 1.5904\n",
      "Epoch 8/10\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 1.5871\n",
      "Epoch 9/10\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 1.5904\n",
      "Epoch 10/10\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 1.5881\n",
      "12/12 [==============================] - 0s 904us/step\n",
      "Epoch 1/10\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 1.6554\n",
      "Epoch 2/10\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 1.6458\n",
      "Epoch 3/10\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 1.6468\n",
      "Epoch 4/10\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 1.6403\n",
      "Epoch 5/10\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 1.6529\n",
      "Epoch 6/10\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 1.6386\n",
      "Epoch 7/10\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 1.6451\n",
      "Epoch 8/10\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 1.6446\n",
      "Epoch 9/10\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 1.6436\n",
      "Epoch 10/10\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 1.6388\n",
      "12/12 [==============================] - 0s 909us/step\n",
      "Epoch 1/10\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 1.5967\n",
      "Epoch 2/10\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 1.5919\n",
      "Epoch 3/10\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 1.5975\n",
      "Epoch 4/10\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 1.5966\n",
      "Epoch 5/10\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 1.5954\n",
      "Epoch 6/10\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 1.5891\n",
      "Epoch 7/10\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 1.5905\n",
      "Epoch 8/10\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 1.5872\n",
      "Epoch 9/10\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 1.5943\n",
      "Epoch 10/10\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 1.5915\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 868us/step\n",
      "Epoch 1/10\n",
      "69/69 [==============================] - 0s 853us/step - loss: 1.5997\n",
      "Epoch 2/10\n",
      "69/69 [==============================] - 0s 816us/step - loss: 1.5283\n",
      "Epoch 3/10\n",
      "69/69 [==============================] - 0s 839us/step - loss: 1.4672\n",
      "Epoch 4/10\n",
      "69/69 [==============================] - 0s 875us/step - loss: 1.4144\n",
      "Epoch 5/10\n",
      "69/69 [==============================] - 0s 989us/step - loss: 1.3680\n",
      "Epoch 6/10\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 1.3259\n",
      "Epoch 7/10\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 1.2893\n",
      "Epoch 8/10\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 1.2552\n",
      "Epoch 9/10\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 1.2231\n",
      "Epoch 10/10\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 1.1933\n",
      "35/35 [==============================] - 0s 794us/step\n",
      "Epoch 1/10\n",
      "69/69 [==============================] - 0s 830us/step - loss: 1.5883\n",
      "Epoch 2/10\n",
      "69/69 [==============================] - 0s 814us/step - loss: 1.5027\n",
      "Epoch 3/10\n",
      "69/69 [==============================] - 0s 822us/step - loss: 1.4360\n",
      "Epoch 4/10\n",
      "69/69 [==============================] - 0s 884us/step - loss: 1.3808\n",
      "Epoch 5/10\n",
      "69/69 [==============================] - 0s 937us/step - loss: 1.3343\n",
      "Epoch 6/10\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 1.2930\n",
      "Epoch 7/10\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 1.2565\n",
      "Epoch 8/10\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 1.2242\n",
      "Epoch 9/10\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 1.1949\n",
      "Epoch 10/10\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 1.1684\n",
      "35/35 [==============================] - 0s 706us/step\n",
      "Epoch 1/10\n",
      "69/69 [==============================] - 0s 896us/step - loss: 1.5725\n",
      "Epoch 2/10\n",
      "69/69 [==============================] - 0s 838us/step - loss: 1.4913\n",
      "Epoch 3/10\n",
      "69/69 [==============================] - 0s 853us/step - loss: 1.4246\n",
      "Epoch 4/10\n",
      "69/69 [==============================] - 0s 862us/step - loss: 1.3685\n",
      "Epoch 5/10\n",
      "69/69 [==============================] - 0s 875us/step - loss: 1.3211\n",
      "Epoch 6/10\n",
      "69/69 [==============================] - 0s 885us/step - loss: 1.2813\n",
      "Epoch 7/10\n",
      "69/69 [==============================] - 0s 992us/step - loss: 1.2461\n",
      "Epoch 8/10\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 1.2153\n",
      "Epoch 9/10\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 1.1867\n",
      "Epoch 10/10\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 1.1602\n",
      "35/35 [==============================] - 0s 809us/step\n",
      "Epoch 1/10\n",
      "69/69 [==============================] - 0s 624us/step - loss: 1.5670\n",
      "Epoch 2/10\n",
      "69/69 [==============================] - 0s 632us/step - loss: 1.5410\n",
      "Epoch 3/10\n",
      "69/69 [==============================] - 0s 674us/step - loss: 1.5172\n",
      "Epoch 4/10\n",
      "69/69 [==============================] - 0s 784us/step - loss: 1.4959\n",
      "Epoch 5/10\n",
      "69/69 [==============================] - 0s 820us/step - loss: 1.4765\n",
      "Epoch 6/10\n",
      "69/69 [==============================] - 0s 787us/step - loss: 1.4583\n",
      "Epoch 7/10\n",
      "69/69 [==============================] - 0s 824us/step - loss: 1.4420\n",
      "Epoch 8/10\n",
      "69/69 [==============================] - 0s 826us/step - loss: 1.4270\n",
      "Epoch 9/10\n",
      "69/69 [==============================] - 0s 831us/step - loss: 1.4129\n",
      "Epoch 10/10\n",
      "69/69 [==============================] - 0s 807us/step - loss: 1.3999\n",
      "35/35 [==============================] - 0s 735us/step\n",
      "Epoch 1/10\n",
      "69/69 [==============================] - 0s 633us/step - loss: 1.7761\n",
      "Epoch 2/10\n",
      "69/69 [==============================] - 0s 632us/step - loss: 1.7468\n",
      "Epoch 3/10\n",
      "69/69 [==============================] - 0s 648us/step - loss: 1.7195\n",
      "Epoch 4/10\n",
      "69/69 [==============================] - 0s 728us/step - loss: 1.6933\n",
      "Epoch 5/10\n",
      "69/69 [==============================] - 0s 806us/step - loss: 1.6696\n",
      "Epoch 6/10\n",
      "69/69 [==============================] - 0s 829us/step - loss: 1.6472\n",
      "Epoch 7/10\n",
      "69/69 [==============================] - 0s 801us/step - loss: 1.6259\n",
      "Epoch 8/10\n",
      "69/69 [==============================] - 0s 816us/step - loss: 1.6060\n",
      "Epoch 9/10\n",
      "69/69 [==============================] - 0s 857us/step - loss: 1.5874\n",
      "Epoch 10/10\n",
      "69/69 [==============================] - 0s 809us/step - loss: 1.5698\n",
      "35/35 [==============================] - 0s 693us/step\n",
      "Epoch 1/10\n",
      "69/69 [==============================] - 0s 697us/step - loss: 1.7369\n",
      "Epoch 2/10\n",
      "69/69 [==============================] - 0s 628us/step - loss: 1.7070\n",
      "Epoch 3/10\n",
      "69/69 [==============================] - 0s 669us/step - loss: 1.6791\n",
      "Epoch 4/10\n",
      "69/69 [==============================] - 0s 698us/step - loss: 1.6530\n",
      "Epoch 5/10\n",
      "69/69 [==============================] - 0s 788us/step - loss: 1.6285\n",
      "Epoch 6/10\n",
      "69/69 [==============================] - 0s 829us/step - loss: 1.6058\n",
      "Epoch 7/10\n",
      "69/69 [==============================] - 0s 814us/step - loss: 1.5841\n",
      "Epoch 8/10\n",
      "69/69 [==============================] - 0s 809us/step - loss: 1.5641\n",
      "Epoch 9/10\n",
      "69/69 [==============================] - 0s 801us/step - loss: 1.5453\n",
      "Epoch 10/10\n",
      "69/69 [==============================] - 0s 824us/step - loss: 1.5279\n",
      "35/35 [==============================] - 0s 679us/step\n",
      "Epoch 1/10\n",
      "14/14 [==============================] - 0s 962us/step - loss: 1.7451\n",
      "Epoch 2/10\n",
      "14/14 [==============================] - 0s 885us/step - loss: 1.6806\n",
      "Epoch 3/10\n",
      "14/14 [==============================] - 0s 885us/step - loss: 1.6317\n",
      "Epoch 4/10\n",
      "14/14 [==============================] - 0s 924us/step - loss: 1.5816\n",
      "Epoch 5/10\n",
      "14/14 [==============================] - 0s 956us/step - loss: 1.5344\n",
      "Epoch 6/10\n",
      "14/14 [==============================] - 0s 883us/step - loss: 1.5005\n",
      "Epoch 7/10\n",
      "14/14 [==============================] - 0s 880us/step - loss: 1.4743\n",
      "Epoch 8/10\n",
      "14/14 [==============================] - 0s 937us/step - loss: 1.4457\n",
      "Epoch 9/10\n",
      "14/14 [==============================] - 0s 962us/step - loss: 1.4285\n",
      "Epoch 10/10\n",
      "14/14 [==============================] - 0s 924us/step - loss: 1.4092\n",
      "7/7 [==============================] - 0s 1000us/step\n",
      "Epoch 1/10\n",
      "14/14 [==============================] - 0s 928us/step - loss: 1.7565\n",
      "Epoch 2/10\n",
      "14/14 [==============================] - 0s 885us/step - loss: 1.6861\n",
      "Epoch 3/10\n",
      "14/14 [==============================] - 0s 906us/step - loss: 1.6399\n",
      "Epoch 4/10\n",
      "14/14 [==============================] - 0s 913us/step - loss: 1.5844\n",
      "Epoch 5/10\n",
      "14/14 [==============================] - 0s 911us/step - loss: 1.5558\n",
      "Epoch 6/10\n",
      "14/14 [==============================] - 0s 907us/step - loss: 1.5193\n",
      "Epoch 7/10\n",
      "14/14 [==============================] - 0s 922us/step - loss: 1.4941\n",
      "Epoch 8/10\n",
      "14/14 [==============================] - 0s 959us/step - loss: 1.4790\n",
      "Epoch 9/10\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 1.4532\n",
      "Epoch 10/10\n",
      "14/14 [==============================] - 0s 908us/step - loss: 1.4413\n",
      "7/7 [==============================] - 0s 1ms/step\n",
      "Epoch 1/10\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 1.6499\n",
      "Epoch 2/10\n",
      "14/14 [==============================] - 0s 884us/step - loss: 1.5925\n",
      "Epoch 3/10\n",
      "14/14 [==============================] - 0s 885us/step - loss: 1.5644\n",
      "Epoch 4/10\n",
      "14/14 [==============================] - 0s 846us/step - loss: 1.5233\n",
      "Epoch 5/10\n",
      "14/14 [==============================] - 0s 907us/step - loss: 1.4936\n",
      "Epoch 6/10\n",
      "14/14 [==============================] - 0s 906us/step - loss: 1.4634\n",
      "Epoch 7/10\n",
      "14/14 [==============================] - 0s 883us/step - loss: 1.4468\n",
      "Epoch 8/10\n",
      "14/14 [==============================] - 0s 925us/step - loss: 1.4247\n",
      "Epoch 9/10\n",
      "14/14 [==============================] - 0s 911us/step - loss: 1.4060\n",
      "Epoch 10/10\n",
      "14/14 [==============================] - 0s 863us/step - loss: 1.3917\n",
      "7/7 [==============================] - 0s 1ms/step\n",
      "Epoch 1/10\n",
      "69/69 [==============================] - 0s 706us/step - loss: 1.7261\n",
      "Epoch 2/10\n",
      "69/69 [==============================] - 0s 692us/step - loss: 1.7109\n",
      "Epoch 3/10\n",
      "69/69 [==============================] - 0s 669us/step - loss: 1.7035\n",
      "Epoch 4/10\n",
      "69/69 [==============================] - 0s 751us/step - loss: 1.7011\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69/69 [==============================] - 0s 866us/step - loss: 1.6977\n",
      "Epoch 6/10\n",
      "69/69 [==============================] - 0s 857us/step - loss: 1.6951\n",
      "Epoch 7/10\n",
      "69/69 [==============================] - 0s 877us/step - loss: 1.6945\n",
      "Epoch 8/10\n",
      "69/69 [==============================] - 0s 862us/step - loss: 1.6994\n",
      "Epoch 9/10\n",
      "69/69 [==============================] - 0s 876us/step - loss: 1.6893\n",
      "Epoch 10/10\n",
      "69/69 [==============================] - 0s 868us/step - loss: 1.6837\n",
      "35/35 [==============================] - 0s 752us/step\n",
      "Epoch 1/10\n",
      "69/69 [==============================] - 0s 706us/step - loss: 1.6015\n",
      "Epoch 2/10\n",
      "69/69 [==============================] - 0s 677us/step - loss: 1.6013\n",
      "Epoch 3/10\n",
      "69/69 [==============================] - 0s 669us/step - loss: 1.6017\n",
      "Epoch 4/10\n",
      "69/69 [==============================] - 0s 678us/step - loss: 1.5938\n",
      "Epoch 5/10\n",
      "69/69 [==============================] - 0s 701us/step - loss: 1.5973\n",
      "Epoch 6/10\n",
      "69/69 [==============================] - 0s 721us/step - loss: 1.5949\n",
      "Epoch 7/10\n",
      "69/69 [==============================] - 0s 845us/step - loss: 1.5934\n",
      "Epoch 8/10\n",
      "69/69 [==============================] - 0s 868us/step - loss: 1.5955\n",
      "Epoch 9/10\n",
      "69/69 [==============================] - 0s 874us/step - loss: 1.5847\n",
      "Epoch 10/10\n",
      "69/69 [==============================] - 0s 834us/step - loss: 1.5771\n",
      "35/35 [==============================] - 0s 731us/step\n",
      "Epoch 1/10\n",
      "69/69 [==============================] - 0s 699us/step - loss: 1.6725\n",
      "Epoch 2/10\n",
      "69/69 [==============================] - 0s 684us/step - loss: 1.6630\n",
      "Epoch 3/10\n",
      "69/69 [==============================] - 0s 707us/step - loss: 1.6674\n",
      "Epoch 4/10\n",
      "69/69 [==============================] - 0s 807us/step - loss: 1.6658\n",
      "Epoch 5/10\n",
      "69/69 [==============================] - 0s 850us/step - loss: 1.6582\n",
      "Epoch 6/10\n",
      "69/69 [==============================] - 0s 853us/step - loss: 1.6545\n",
      "Epoch 7/10\n",
      "69/69 [==============================] - 0s 868us/step - loss: 1.6572\n",
      "Epoch 8/10\n",
      "69/69 [==============================] - 0s 875us/step - loss: 1.6500\n",
      "Epoch 9/10\n",
      "69/69 [==============================] - 0s 886us/step - loss: 1.6484\n",
      "Epoch 10/10\n",
      "69/69 [==============================] - 0s 850us/step - loss: 1.6507\n",
      "35/35 [==============================] - 0s 723us/step\n",
      "Epoch 1/10\n",
      "69/69 [==============================] - 0s 729us/step - loss: 1.6683\n",
      "Epoch 2/10\n",
      "69/69 [==============================] - 0s 713us/step - loss: 1.6223\n",
      "Epoch 3/10\n",
      "69/69 [==============================] - 0s 721us/step - loss: 1.5729\n",
      "Epoch 4/10\n",
      "69/69 [==============================] - 0s 808us/step - loss: 1.5359\n",
      "Epoch 5/10\n",
      "69/69 [==============================] - 0s 853us/step - loss: 1.4994\n",
      "Epoch 6/10\n",
      "69/69 [==============================] - 0s 897us/step - loss: 1.4709\n",
      "Epoch 7/10\n",
      "69/69 [==============================] - 0s 930us/step - loss: 1.4429\n",
      "Epoch 8/10\n",
      "69/69 [==============================] - 0s 907us/step - loss: 1.4130\n",
      "Epoch 9/10\n",
      "69/69 [==============================] - 0s 952us/step - loss: 1.3971\n",
      "Epoch 10/10\n",
      "69/69 [==============================] - 0s 948us/step - loss: 1.3695\n",
      "35/35 [==============================] - 0s 696us/step\n",
      "Epoch 1/10\n",
      "69/69 [==============================] - 0s 763us/step - loss: 1.6636\n",
      "Epoch 2/10\n",
      "69/69 [==============================] - 0s 726us/step - loss: 1.6150\n",
      "Epoch 3/10\n",
      "69/69 [==============================] - 0s 776us/step - loss: 1.5776\n",
      "Epoch 4/10\n",
      "69/69 [==============================] - 0s 831us/step - loss: 1.5287\n",
      "Epoch 5/10\n",
      "69/69 [==============================] - 0s 924us/step - loss: 1.5032\n",
      "Epoch 6/10\n",
      "69/69 [==============================] - 0s 956us/step - loss: 1.4721\n",
      "Epoch 7/10\n",
      "69/69 [==============================] - 0s 948us/step - loss: 1.4512\n",
      "Epoch 8/10\n",
      "69/69 [==============================] - 0s 977us/step - loss: 1.4134\n",
      "Epoch 9/10\n",
      "69/69 [==============================] - 0s 984us/step - loss: 1.3917\n",
      "Epoch 10/10\n",
      "69/69 [==============================] - 0s 952us/step - loss: 1.3770\n",
      "35/35 [==============================] - 0s 676us/step\n",
      "Epoch 1/10\n",
      "69/69 [==============================] - 0s 763us/step - loss: 1.5927\n",
      "Epoch 2/10\n",
      "69/69 [==============================] - 0s 726us/step - loss: 1.5405\n",
      "Epoch 3/10\n",
      "69/69 [==============================] - 0s 733us/step - loss: 1.5134\n",
      "Epoch 4/10\n",
      "69/69 [==============================] - 0s 728us/step - loss: 1.4843\n",
      "Epoch 5/10\n",
      "69/69 [==============================] - 0s 850us/step - loss: 1.4447\n",
      "Epoch 6/10\n",
      "69/69 [==============================] - 0s 892us/step - loss: 1.4229\n",
      "Epoch 7/10\n",
      "69/69 [==============================] - 0s 925us/step - loss: 1.3980\n",
      "Epoch 8/10\n",
      "69/69 [==============================] - 0s 921us/step - loss: 1.3714\n",
      "Epoch 9/10\n",
      "69/69 [==============================] - 0s 918us/step - loss: 1.3600\n",
      "Epoch 10/10\n",
      "69/69 [==============================] - 0s 927us/step - loss: 1.3367\n",
      "35/35 [==============================] - 0s 663us/step\n",
      "Epoch 1/10\n",
      "14/14 [==============================] - 0s 913us/step - loss: 1.7444\n",
      "Epoch 2/10\n",
      "14/14 [==============================] - 0s 828us/step - loss: 1.6031\n",
      "Epoch 3/10\n",
      "14/14 [==============================] - 0s 809us/step - loss: 1.4963\n",
      "Epoch 4/10\n",
      "14/14 [==============================] - 0s 769us/step - loss: 1.4173\n",
      "Epoch 5/10\n",
      "14/14 [==============================] - 0s 808us/step - loss: 1.3512\n",
      "Epoch 6/10\n",
      "14/14 [==============================] - 0s 806us/step - loss: 1.2973\n",
      "Epoch 7/10\n",
      "14/14 [==============================] - 0s 768us/step - loss: 1.2522\n",
      "Epoch 8/10\n",
      "14/14 [==============================] - 0s 769us/step - loss: 1.2126\n",
      "Epoch 9/10\n",
      "14/14 [==============================] - 0s 770us/step - loss: 1.1786\n",
      "Epoch 10/10\n",
      "14/14 [==============================] - 0s 844us/step - loss: 1.1483\n",
      "7/7 [==============================] - 0s 833us/step\n",
      "Epoch 1/10\n",
      "14/14 [==============================] - 0s 975us/step - loss: 1.5757\n",
      "Epoch 2/10\n",
      "14/14 [==============================] - 0s 769us/step - loss: 1.4634\n",
      "Epoch 3/10\n",
      "14/14 [==============================] - 0s 805us/step - loss: 1.3793\n",
      "Epoch 4/10\n",
      "14/14 [==============================] - 0s 729us/step - loss: 1.3145\n",
      "Epoch 5/10\n",
      "14/14 [==============================] - 0s 807us/step - loss: 1.2618\n",
      "Epoch 6/10\n",
      "14/14 [==============================] - 0s 829us/step - loss: 1.2184\n",
      "Epoch 7/10\n",
      "14/14 [==============================] - 0s 814us/step - loss: 1.1817\n",
      "Epoch 8/10\n",
      "14/14 [==============================] - 0s 796us/step - loss: 1.1502\n",
      "Epoch 9/10\n",
      "14/14 [==============================] - 0s 808us/step - loss: 1.1221\n",
      "Epoch 10/10\n",
      "14/14 [==============================] - 0s 801us/step - loss: 1.0973\n",
      "7/7 [==============================] - 0s 926us/step\n",
      "Epoch 1/10\n",
      "14/14 [==============================] - 0s 846us/step - loss: 1.6315\n",
      "Epoch 2/10\n",
      "14/14 [==============================] - 0s 811us/step - loss: 1.5022\n",
      "Epoch 3/10\n",
      "14/14 [==============================] - 0s 787us/step - loss: 1.4108\n",
      "Epoch 4/10\n",
      "14/14 [==============================] - 0s 808us/step - loss: 1.3416\n",
      "Epoch 5/10\n",
      "14/14 [==============================] - 0s 779us/step - loss: 1.2879\n",
      "Epoch 6/10\n",
      "14/14 [==============================] - 0s 808us/step - loss: 1.2470\n",
      "Epoch 7/10\n",
      "14/14 [==============================] - 0s 747us/step - loss: 1.2104\n",
      "Epoch 8/10\n",
      "14/14 [==============================] - 0s 808us/step - loss: 1.1804\n",
      "Epoch 9/10\n",
      "14/14 [==============================] - 0s 780us/step - loss: 1.1533\n",
      "Epoch 10/10\n",
      "14/14 [==============================] - 0s 731us/step - loss: 1.1293\n",
      "7/7 [==============================] - 0s 1ms/step\n",
      "Epoch 1/10\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 1.5446\n",
      "Epoch 2/10\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 1.3737\n",
      "Epoch 3/10\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 1.2618\n",
      "Epoch 4/10\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 1.1726\n",
      "Epoch 5/10\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 1.1032\n",
      "Epoch 6/10\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 1.0470\n",
      "Epoch 7/10\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 1.0128\n",
      "Epoch 8/10\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.9675\n",
      "Epoch 9/10\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.9418\n",
      "Epoch 10/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 2ms/step - loss: 0.9109\n",
      "7/7 [==============================] - 0s 1ms/step\n",
      "Epoch 1/10\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 1.5690\n",
      "Epoch 2/10\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 1.3980\n",
      "Epoch 3/10\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 1.2914\n",
      "Epoch 4/10\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 1.1894\n",
      "Epoch 5/10\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 1.1176\n",
      "Epoch 6/10\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 1.0441\n",
      "Epoch 7/10\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 1.0235\n",
      "Epoch 8/10\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.9733\n",
      "Epoch 9/10\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.9446\n",
      "Epoch 10/10\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.9288\n",
      "7/7 [==============================] - 0s 936us/step\n",
      "Epoch 1/10\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 1.5095\n",
      "Epoch 2/10\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 1.3268\n",
      "Epoch 3/10\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 1.2163\n",
      "Epoch 4/10\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 1.1321\n",
      "Epoch 5/10\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 1.0678\n",
      "Epoch 6/10\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 1.0206\n",
      "Epoch 7/10\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.9909\n",
      "Epoch 8/10\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.9560\n",
      "Epoch 9/10\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.9359\n",
      "Epoch 10/10\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.9166\n",
      "7/7 [==============================] - 0s 1000us/step\n",
      "Epoch 1/10\n",
      "14/14 [==============================] - 0s 809us/step - loss: 1.5419\n",
      "Epoch 2/10\n",
      "14/14 [==============================] - 0s 731us/step - loss: 1.5417\n",
      "Epoch 3/10\n",
      "14/14 [==============================] - 0s 746us/step - loss: 1.5414\n",
      "Epoch 4/10\n",
      "14/14 [==============================] - 0s 731us/step - loss: 1.5411\n",
      "Epoch 5/10\n",
      "14/14 [==============================] - 0s 731us/step - loss: 1.5408\n",
      "Epoch 6/10\n",
      "14/14 [==============================] - 0s 731us/step - loss: 1.5405\n",
      "Epoch 7/10\n",
      "14/14 [==============================] - 0s 759us/step - loss: 1.5403\n",
      "Epoch 8/10\n",
      "14/14 [==============================] - 0s 730us/step - loss: 1.5400\n",
      "Epoch 9/10\n",
      "14/14 [==============================] - 0s 810us/step - loss: 1.5397\n",
      "Epoch 10/10\n",
      "14/14 [==============================] - 0s 784us/step - loss: 1.5394\n",
      "7/7 [==============================] - 0s 928us/step\n",
      "Epoch 1/10\n",
      "14/14 [==============================] - 0s 792us/step - loss: 1.7406\n",
      "Epoch 2/10\n",
      "14/14 [==============================] - 0s 726us/step - loss: 1.7400\n",
      "Epoch 3/10\n",
      "14/14 [==============================] - 0s 697us/step - loss: 1.7394\n",
      "Epoch 4/10\n",
      "14/14 [==============================] - 0s 738us/step - loss: 1.7388\n",
      "Epoch 5/10\n",
      "14/14 [==============================] - 0s 731us/step - loss: 1.7382\n",
      "Epoch 6/10\n",
      "14/14 [==============================] - 0s 773us/step - loss: 1.7377\n",
      "Epoch 7/10\n",
      "14/14 [==============================] - 0s 729us/step - loss: 1.7371\n",
      "Epoch 8/10\n",
      "14/14 [==============================] - 0s 693us/step - loss: 1.7365\n",
      "Epoch 9/10\n",
      "14/14 [==============================] - 0s 820us/step - loss: 1.7359\n",
      "Epoch 10/10\n",
      "14/14 [==============================] - 0s 770us/step - loss: 1.7353\n",
      "7/7 [==============================] - 0s 1ms/step\n",
      "Epoch 1/10\n",
      "14/14 [==============================] - 0s 769us/step - loss: 1.7525\n",
      "Epoch 2/10\n",
      "14/14 [==============================] - 0s 730us/step - loss: 1.7518\n",
      "Epoch 3/10\n",
      "14/14 [==============================] - 0s 695us/step - loss: 1.7510\n",
      "Epoch 4/10\n",
      "14/14 [==============================] - 0s 731us/step - loss: 1.7503\n",
      "Epoch 5/10\n",
      "14/14 [==============================] - 0s 730us/step - loss: 1.7495\n",
      "Epoch 6/10\n",
      "14/14 [==============================] - 0s 731us/step - loss: 1.7488\n",
      "Epoch 7/10\n",
      "14/14 [==============================] - 0s 719us/step - loss: 1.7480\n",
      "Epoch 8/10\n",
      "14/14 [==============================] - 0s 731us/step - loss: 1.7473\n",
      "Epoch 9/10\n",
      "14/14 [==============================] - 0s 731us/step - loss: 1.7465\n",
      "Epoch 10/10\n",
      "14/14 [==============================] - 0s 731us/step - loss: 1.7458\n",
      "7/7 [==============================] - 0s 1ms/step\n",
      "Epoch 1/10\n",
      "23/23 [==============================] - 0s 864us/step - loss: 1.6649\n",
      "Epoch 2/10\n",
      "23/23 [==============================] - 0s 750us/step - loss: 1.6461\n",
      "Epoch 3/10\n",
      "23/23 [==============================] - 0s 779us/step - loss: 1.6279\n",
      "Epoch 4/10\n",
      "23/23 [==============================] - 0s 773us/step - loss: 1.6110\n",
      "Epoch 5/10\n",
      "23/23 [==============================] - 0s 773us/step - loss: 1.5943\n",
      "Epoch 6/10\n",
      "23/23 [==============================] - 0s 773us/step - loss: 1.5787\n",
      "Epoch 7/10\n",
      "23/23 [==============================] - 0s 795us/step - loss: 1.5639\n",
      "Epoch 8/10\n",
      "23/23 [==============================] - 0s 800us/step - loss: 1.5495\n",
      "Epoch 9/10\n",
      "23/23 [==============================] - 0s 836us/step - loss: 1.5358\n",
      "Epoch 10/10\n",
      "23/23 [==============================] - 0s 742us/step - loss: 1.5226\n",
      "12/12 [==============================] - 0s 864us/step\n",
      "Epoch 1/10\n",
      "23/23 [==============================] - 0s 848us/step - loss: 1.6591\n",
      "Epoch 2/10\n",
      "23/23 [==============================] - 0s 750us/step - loss: 1.6341\n",
      "Epoch 3/10\n",
      "23/23 [==============================] - 0s 727us/step - loss: 1.6107\n",
      "Epoch 4/10\n",
      "23/23 [==============================] - 0s 750us/step - loss: 1.5886\n",
      "Epoch 5/10\n",
      "23/23 [==============================] - 0s 750us/step - loss: 1.5675\n",
      "Epoch 6/10\n",
      "23/23 [==============================] - 0s 750us/step - loss: 1.5476\n",
      "Epoch 7/10\n",
      "23/23 [==============================] - 0s 774us/step - loss: 1.5289\n",
      "Epoch 8/10\n",
      "23/23 [==============================] - 0s 750us/step - loss: 1.5111\n",
      "Epoch 9/10\n",
      "23/23 [==============================] - 0s 750us/step - loss: 1.4941\n",
      "Epoch 10/10\n",
      "23/23 [==============================] - 0s 750us/step - loss: 1.4784\n",
      "12/12 [==============================] - 0s 727us/step\n",
      "Epoch 1/10\n",
      "23/23 [==============================] - 0s 798us/step - loss: 1.7291\n",
      "Epoch 2/10\n",
      "23/23 [==============================] - 0s 713us/step - loss: 1.7032\n",
      "Epoch 3/10\n",
      "23/23 [==============================] - 0s 793us/step - loss: 1.6786\n",
      "Epoch 4/10\n",
      "23/23 [==============================] - 0s 791us/step - loss: 1.6555\n",
      "Epoch 5/10\n",
      "23/23 [==============================] - 0s 829us/step - loss: 1.6332\n",
      "Epoch 6/10\n",
      "23/23 [==============================] - 0s 755us/step - loss: 1.6129\n",
      "Epoch 7/10\n",
      "23/23 [==============================] - 0s 782us/step - loss: 1.5928\n",
      "Epoch 8/10\n",
      "23/23 [==============================] - 0s 814us/step - loss: 1.5743\n",
      "Epoch 9/10\n",
      "23/23 [==============================] - 0s 818us/step - loss: 1.5565\n",
      "Epoch 10/10\n",
      "23/23 [==============================] - 0s 922us/step - loss: 1.5398\n",
      "12/12 [==============================] - 0s 775us/step\n",
      "Epoch 1/10\n",
      "23/23 [==============================] - 0s 746us/step - loss: 1.6206\n",
      "Epoch 2/10\n",
      "23/23 [==============================] - 0s 659us/step - loss: 1.6196\n",
      "Epoch 3/10\n",
      "23/23 [==============================] - 0s 698us/step - loss: 1.6185\n",
      "Epoch 4/10\n",
      "23/23 [==============================] - 0s 727us/step - loss: 1.6175\n",
      "Epoch 5/10\n",
      "23/23 [==============================] - 0s 705us/step - loss: 1.6164\n",
      "Epoch 6/10\n",
      "23/23 [==============================] - 0s 705us/step - loss: 1.6154\n",
      "Epoch 7/10\n",
      "23/23 [==============================] - 0s 705us/step - loss: 1.6143\n",
      "Epoch 8/10\n",
      "23/23 [==============================] - 0s 827us/step - loss: 1.6133\n",
      "Epoch 9/10\n",
      "23/23 [==============================] - 0s 868us/step - loss: 1.6122\n",
      "Epoch 10/10\n",
      "23/23 [==============================] - 0s 864us/step - loss: 1.6112\n",
      "12/12 [==============================] - 0s 818us/step\n",
      "Epoch 1/10\n",
      "23/23 [==============================] - 0s 843us/step - loss: 1.6325\n",
      "Epoch 2/10\n",
      "23/23 [==============================] - 0s 660us/step - loss: 1.6318\n",
      "Epoch 3/10\n",
      "23/23 [==============================] - 0s 690us/step - loss: 1.6311\n",
      "Epoch 4/10\n",
      "23/23 [==============================] - 0s 682us/step - loss: 1.6305\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 659us/step - loss: 1.6298\n",
      "Epoch 6/10\n",
      "23/23 [==============================] - 0s 659us/step - loss: 1.6292\n",
      "Epoch 7/10\n",
      "23/23 [==============================] - 0s 705us/step - loss: 1.6285\n",
      "Epoch 8/10\n",
      "23/23 [==============================] - 0s 684us/step - loss: 1.6279\n",
      "Epoch 9/10\n",
      "23/23 [==============================] - 0s 723us/step - loss: 1.6272\n",
      "Epoch 10/10\n",
      "23/23 [==============================] - 0s 773us/step - loss: 1.6265\n",
      "12/12 [==============================] - 0s 877us/step\n",
      "Epoch 1/10\n",
      "23/23 [==============================] - 0s 730us/step - loss: 1.7104\n",
      "Epoch 2/10\n",
      "23/23 [==============================] - 0s 659us/step - loss: 1.7093\n",
      "Epoch 3/10\n",
      "23/23 [==============================] - 0s 659us/step - loss: 1.7083\n",
      "Epoch 4/10\n",
      "23/23 [==============================] - 0s 659us/step - loss: 1.7072\n",
      "Epoch 5/10\n",
      "23/23 [==============================] - 0s 659us/step - loss: 1.7062\n",
      "Epoch 6/10\n",
      "23/23 [==============================] - 0s 705us/step - loss: 1.7052\n",
      "Epoch 7/10\n",
      "23/23 [==============================] - 0s 750us/step - loss: 1.7041\n",
      "Epoch 8/10\n",
      "23/23 [==============================] - 0s 795us/step - loss: 1.7031\n",
      "Epoch 9/10\n",
      "23/23 [==============================] - 0s 866us/step - loss: 1.7020\n",
      "Epoch 10/10\n",
      "23/23 [==============================] - 0s 796us/step - loss: 1.7010\n",
      "12/12 [==============================] - 0s 864us/step\n",
      "Epoch 1/10\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 1.3603\n",
      "Epoch 2/10\n",
      "14/14 [==============================] - 0s 727us/step - loss: 1.0830\n",
      "Epoch 3/10\n",
      "14/14 [==============================] - 0s 772us/step - loss: 0.9741\n",
      "Epoch 4/10\n",
      "14/14 [==============================] - 0s 808us/step - loss: 0.8941\n",
      "Epoch 5/10\n",
      "14/14 [==============================] - 0s 808us/step - loss: 0.8342\n",
      "Epoch 6/10\n",
      "14/14 [==============================] - 0s 778us/step - loss: 0.7933\n",
      "Epoch 7/10\n",
      "14/14 [==============================] - 0s 794us/step - loss: 0.7614\n",
      "Epoch 8/10\n",
      "14/14 [==============================] - 0s 770us/step - loss: 0.7336\n",
      "Epoch 9/10\n",
      "14/14 [==============================] - 0s 730us/step - loss: 0.7149\n",
      "Epoch 10/10\n",
      "14/14 [==============================] - 0s 808us/step - loss: 0.6969\n",
      "7/7 [==============================] - 0s 840us/step\n",
      "Epoch 1/10\n",
      "14/14 [==============================] - 0s 909us/step - loss: 1.3986\n",
      "Epoch 2/10\n",
      "14/14 [==============================] - 0s 731us/step - loss: 1.1336\n",
      "Epoch 3/10\n",
      "14/14 [==============================] - 0s 731us/step - loss: 1.0078\n",
      "Epoch 4/10\n",
      "14/14 [==============================] - 0s 729us/step - loss: 0.9202\n",
      "Epoch 5/10\n",
      "14/14 [==============================] - 0s 780us/step - loss: 0.8527\n",
      "Epoch 6/10\n",
      "14/14 [==============================] - 0s 710us/step - loss: 0.8061\n",
      "Epoch 7/10\n",
      "14/14 [==============================] - 0s 810us/step - loss: 0.7638\n",
      "Epoch 8/10\n",
      "14/14 [==============================] - 0s 807us/step - loss: 0.7463\n",
      "Epoch 9/10\n",
      "14/14 [==============================] - 0s 805us/step - loss: 0.7186\n",
      "Epoch 10/10\n",
      "14/14 [==============================] - 0s 799us/step - loss: 0.7017\n",
      "7/7 [==============================] - 0s 1000us/step\n",
      "Epoch 1/10\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 1.3824\n",
      "Epoch 2/10\n",
      "14/14 [==============================] - 0s 776us/step - loss: 1.1136\n",
      "Epoch 3/10\n",
      "14/14 [==============================] - 0s 810us/step - loss: 1.0023\n",
      "Epoch 4/10\n",
      "14/14 [==============================] - 0s 793us/step - loss: 0.9170\n",
      "Epoch 5/10\n",
      "14/14 [==============================] - 0s 806us/step - loss: 0.8583\n",
      "Epoch 6/10\n",
      "14/14 [==============================] - 0s 730us/step - loss: 0.8205\n",
      "Epoch 7/10\n",
      "14/14 [==============================] - 0s 808us/step - loss: 0.7879\n",
      "Epoch 8/10\n",
      "14/14 [==============================] - 0s 731us/step - loss: 0.7537\n",
      "Epoch 9/10\n",
      "14/14 [==============================] - 0s 729us/step - loss: 0.7282\n",
      "Epoch 10/10\n",
      "14/14 [==============================] - 0s 811us/step - loss: 0.7147\n",
      "7/7 [==============================] - 0s 667us/step\n",
      "Epoch 1/10\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 1.6353\n",
      "Epoch 2/10\n",
      "14/14 [==============================] - 0s 981us/step - loss: 1.6350\n",
      "Epoch 3/10\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 1.6346\n",
      "Epoch 4/10\n",
      "14/14 [==============================] - 0s 973us/step - loss: 1.6342\n",
      "Epoch 5/10\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 1.6339\n",
      "Epoch 6/10\n",
      "14/14 [==============================] - 0s 962us/step - loss: 1.6335\n",
      "Epoch 7/10\n",
      "14/14 [==============================] - 0s 923us/step - loss: 1.6331\n",
      "Epoch 8/10\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 1.6328\n",
      "Epoch 9/10\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 1.6324\n",
      "Epoch 10/10\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 1.6320\n",
      "7/7 [==============================] - 0s 1ms/step\n",
      "Epoch 1/10\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 1.6961\n",
      "Epoch 2/10\n",
      "14/14 [==============================] - 0s 893us/step - loss: 1.6954\n",
      "Epoch 3/10\n",
      "14/14 [==============================] - 0s 897us/step - loss: 1.6947\n",
      "Epoch 4/10\n",
      "14/14 [==============================] - 0s 926us/step - loss: 1.6940\n",
      "Epoch 5/10\n",
      "14/14 [==============================] - 0s 884us/step - loss: 1.6933\n",
      "Epoch 6/10\n",
      "14/14 [==============================] - 0s 960us/step - loss: 1.6926\n",
      "Epoch 7/10\n",
      "14/14 [==============================] - 0s 929us/step - loss: 1.6919\n",
      "Epoch 8/10\n",
      "14/14 [==============================] - 0s 961us/step - loss: 1.6913\n",
      "Epoch 9/10\n",
      "14/14 [==============================] - 0s 921us/step - loss: 1.6906\n",
      "Epoch 10/10\n",
      "14/14 [==============================] - 0s 962us/step - loss: 1.6899\n",
      "7/7 [==============================] - 0s 1ms/step\n",
      "Epoch 1/10\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 1.6421\n",
      "Epoch 2/10\n",
      "14/14 [==============================] - 0s 942us/step - loss: 1.6415\n",
      "Epoch 3/10\n",
      "14/14 [==============================] - 0s 956us/step - loss: 1.6409\n",
      "Epoch 4/10\n",
      "14/14 [==============================] - 0s 923us/step - loss: 1.6404\n",
      "Epoch 5/10\n",
      "14/14 [==============================] - 0s 924us/step - loss: 1.6398\n",
      "Epoch 6/10\n",
      "14/14 [==============================] - 0s 960us/step - loss: 1.6392\n",
      "Epoch 7/10\n",
      "14/14 [==============================] - 0s 923us/step - loss: 1.6386\n",
      "Epoch 8/10\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 1.6381\n",
      "Epoch 9/10\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 1.6375\n",
      "Epoch 10/10\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 1.6369\n",
      "7/7 [==============================] - 0s 1ms/step\n",
      "Epoch 1/10\n",
      "103/103 [==============================] - 0s 708us/step - loss: 1.0625\n",
      "Epoch 2/10\n",
      "103/103 [==============================] - 0s 711us/step - loss: 0.8275\n",
      "Epoch 3/10\n",
      "103/103 [==============================] - 0s 807us/step - loss: 0.7611\n",
      "Epoch 4/10\n",
      "103/103 [==============================] - 0s 887us/step - loss: 0.7224\n",
      "Epoch 5/10\n",
      "103/103 [==============================] - 0s 870us/step - loss: 0.6838\n",
      "Epoch 6/10\n",
      "103/103 [==============================] - 0s 897us/step - loss: 0.6651\n",
      "Epoch 7/10\n",
      "103/103 [==============================] - 0s 902us/step - loss: 0.6615\n",
      "Epoch 8/10\n",
      "103/103 [==============================] - 0s 922us/step - loss: 0.6462\n",
      "Epoch 9/10\n",
      "103/103 [==============================] - 0s 888us/step - loss: 0.6288\n",
      "Epoch 10/10\n",
      "103/103 [==============================] - 0s 874us/step - loss: 0.6281\n",
      "CPU times: total: 18min 2s\n",
      "Wall time: 2min 7s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "#from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "rnd_search_cv = RandomizedSearchCV(\n",
    "    estimator=keras_clf, \n",
    "    param_distributions=params, \n",
    "    scoring='accuracy',  # we could use any appropriate sklearn metric here (i.e. accuracy, f1_micro, f1_macro)\n",
    "    n_iter=50, \n",
    "    cv=3)\n",
    "\n",
    "# In rare cases, you may find your model training results in exceeding python's default recursion limit.\n",
    "# If needed, you can increase this excersion limit by using the following code.\n",
    "#import sys\n",
    "#sys.setrecursionlimit(10000) # note: the default is 3000 (python 3.9)\n",
    "\n",
    "_ = rnd_search_cv.fit(X_train, y_train,  verbose=1)\n",
    "\n",
    "# You can create 'call back' functions. These are functions that will be called at the \n",
    "# end of each epoch. There are a number of builtin functions created for this purpose, \n",
    "# one of which is EarlyStopping -- that, based on the parameters you give, will stop\n",
    "# the training process. This is useful when the algorithm is not making any significant\n",
    "# gains through further training. \n",
    "#earlystop = EarlyStopping(monitor='val_loss', patience=5, verbose=0, mode='auto')\n",
    "#callback = [earlystop]\n",
    "#_ = rnd_search_cv.fit(X_train, y_train, callbacks=callback, verbose=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "b2b774af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'optimizer__learning_rate': 0.01,\n",
       " 'optimizer': 'adam',\n",
       " 'model__hidden_layer_sizes': (56,),\n",
       " 'model__dropout': 0,\n",
       " 'loss': 'sparse_categorical_crossentropy',\n",
       " 'epochs': 10,\n",
       " 'batch_size': 20}"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "317c4db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = rnd_search_cv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "ced292d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 0s 572us/step\n",
      "best score 0.6933895921237694\n",
      "min loss 0.6280825138092041\n",
      "CPU times: total: 375 ms\n",
      "Wall time: 82.6 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "print(f\"best score {best_model.score(X_test, y_test)}\")\n",
    "print(f\"min loss {min(best_model.history_['loss'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "f8723565",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list,\n",
       "            {'loss': [1.0625369548797607,\n",
       "              0.8274549841880798,\n",
       "              0.761139988899231,\n",
       "              0.7223868370056152,\n",
       "              0.6838194727897644,\n",
       "              0.6650986671447754,\n",
       "              0.6615259051322937,\n",
       "              0.6461979150772095,\n",
       "              0.6287920475006104,\n",
       "              0.6280825138092041]})"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.history_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "3baee4b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 0s 618us/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(y_test, best_model.predict(X_test))\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "85a66050",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 0s 587us/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6476    0.5484    0.5939       124\n",
      "           1     0.6279    0.5912    0.6090       137\n",
      "           2     0.8143    0.7403    0.7755       231\n",
      "           3     0.4511    0.6667    0.5381        90\n",
      "           4     0.8433    0.8760    0.8593       129\n",
      "\n",
      "    accuracy                         0.6934       711\n",
      "   macro avg     0.6768    0.6845    0.6752       711\n",
      "weighted avg     0.7086    0.6934    0.6969       711\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, best_model.predict(X_test), digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "2c01212c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Keras with Keras Hyperparameter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b1a0c2b",
   "metadata": {},
   "source": [
    " Keras Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "6d3e4324",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras_tuner\n",
    "# If you don't have keras_tuner installed, run the following in your terminal (mac), or anaconda prompt (windows)\n",
    "# conda install -c conda-forge keras-tuner\n",
    "\n",
    "\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "96184ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "\n",
    "\n",
    "def recall(y_true, y_pred):\n",
    "    y_true = K.ones_like(y_true)\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall_keras = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall_keras\n",
    "\n",
    "\n",
    "def precision(y_true, y_pred):\n",
    "    y_true = K.ones_like(y_true)\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision_keras = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision_keras\n",
    "\n",
    "\n",
    "def specificity(y_true, y_pred):\n",
    "    y_true = K.ones_like(y_true)\n",
    "    tn = K.sum(K.round(K.clip((1 - y_true) * (1 - y_pred), 0, 1)))\n",
    "    fp = K.sum(K.round(K.clip((1 - y_true) * y_pred, 0, 1)))\n",
    "    return tn / (tn + fp + K.epsilon())\n",
    "\n",
    "\n",
    "def negative_predictive_value(y_true, y_pred):\n",
    "    tn = K.sum(K.round(K.clip((1 - y_true) * (1 - y_pred), 0, 1)))\n",
    "    fn = K.sum(K.round(K.clip(y_true * (1 - y_pred), 0, 1)))\n",
    "    return tn / (tn + fn + K.epsilon())\n",
    "\n",
    "\n",
    "def f1(y_true, y_pred):\n",
    "    p = precision(y_true, y_pred)\n",
    "    r = recall(y_true, y_pred)\n",
    "    return 2 * ((p * r) / (p + r + K.epsilon()))\n",
    "\n",
    "\n",
    "def fbeta(y_true, y_pred, beta=2):\n",
    "    y_pred = K.clip(y_pred, 0, 1)\n",
    "\n",
    "    tp = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)), axis=1)\n",
    "    fp = K.sum(K.round(K.clip(y_pred - y_true, 0, 1)), axis=1)\n",
    "    fn = K.sum(K.round(K.clip(y_true - y_pred, 0, 1)), axis=1)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    num = (1 + beta ** 2) * (p * r)\n",
    "    den = (beta ** 2 * p + r + K.epsilon())\n",
    "    return K.mean(num / den)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "e5d585d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x2056bde47f0>"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def build_model(hp):\n",
    "    model = keras.Sequential()\n",
    "\n",
    "    # create input layer\n",
    "    model.add(layers.Input(9))\n",
    "\n",
    "    dropout = hp.Boolean(\"dropout\") # generate a boolean variable called dropout whos value is randomly set to either True of False\n",
    "    normalize = hp.Boolean(\"normalize\") # generate a boolean variable called normalize whos value is randomly set to either True of False\n",
    "\n",
    "    # create hidden layers\n",
    "    for i in range(hp.Int(name='hidden_layer_count', min_value=1, max_value=5, step=1)):\n",
    "        model.add(layers.Dense(units=hp.Int(\"units\", min_value=32, max_value=1024, step=32),activation=hp.Choice(\"activation\", [\"selu\", \"elu\", \"relu\", \"tanh\"]))) \n",
    "        if dropout:\n",
    "            model.add(layers.Dropout(rate=hp.Float(\"dropout rate\", min_value=0.01, max_value=0.1, step=.005)))\n",
    "        if normalize:\n",
    "            model.add(layers.Normalization())\n",
    "\n",
    "    model.add(layers.Dense(units=5, activation=\"softmax\"))\n",
    "\n",
    "    # Define the optimizer learning rate as a hyperparameter.\n",
    "    lr = hp.Float(\"lr\", min_value=1e-4, max_value=1e-2, sampling=\"log\")   \n",
    "    choice = hp.Choice(name='optimizer', values=['adam', 'sgd'])\n",
    "    if 'adam' == choice:\n",
    "        optimizer = keras.optimizers.legacy.Adam(learning_rate=lr)  # for M1/M2 use optimizers.legacy.Adam, otherwise use optimizers.Adam\n",
    "    else:\n",
    "        optimizer = keras.optimizers.legacy.SGD(learning_rate=lr)  # for M1/M2 use optimizers.legacy.SGD, otherwise use optimizers.SGD\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss=\"sparse_categorical_crossentropy\",\n",
    "        # see here https://www.tensorflow.org/api_docs/python/tf/keras/losses\n",
    "        \n",
    "        # Though you can add a metric, this doesn't get used to train the model, it's only informative (see previous notebook for more detail).\n",
    "        metrics=['accuracy', f1, recall, precision],  # you need to set this in order for keras_tuner to have one of these objectives!\n",
    "        # for metrics, see https://www.tensorflow.org/api_docs/python/tf/keras/metrics/\n",
    "    )\n",
    "    return model\n",
    "\n",
    "build_model(keras_tuner.HyperParameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "7dbcf186",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "datestring = datetime.datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "4e3ccce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = keras_tuner.RandomSearch(\n",
    "    hypermodel=build_model,\n",
    "    objective=\"val_accuracy\",\n",
    "# \n",
    "# You can use metrics other than accuracy, but you need to have this defined in the build model first\n",
    "# For instance, if you have f1 defined in the build model, to have keras_tuner 'tune' on f1, you set objective to be 'val_f1'. \n",
    "# For precision you would have to have precision defined in the build model, and to tune on precision, you set the object to \n",
    "# be 'val_precision', etc.\n",
    "# \n",
    "# Also, for custom objectives, you need to set a 'direction' for the tune... so if you want to maximize f1, you set direction to be 'max'.\n",
    "# \n",
    "#    objective = keras_tuner.Objective(\"val_f1\", direction=\"max\"), \n",
    "  \n",
    "    max_trials=150, # max_trials represents the number of hyperparameter combinations that will be tested by the tuner (like n_iter in sklearn random search)\n",
    "    executions_per_trial=2, # max number of models to fit per set of set of hyperparameters combinations\n",
    "\n",
    "    # the next three parameters about where the results from the training are stored\n",
    "    directory=f'logs/{datestring:s}',\n",
    "    project_name=\"keras_tuned\",\n",
    "    overwrite=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "2297736c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search space summary\n",
      "Default search space size: 7\n",
      "dropout (Boolean)\n",
      "{'default': False, 'conditions': []}\n",
      "normalize (Boolean)\n",
      "{'default': False, 'conditions': []}\n",
      "hidden_layer_count (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 1, 'max_value': 5, 'step': 1, 'sampling': 'linear'}\n",
      "units (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 1024, 'step': 32, 'sampling': 'linear'}\n",
      "activation (Choice)\n",
      "{'default': 'selu', 'conditions': [], 'values': ['selu', 'elu', 'relu', 'tanh'], 'ordered': False}\n",
      "lr (Float)\n",
      "{'default': 0.0001, 'conditions': [], 'min_value': 0.0001, 'max_value': 0.01, 'step': None, 'sampling': 'log'}\n",
      "optimizer (Choice)\n",
      "{'default': 'adam', 'conditions': [], 'values': ['adam', 'sgd'], 'ordered': False}\n"
     ]
    }
   ],
   "source": [
    "tuner.search_space_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "3a70a7fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 150 Complete [00h 00m 04s]\n",
      "val_accuracy: 0.527426153421402\n",
      "\n",
      "Best val_accuracy So Far: 0.6997186839580536\n",
      "Total elapsed time: 00h 10m 44s\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "CPU times: total: 1h 23min 13s\n",
      "Wall time: 10min 44s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import time\n",
    "from tensorflow.keras.callbacks import LambdaCallback\n",
    "    \n",
    "epoch_callback = LambdaCallback(\n",
    "    on_epoch_begin=lambda epoch,logs: print(f'Starting Epoch {epoch+1}!')\n",
    ")\n",
    "\n",
    "batch_loss_callback = LambdaCallback(\n",
    "    on_batch_end=lambda batch,logs: print(f'\\n After batch {batch}, the loss is {logs}.')\n",
    ")\n",
    "    \n",
    "train_finish_callback = LambdaCallback(\n",
    "    on_train_end=lambda logs: print('Training finished!')\n",
    ")\n",
    "\n",
    "tuner.search(\n",
    "    X_train, \n",
    "    y_train, \n",
    "    epochs=10, \n",
    "    batch_size=200, \n",
    "    validation_data=(X_test, y_test), \n",
    "    callbacks=[epoch_callback, batch_loss_callback, train_finish_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "0a0de89f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results summary\n",
      "Results in logs/2023-04-13-18-28-55\\keras_tuned\n",
      "Showing 10 best trials\n",
      "Objective(name=\"val_accuracy\", direction=\"max\")\n",
      "\n",
      "Trial 056 summary\n",
      "Hyperparameters:\n",
      "dropout: False\n",
      "normalize: False\n",
      "hidden_layer_count: 4\n",
      "units: 416\n",
      "activation: relu\n",
      "lr: 0.001378263248778274\n",
      "optimizer: adam\n",
      "dropout rate: 0.04\n",
      "Score: 0.6997186839580536\n",
      "\n",
      "Trial 000 summary\n",
      "Hyperparameters:\n",
      "dropout: False\n",
      "normalize: True\n",
      "hidden_layer_count: 4\n",
      "units: 448\n",
      "activation: relu\n",
      "lr: 0.0007104416318148381\n",
      "optimizer: adam\n",
      "Score: 0.6983122527599335\n",
      "\n",
      "Trial 052 summary\n",
      "Hyperparameters:\n",
      "dropout: False\n",
      "normalize: True\n",
      "hidden_layer_count: 3\n",
      "units: 224\n",
      "activation: relu\n",
      "lr: 0.005862125721808125\n",
      "optimizer: adam\n",
      "dropout rate: 0.060000000000000005\n",
      "Score: 0.6983122229576111\n",
      "\n",
      "Trial 061 summary\n",
      "Hyperparameters:\n",
      "dropout: True\n",
      "normalize: False\n",
      "hidden_layer_count: 3\n",
      "units: 992\n",
      "activation: relu\n",
      "lr: 0.005227316838512897\n",
      "optimizer: adam\n",
      "dropout rate: 0.015\n",
      "Score: 0.6969057619571686\n",
      "\n",
      "Trial 140 summary\n",
      "Hyperparameters:\n",
      "dropout: True\n",
      "normalize: False\n",
      "hidden_layer_count: 5\n",
      "units: 320\n",
      "activation: relu\n",
      "lr: 0.0006068110204571213\n",
      "optimizer: adam\n",
      "dropout rate: 0.03\n",
      "Score: 0.6954993009567261\n",
      "\n",
      "Trial 034 summary\n",
      "Hyperparameters:\n",
      "dropout: False\n",
      "normalize: True\n",
      "hidden_layer_count: 4\n",
      "units: 832\n",
      "activation: relu\n",
      "lr: 0.0009878314341240696\n",
      "optimizer: adam\n",
      "dropout rate: 0.055\n",
      "Score: 0.6947960555553436\n",
      "\n",
      "Trial 016 summary\n",
      "Hyperparameters:\n",
      "dropout: True\n",
      "normalize: False\n",
      "hidden_layer_count: 2\n",
      "units: 992\n",
      "activation: relu\n",
      "lr: 0.0013960944101282333\n",
      "optimizer: adam\n",
      "dropout rate: 0.09\n",
      "Score: 0.6933895945549011\n",
      "\n",
      "Trial 071 summary\n",
      "Hyperparameters:\n",
      "dropout: True\n",
      "normalize: False\n",
      "hidden_layer_count: 3\n",
      "units: 480\n",
      "activation: tanh\n",
      "lr: 0.00044010071253490897\n",
      "optimizer: adam\n",
      "dropout rate: 0.08499999999999999\n",
      "Score: 0.6933895945549011\n",
      "\n",
      "Trial 096 summary\n",
      "Hyperparameters:\n",
      "dropout: False\n",
      "normalize: False\n",
      "hidden_layer_count: 5\n",
      "units: 96\n",
      "activation: selu\n",
      "lr: 0.0005160433527180204\n",
      "optimizer: adam\n",
      "dropout rate: 0.06999999999999999\n",
      "Score: 0.6933895945549011\n",
      "\n",
      "Trial 031 summary\n",
      "Hyperparameters:\n",
      "dropout: True\n",
      "normalize: False\n",
      "hidden_layer_count: 5\n",
      "units: 672\n",
      "activation: tanh\n",
      "lr: 0.0008635595838211174\n",
      "optimizer: adam\n",
      "dropout rate: 0.095\n",
      "Score: 0.6884669661521912\n"
     ]
    }
   ],
   "source": [
    "tuner.results_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "2783b332",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dropout': False,\n",
       " 'normalize': False,\n",
       " 'hidden_layer_count': 4,\n",
       " 'units': 416,\n",
       " 'activation': 'relu',\n",
       " 'lr': 0.001378263248778274,\n",
       " 'optimizer': 'adam',\n",
       " 'dropout rate': 0.04}"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_hps = tuner.get_best_hyperparameters(5)\n",
    "best_hps[0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "93cf31fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 416)               4160      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 416)               173472    \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 416)               173472    \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 416)               173472    \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 5)                 2085      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 526,661\n",
      "Trainable params: 526,661\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Get list of the top 2 models.\n",
    "models = tuner.get_best_models(num_models=2)\n",
    "# select the first one in the list (this is the best performing model)\n",
    "best_model = models[0] # select the first one\n",
    "# display summary of model training\n",
    "best_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "e04b7f1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 1ms/step - loss: 0.9722 - accuracy: 0.7075 - f1: 0.9553 - recall: 0.9158 - precision: 1.0000\n",
      "Loss: 0.972199022769928 Accuracy: 0.707454264163971 F1 Score: 0.9553139805793762 Precision: 0.91576087474823 Recall: 1.0\n"
     ]
    }
   ],
   "source": [
    "(loss,accuracy,f1_score, precision, recall) = best_model.evaluate(X_test, y_test, verbose=1)\n",
    "print(f\"Loss: {loss} Accuracy: {accuracy} F1 Score: {f1_score} Precision: {precision} Recall: {recall}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e7ba2d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "cc642198",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Site_Id', 1)]\n",
      "23/23 [==============================] - 0s 900us/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# for reference, list the frequency of each digit found in the y_test data\n",
    "print(sorted(collections.Counter(y_test).items(), key=lambda i: i[0]))\n",
    "      \n",
    "# display the confusion matrix\n",
    "cm = confusion_matrix(y_test, best_model.predict(X_test).argmax(axis=1))\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "1a3f04e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 940us/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.59      0.61       124\n",
      "           1       0.62      0.58      0.60       137\n",
      "           2       0.83      0.80      0.81       231\n",
      "           3       0.48      0.62      0.54        90\n",
      "           4       0.87      0.85      0.86       129\n",
      "\n",
      "    accuracy                           0.71       711\n",
      "   macro avg       0.68      0.69      0.68       711\n",
      "weighted avg       0.72      0.71      0.71       711\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, best_model.predict(X_test).argmax(axis=1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3775fe37",
   "metadata": {},
   "source": [
    "## For the above data we have fitted the following Neural networks\n",
    "1. NN by using sklearn - (68% accuracy)\n",
    "2. NN by using sklearn and using sklearn hyperparameter tuning - (72% accuracy) \n",
    "3. NN by using keras - (69% accuracy)\n",
    "4. NN by using Kears and using sklearn Hyperparamerter tuning - (69.3% accuracy)\n",
    "5. NN by using Keras and using Keras Hyperparameter tuning - (71%)\n",
    "\n",
    "from the above Accuracy results we can say the the NN with sklearn and with the sklearn hyperparameter is the best fit model for the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b901df3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
